<!DOCTYPE html>
<html lang="es" xml:lang="es">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Fundamentos de Investigación II</title>
  <meta name="description" content="Apuntes de la asignatura de Fundamentos de Investigación II" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Fundamentos de Investigación II" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.png" />
  <meta property="og:description" content="Apuntes de la asignatura de Fundamentos de Investigación II" />
  <meta name="github-repo" content="negatoscope/FdI2" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Fundamentos de Investigación II" />
  
  <meta name="twitter:description" content="Apuntes de la asignatura de Fundamentos de Investigación II" />
  <meta name="twitter:image" content="images/cover.png" />

<meta name="author" content="Luis Eudave" />


<meta name="date" content="2020-09-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Fundamentos de Investigación II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="03-method.html"><a href="#probability"><i class="fa fa-check"></i><b>1</b> Introducción a la probabilidad</a><ul>
<li class="chapter" data-level="1.1" data-path="03-method.html"><a href="#probstats"><i class="fa fa-check"></i><b>1.1</b> ¿Cómo de diferentes son la probabilidad y la estadística?</a></li>
<li class="chapter" data-level="1.2" data-path="03-method.html"><a href="#probmeaning"><i class="fa fa-check"></i><b>1.2</b> ¿Qué significa la probabilidad?</a><ul>
<li class="chapter" data-level="1.2.1" data-path="03-method.html"><a href="#la-visión-frecuentista"><i class="fa fa-check"></i><b>1.2.1</b> La visión frecuentista</a></li>
<li class="chapter" data-level="1.2.2" data-path="03-method.html"><a href="#la-visión-bayesiana"><i class="fa fa-check"></i><b>1.2.2</b> La visión bayesiana</a></li>
<li class="chapter" data-level="1.2.3" data-path="03-method.html"><a href="#cuál-es-la-diferencia-y-quién-tiene-razón"><i class="fa fa-check"></i><b>1.2.3</b> ¿Cuál es la diferencia? ¿Y quién tiene razón?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="03-method.html"><a href="#basicprobability"><i class="fa fa-check"></i><b>1.3</b> Teoría de probabilidad básica</a><ul>
<li class="chapter" data-level="1.3.1" data-path="03-method.html"><a href="#introducción-a-las-distribuciones-de-probabilidad"><i class="fa fa-check"></i><b>1.3.1</b> Introducción a las distribuciones de probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="03-method.html"><a href="#binomial"><i class="fa fa-check"></i><b>1.4</b> La distribución binomial</a><ul>
<li class="chapter" data-level="1.4.1" data-path="03-method.html"><a href="#introducción-al-binomio"><i class="fa fa-check"></i><b>1.4.1</b> Introducción al binomio</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="03-method.html"><a href="#normal"><i class="fa fa-check"></i><b>1.5</b> La distribución normal</a><ul>
<li class="chapter" data-level="1.5.1" data-path="03-method.html"><a href="#density"><i class="fa fa-check"></i><b>1.5.1</b> Densidad de probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="03-method.html"><a href="#otherdists"><i class="fa fa-check"></i><b>1.6</b> Otras distribuciones útiles</a></li>
<li class="chapter" data-level="1.7" data-path="03-method.html"><a href="#resumen"><i class="fa fa-check"></i><b>1.7</b> Resumen</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de Investigación II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Fundamentos de Investigación II</h1>
<p class="author"><em>Luis Eudave</em></p>
<p class="date"><em>2020-09-03</em></p>
</div>
<div id="probability" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Introducción a la probabilidad</h1>
<p>Hasta este punto en el libro, hemos discutido algunas de las ideas clave sobre el diseño experimental, y hemos hablado un poco acerca de cómo puede resumir un conjunto de datos. Para muchas personas, esto es todo lo que hay en estadística: calcular promedios, recopilar datos, elaborar gráficos y ponerlos todos en un informe en algún lugar. Mas o menos como coleccionar sellos, pero con números. Sin embargo, las estadísticas cubren mucho más que eso. De hecho, la estadística descriptiva es una de las partes más pequeñas de la estadística, y una de las menos poderosas (en cuanto a las conclusiones que puede aportar). La parte más importante y más útil de la estadística es aquella que que permite hacer <em>inferencias</em> sobre los datos.</p>
<p>Una vez contemplada las estadística en estos términos, -que la estadística están ahí para ayudarnos a hacer inferencias a partir de datos- podemos ver ejemplos de ella en todas partes. Por ejemplo, aquí hay un pequeño extracto de un periódico artículo en el Sydney Morning Herald (30 de octubre de 2010):</p>
<blockquote>
<p>&quot;Tengo un trabajo difícil&quot;, dijo el Primer Ministro en respuesta a una encuesta que encontró que su gobierno es ahora la administración más impopular en la historia de las encuestas, con un voto primario de sólo el 23 por ciento.</p>
</blockquote>
<p>Este tipo de comentario es completamente irrelevante en los periódicos o en la vida cotidiana, pero pensemos sobre lo que implica. Una compañía encuestadora ha realizado una encuesta, generalmente una muy grande porque puede permitírselo. Imaginemos que llamaron a 1.000 votantes de la región de New South Wales (NSW) al azar, y 230 (23%) de ellos afirmaron que tenían la intención de votar por el ALP. Para la elección federal del 2010, la Comisión Electoral Australiana confirmó la participación de 4.610.795 votantes inscritos en Nueva Gales del Sur; por lo tanto, las opiniones de los 4,609,795 votantes restantes (aproximadamente el 99.98% de los votantes) siguen siendo desconocidas para la encuestadora (y para nosotros). Aún suponiendo que nadie mintió en la encuesta, lo único que podemos decir con un 100% de confianza es que el verdadero voto primario al ALP está en algún lugar entre 230/4610795 (aproximadamente el 0.005%) y 4610025/4610795 (alrededor del 99.83%). Entonces, ¿sobre qué base es legítimo para la empresa encuestadora, el periódico y el lectores concluir que el voto primario al ALP fue de sólo el 23%?</p>
<p>La respuesta a la pregunta es bastante obvia: si llamo a 1.000 personas al azar, y 230 de ellas dicen tienen la intención de votar por el ALP, entonces parece muy poco probable que estas sean las <em>únicas</em> 230 personas del todo el público votante que realmente tiene la intención de hacerlo. En otras palabras, suponemos que los datos recopilados por la empresa encuestadora es bastante representativa de la población en general. ¿Pero qué tan representativo? ¿Nos sorprendería descubrir que el verdadero voto primario al ALP es en realidad del 24%? ¿29%? ¿37%? En este punto nuestración intuición comienza a romperse un poco. Nadie se sorprendería si fuese el 24%, y todos lo harían con un 37%, pero es un poco difícil decir si el 29% es plausible. Necesitamos algunas herramientas más poderosas que solo el mirar los números y adivinar.</p>
<p><strong><em>La estadística inferencial</em></strong> proporciona las herramientas que necesitamos para responder a este tipo de preguntas, y ya que este tipo de preguntas se encuentran en el corazón del quehacer científica, ocupan una parte sustancial de cada curso introductorio sobre estadística y métodos de investigación. Sin embargo, la teoría sobre la estadística inferencial está construida sobre la <strong><em>teoría de probabilidad</em></strong>. Y es a la teoría de la probabilidad a la que ahora debemos girar. La discusión de la teoría de la probabilidad es básicamente de fondo: no hay mucho contenido estadístico <em>per se</em> en este capítulo, y no es necesario comprender este material con tanta profundidad como en otros capítulos libro. Sin embargo, debido a que gran parte de la estadística se sustenta en la teoría de la probabilidad, merece la pena ir cubriendo algunos de los conceptos básicos.</p>
<div id="probstats" class="section level2">
<h2><span class="header-section-number">1.1</span> ¿Cómo de diferentes son la probabilidad y la estadística?</h2>
<p>Antes de comenzar a hablar sobre la teoría de la probabilidad, es útil pensar un momento en la relación que existe entre probabilidad y estadística. Las dos disciplinas están estrechamente relacionadas, pero no son idénticas. La teoría de la probabilidad es &quot;la doctrina de las posibilidades&quot;. Es una rama de las matemáticas que te dice con qué frecuencia sucederán diferentes tipos de eventos. Por ejemplo, todas estas preguntas son cosas que puedes responder usando la teoría de la probabilidad:</p>
<ul>
<li>¿Cuáles son las probabilidades de que al lanzar una moneda salga cara 10 veces seguidas?</li>
<li>Si lanzo dos dados de seis caras, ¿qué probabilidad hay de que tire dos seises?</li>
<li>¿Qué probabilidad hay de que cinco cartas extraídas de un mazo perfectamente barajado sean todas de corazones?</li>
<li>¿Cuál es la probabilidad de que gane la lotería?</li>
</ul>
<p>Hay que tener en cuenta que todas estas preguntas tienen algo en común. En cada caso, existe y se conoce una &quot;verdad sobre el mundo&quot;, y la pregunta se refiere más bien al &quot;qué tipo de eventos&quot; sucederán. En la primera pregunta que <em>sé</em> que la moneda es justa (no es más pesada por uno de los lados, sesgando el resultado), por lo que hay un 50% de probabilidad de que cualquier lanzamiento de moneda salga cara. En la segunda pregunta, <em>sé</em> que la probabilidad de sacar un 6 en un solo dado es de 1 en 6. En la tercera pregunta <em>sé</em> que la baraja se baraja correctamente (no hay un acomodo de cartas). Y en la cuarta pregunta, sé que la lotería sigue unas reglas específicas. El punto crítico es que las preguntas probabilísticas comienzan con un <strong><em>modelo</em></strong> conocido del mundo, y usamos ese modelo para hacer algunos cálculos. El modelo subyacente puede ser bastante simple. Por ejemplo, en el ejemplo de lanzar monedas, podemos escribir el modelo de esta manera: <span class="math display">\[
P(\mbox{cara}) = 0.5
\]</span> que puedes leer como &quot;la probabilidad de que salga cara es 0.5&quot;. Como veremos más adelante, de la misma manera que los porcentajes son números que van del 0% al 100%, las probabilidades son solo números que van del 0 al 1. Cuando usamos este modelo de probabilidad para responder a la primera pregunta, en realidad no sé exactamente qué va a ocurrir. Tal vez obtenga 10 caras, como dice la pregunta. Pero tal vez salgan sólo tres caras. Esta es la clave: con la teoría de la probabilidad, se conoce el <em>modelo</em>, pero no los <em>datos</em>.</p>
<p>Hemos visto lo que es la probabilidad. ¿Qué hay de las estadística? Las preguntas en estadística funcionan al revés. En estadística, nosotros <em>no</em> sabemos la verdad sobre el mundo. Todo lo que tenemos son los datos, y es a partir de esos datos que queremos <em>aprender</em> sobre la verdad del mundo. Las preguntas estadísticas tienden a parecerse más a estas:</p>
<ul>
<li>Si mi amigo lanza una moneda 10 veces y obtiene 10 caras, ¿me está engañando?</li>
<li>Si las primeras cinco cartas de la parte superior del mazo son todas de corazones, ¿qué tan probable es que se haya barajado el mazo?</li>
<li>Si el hijo del comisionado de la lotería gana la lotería, ¿qué tan probable es que el sorteo haya sido manipulado?</li>
</ul>
<p>Esta vez, lo único que tenemos son datos. Lo que <em>sé</em> es que vi a mi amigo lanzar la moneda 10 veces y salió cara en cada una de las veces. Y lo que quiero es <strong><em>inferir</em></strong> si debería concluir que lo que acabo de ver es en realidad una moneda justa lanzada 10 veces seguidas, o si debería sospechar que mi amigo me está jugando una mala pasada. Los datos que tengo se ven así:</p>
<pre><code>C C C C C C C C C C C</code></pre>
<p>y lo que estoy tratando de hacer es averiguar en qué &quot;modelo de verdad del mundo&quot; debería confiar. Si la moneda es justa, entonces el modelo que debo aceptar es uno que diga que la probabilidad de que salga cara es 0.5; es decir, <span class="math inline">\(P(\mbox{cara}) = 0.5\)</span>. Si la moneda no es justa, entonces debo concluir que la probabilidad de que salga cara <em>no</em> es 0.5, lo que escribiríamos como <span class="math inline">\(P(\mbox{cara}) \neq 0.5\)</span>. En otras palabras, el objetivo de la inferencia estadística es decidir cual de estos modelos de probabilidad es el correcto. Vemos pues, que una pregunta en estadística no es la misma que una pregunta en probabilidad, pero están íntimamente conectados entre sí. Es por ello que una buena introducción a la teoría estadística comenzará con una discusión sobre qué es la probabilidad y cómo funciona.</p>
</div>
<div id="probmeaning" class="section level2">
<h2><span class="header-section-number">1.2</span> ¿Qué significa la probabilidad?</h2>
<p>Comencemos con la primera de estas preguntas. ¿Qué es la &quot;probabilidad&quot;? Puede parecer sorprendente, pero mientras que los estadísticos y matemáticos (en su mayoría) están de acuerdo sobre cuáles son las <em>reglas</em> de la probabilidad, hay mucho menos consenso sobre lo que realmente <em>significa</em> la palabra. Parece extraño porque todos usemos con soltura palabras como &quot;posibilidad&quot;, &quot;probabilidad&quot;, &quot;posible&quot; y &quot;probable&quot;, y además no parece que deba ser una pregunta difícil de responder. Si tuvieramos que explicar el concepto de &quot;probabilidad&quot; a un niño de cinco años, podríamos hacerlo sin muchos problemas. Pero si alguna vez has tenido esa experiencia en la vida real, podrías terminar esa conversación sintiendo que no lo has hecho muy bien y que (como con muchos conceptos cotidianos) resulta que <em>realmente</em> no sabes de qué se trata.</p>
<p>Así que intentémoslo. Supongamos que quiero apostar en un juego de fútbol entre dos equipos de robots, <em>Arduino Arsenal</em> y <em>C Milan</em>. Después de pensarlo un poco, decido que hay un 80% de probabilidad de que el <em>Arduino Arsenal</em> gane. ¿Qué quiero decir realmente con eso? Aquí hay tres posibilidades...</p>
<ul>
<li>Son equipos de robots, así que puedo hacer que jueguen una y otra vez, y si lo hiciera, el <em>Arduino Arsenal</em> ganaría 8 de cada 10 juegos de media.</li>
<li>En cada juego solo estaría de acuerdo en que apostar en este juego es &quot;justo&quot; si una apuesta de $1 al <em>C Milan</em> da un pago de $5 (es decir, recibo mi $1 de vuelta más una recompensa de $4 por haber acertado), al igual que una apuesta de $4 al <em>Arduino Arsenal</em> (es decir, mi apuesta de $4 más una recompensa de $1).</li>
<li>Mi &quot;creencia&quot; o &quot;confianza&quot; subjetiva en una victoria del <em>Arduino Arsenal</em> es cuatro veces más fuerte que mi &quot;creencia&quot; o &quot;confianza&quot; en una victoria del <em>C Milan</em>.</li>
</ul>
<p>Cada uno de estos enunciados parece correcto. Sin embargo, no son idénticos, y no todos los estadísticos respaldarían todos ellos por igual. La razón es que hay diferentes ideologías estadísticas (¡sí, de verdad!) y dependiendo de cual se escoja, se podría decir que algunas de estas declaraciones no tienen sentido o que son irrelevantes. En esta sección, se dará una breve introducción a dos de los enfoques principales que existen en la literatura estadística. Esto no significa que sean los únicos enfoques, pero sí los dos más importantes.</p>
<div id="la-visión-frecuentista" class="section level3">
<h3><span class="header-section-number">1.2.1</span> La visión frecuentista</h3>
<p>El primero de los dos enfoques principales a la teoría de la probabilidad, y el más dominante en estadística, se le conoce como la <strong><em>visión frecuentista</em></strong>, y define a la probabilidad como una <strong>_ frecuencia a largo plazo_</strong>. Supongamos que queremos intentar lanzar una moneda justa, una y otra vez. Por definición, esta es una moneda que tiene una <span class="math inline">\(P(Cara) = 0.5\)</span>. ¿Qué resultado podremos observar? Una posibilidad es que los primeros 20 lanzamientos se vean así (donde C es cara y X cruz):</p>
<pre><code>X,C,C,C,C,X,X,C,C,C,C,X,C,C,X,X,X,X,X,C</code></pre>
<p>En este caso, en 11 de los 20 lanzamientos (55%) salió cara. Ahora supongamos que he ido guardando un registro con el número de caras (que llamaré <span class="math inline">\(N_C\)</span>) que han salido, a lo largo de las primeras <span class="math inline">\(N\)</span> lanzadas de moneda, además de calcular la proporción de caras <span class="math inline">\(N_C / N\)</span> con cada registro. Este es el resultado que obtendría (¡literalmente lancé monedas para producir esto!):</p>
<table>
<thead>
<tr class="header">
<th align="right">número.de.lanzamientos</th>
<th align="right">número.de.caras</th>
<th align="right">proporción</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">1</td>
<td align="right">0.50</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">2</td>
<td align="right">0.67</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">3</td>
<td align="right">0.75</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">4</td>
<td align="right">0.80</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">4</td>
<td align="right">0.67</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">4</td>
<td align="right">0.57</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">5</td>
<td align="right">0.63</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">6</td>
<td align="right">0.67</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">7</td>
<td align="right">0.70</td>
</tr>
<tr class="odd">
<td align="right">11</td>
<td align="right">8</td>
<td align="right">0.73</td>
</tr>
<tr class="even">
<td align="right">12</td>
<td align="right">8</td>
<td align="right">0.67</td>
</tr>
<tr class="odd">
<td align="right">13</td>
<td align="right">9</td>
<td align="right">0.69</td>
</tr>
<tr class="even">
<td align="right">14</td>
<td align="right">10</td>
<td align="right">0.71</td>
</tr>
<tr class="odd">
<td align="right">15</td>
<td align="right">10</td>
<td align="right">0.67</td>
</tr>
<tr class="even">
<td align="right">16</td>
<td align="right">10</td>
<td align="right">0.63</td>
</tr>
<tr class="odd">
<td align="right">17</td>
<td align="right">10</td>
<td align="right">0.59</td>
</tr>
<tr class="even">
<td align="right">18</td>
<td align="right">10</td>
<td align="right">0.56</td>
</tr>
<tr class="odd">
<td align="right">19</td>
<td align="right">10</td>
<td align="right">0.53</td>
</tr>
<tr class="even">
<td align="right">20</td>
<td align="right">11</td>
<td align="right">0.55</td>
</tr>
</tbody>
</table>
<p>Tengamos en cuenta que al comienzo de esta secuencia, la <em>proporción</em> de caras fluctúa enormemente, comenzando en .00 y subiendo tan alto como .80. Conforme aumenta el número de lanzamientos, uno tiene la impresión de que este efecto se amortigua un poco, mientras que los valores se aproximan cada vez más a la respuesta &quot;correcta&quot; de .50. Esta es la definición frecuentista de probabilidad en pocas palabras: lanzar una moneda justa una y otra vez, y a medida que <span class="math inline">\(N\)</span> crece (se acerca al infinito, denotado como <span class="math inline">\(N\rightarrow \infty\)</span>), la proporción de caras convergerá en el 50%. Tecnicismos matemáticos aparte, cualitativamente hablando, es así es como los frecuentistas definen la probabilidad. Desafortunadamente, no tengo un número infinito de monedas, o la paciencia infinita requerida para lanzar una moneda un número infinito de veces. Sin embargo, existen los ordenadores, y los ordenadores destacan en la ejecución repetitiva de tareas sin sentido como esta. Entonces, al simular 1.000 lanzamientos de moneda y repetir este procesos 4 veces (para darle solidez a los resultados), podemos ver qué sucede con la proporción <span class="math inline">\(N_C / N\)</span> a medida que <span class="math inline">\(N\)</span> aumenta. Los resultados se muestran en la Figura <a href="#fig:frequentistprobability">1.1</a>. Podemos apreciar que la <em>proporción de caras observadas</em> deja de fluctuar conforme aumenta el número de lanzamientos; cuando lo hace, el número en el que finalmente obtenemos es el verdadera probabilidad de salga cara.</p>
<div class="figure"><span id="fig:frequentistprobability"></span>
<img src="FdI2_files/figure-html/frequentistprobability-1.png" alt=" Una imagen de cómo funciona la probabilidad frecuentista. Si lanzas una moneda justa una y otra vez, la proporción de caras deja de fluctuar y converge hacia la probabilidad real de 0.5. Cada panel muestra uno de las cuatro simulaciones con 1.000 lanzamientos cada uno. Aunque ninguna de estas simulaciones terminó con un valor exacto de .5, si hubiéramos extendido el experimento por un número infinito de lanzamientos lo habríamos conseguido." width="672" />
<p class="caption">
Figure 1.1:  Una imagen de cómo funciona la probabilidad frecuentista. Si lanzas una moneda justa una y otra vez, la proporción de caras deja de fluctuar y converge hacia la probabilidad real de 0.5. Cada panel muestra uno de las cuatro simulaciones con 1.000 lanzamientos cada uno. Aunque ninguna de estas simulaciones terminó con un valor exacto de .5, si hubiéramos extendido el experimento por un número infinito de lanzamientos lo habríamos conseguido.
</p>
</div>
<p>La definición frecuentista de probabilidad tiene algunas características que le hacen deseable. En primer lugar, es objetivo: la probabilidad de un evento se basa <em>necesariamente</em> en el mundo. La única forma en que declaraciones de probabilidad puedan tener sentido es si se refieren a (una secuencia de) eventos que ocurren en el universo físico. En segundo lugar, es inequívoco: dos personas que miran como se desarrollala misma secuencia de eventos, al tratar de calcular la probabilidad de un evento, inevitablemente deberán llegar a la misma respuesta. Sin embargo, también tiene algunas características no tan deseables. En primer lugar, no existen secuencias infinitas en el mundo físico. Supongamos que has recogido una moneda y has comenzado a lanzarla varias veces. Cada vez que aterriza, impacta en el suelo. Cada impacto daña un poco a la moneda; eventualmente, la moneda será inutilizable. Entonces, uno podría preguntarse si realmente tiene sentido fingir que una secuencia &quot;infinita&quot; de lanzamientos de monedas es un concepto significativo u objetivo. No podemos decir que una &quot;secuencia infinita&quot; de eventos es algo real en el universo físico, porque el universo físico no permite nada infinito. Así, podemos ver que la definición frecuentista tiene un alcance limitado. Hay muchas cosas por ahí a las que los seres humanos estamos felices de asignar probabilidades en el día a día, pero que no pueden (ni siquiera en teoría) ser planteadas como una secuencia hipotética de eventos. Por ejemplo, si un meteorólogo aparece en televisión y dice: &quot;la probabilidad de lluvia en Pamplona (Navarra) el 2 de noviembre del 2048 es del 60%&quot; nosotros podemos aceptarlo sin rechistar. Pero desde un punto de vista frecuentista, no queda tan claro cómo podemos defirnirlo. Sólo hay una ciudad de Pamplona (en Navarra), y solo un 2 de noviembre del 2048. Aquí no hay una secuencia infinita de eventos, solo una cosa de una vez. La probabilidad frecuentista nos <em>prohíbe</em> hacer declaraciones de probabilidad sobre un solo evento. Desde la perspectiva frecuentista, lloverá mañana o o no lloverá; no hay una &quot;probabilidad&quot; que se pueda adjuntar a un solo evento no repetible. Sin embargo, existen algunos trucos muy inteligentes que los frecuentistas pueden utililizar para solucionar esta situación. Una posibilidad es que el meteorólogo en realidad quería decir algo así: &quot;Existe una categoría de días para la que predigo un 60% probabilidad de lluvia; si miramos sólo esos días para los que hago esta predicción, entonces en el 60% de esos días lloverá realmente&quot;. Es un poco extraño y contradictorio pensarlo de esta manera, pero los frecuentistas sí que hacen esto a veces. Y lo veremos más adelante (ver Sección <a href="#ci"><strong>??</strong></a>).</p>
</div>
<div id="la-visión-bayesiana" class="section level3">
<h3><span class="header-section-number">1.2.2</span> La visión bayesiana</h3>
<p>La alternativa a la visión frecuentista, la <strong><em>visión bayesiana</em></strong> de la probabilidad, a menudo se denomina visión subjetivista, y es una visión relativamente minoritaria entre los estadísticos, aunque ha ido ganando terreno constantemente a lo largo de las últimas décadas. Hay muchos formas de bayesianismo, lo que hace difícil decir exactamente cuál es &quot;la&quot; visión bayesiana. La forma más fácil de entender la probabilidad subjetiva es al definir la probabilidad de un evento como el <strong><em>grado de creencia</em></strong> que un agente inteligente y racional asigna a la verdad de ese evento. Desde esa perspectiva, las probabilidades no existen en el mundo, sino más bien en los pensamientos y suposiciones de las personas y otros seres inteligentes. Sin embargo, para que este enfoque funcione, necesitamos una forma de operacionalizar este &quot;grado de creencia&quot;. Una forma de hacerlo es formalizándolo en términos de una &quot;apuesta racional&quot; aunque existen muchas otras formas. Supongamos que creo que existe una probabilidad de que llueva mañana de un 60%. Si alguien me hace una apuesta, si llueve mañana, gano $5, pero si no llueve, pierdo $5. Claramente, desde mi punto de vista, esta es una buena apuesta. Por otro lado, si creo que la probabilidad de lluvia es sólo del 40%, entonces es una mala apuesta. Por lo tanto, podemos poner en práctica la noción de una &quot;probabilidad subjetiva&quot; en términos de qué apuestas que estoy dispuesto a aceptar.</p>
<p>¿Cuáles son las ventajas y desventajas del enfoque bayesiano? La principal ventaja es que le permite asignar probabilidades a cualquier evento. No esta limitado a aquellos eventos que son repetibles. La principal desventaja (para muchas personas) es que no podemos ser realmente objetivos - especificar una probabilidad requiere que especifiquemos la entidad que tiene el grado de creencia que estamos examinando. Esta entidad puede ser un humano, un extraterrestre, un robot o incluso un estadístico, pero tiene que ser un agente inteligente que sea capaz de creer en cosas. Para muchas personas esto representa un inconveniente: parece hacer que la probabilidad sea arbitraria. Si bien el enfoque bayesiano requiere que el agente en cuestión sea racional (es decir, que obedezca las reglas de la probabilidad), permite que todos tengan sus propias creencias; yo puedo creer que la moneda es justa mientras que otro no, aunque ambos seamos racionales. La visión frecuentista no permite que dos observadores atribuyan diferentes probabilidades al mismo evento: cuando eso sucede, al menos uno de ellos debe estar equivocado. La visión bayesiana no evita que esto ocurra. Dos observadores con diferentes conocimientos previos pueden tener legítimamente creencias diferentes sobre el mismo evento. En otras palabras, mientras que la visión frecuentista se puede considerar demasiado estrecha (prohíbe muchas cosas a las cuales queremos asignar probabilidades), la visión bayesiana puede resultar demasiado amplia (permite demasiadas diferencias entre observadores).</p>
</div>
<div id="cuál-es-la-diferencia-y-quién-tiene-razón" class="section level3">
<h3><span class="header-section-number">1.2.3</span> ¿Cuál es la diferencia? ¿Y quién tiene razón?</h3>
<p>Ahora que hemos visto ambas visiones estadísticas de forma independiente, es necesario compararlas. Regresemos al hipotético juego de fútbol de robots que comentamos comienzo de la sección. ¿Que dirían un frecuentista y un bayesiano sobre las tres afirmaciones? ¿Qué enunciado sería la definición de probabilidad correcta para el frecuentista? ¿Y para el bayesiano? ¿Es posible que alguno de los enunciados no tenga sentido para cualquiera de los dos? Si entendemos ambas perspectivas, podemos intuir cómo responder a estas preguntas.</p>
<p>Entendiendo las diferencias, podemos preguntarnos a continuación cuál de dos enfoques es el <em>correcto</em>. Sin embargo, no existe una respuesta correcta. Matemáticamente hablando, no hay nada incorrecto sobre la forma en que los frecuentistas piensan sobre secuencias de eventos, ni hay nada incorrecto acerca de la forma en que los bayesianos definen las creencias de un agente racional. De hecho, si vamos al detalle, los bayesianos y los frecuentistas en realidad están de acuerdo en muchas cosas. Muchos métodos frecuentistas conducen a decisiones que los bayesianos pensarían que toma un agente racional. Muchos métodos bayesianos tienen buenas propiedades frecuentistas.</p>
<p>En su mayor parte, soy bastante pragmático, por lo que usaré cualquier método estadístico en el que tenga confianza. Esto hace que prefiera los métodos bayesianos, pero no me opongo fundamentalmente a los métodos frecuentistas. Sin embargo, no todos son tan flexibles. Por ejemplo, Sir Ronald Fisher, una de las figuras más destacadas de la estadística del siglo XX y un vehemente oponente a todo lo Bayesiano, que su artículo sobre los fundamentos matemáticos de la estadística se refería a la probabilidad Bayesiana como &quot;una jungla impenetrable [que] detiene el progreso hacia la precisión de los conceptos estadísticos&quot; <span class="citation">(<span class="citeproc-not-found" data-reference-id="Fisher1922b"><strong>???</strong></span>)</span>. O el psicólogo Paul Meehl, quien sugiere que confiar en métodos frecuentistas podría convertirte en &quot;un rastrillo intelectual potente pero estéril que deja en su alegre camino un largo tren de doncellas violadas pero sin descendencia científica viable&quot; <span class="citation">(<span class="citeproc-not-found" data-reference-id="Meehl1967"><strong>???</strong></span>)</span>. La historia de la estadística, como puede verse, no está exenta de entretenimiento.</p>
<p>En cualquier caso, aunque personalmente prefiero la visión bayesiana, la mayor parte de los métodos y análisis estadísticos en la literatura se basan en el enfoque frecuentista. Mi razonamiento es pragmático: el objetivo de este curso es cubrir aproximadamente mismo temario que una clase típica de estadística de pregrado en educación, y si quieremos entender las herramientas estadísticas utilizadas por la mayoría de los educadores en investigación, necesitaremos una buena comprensión de los métodos frecuentistas. Pero ignoraré por completo la visión bayesiana. De vez en cuando agregaré comentarios desde un punto de vista bayesiano, y volveré a examinar el tema con más profundidad en el Capítulo <a href="#bayes"><strong>??</strong></a>.</p>
</div>
</div>
<div id="basicprobability" class="section level2">
<h2><span class="header-section-number">1.3</span> Teoría de probabilidad básica</h2>
<p>A pesar de los argumentos ideológicos entre bayesianos y frecuentistas, existe un consenso más o menos generalizado sobre las reglas que la probabilidad debe obedecer. Hay muchas formas de abordar estas reglas. El enfoque más utilizado se basa en el trabajo de Andrey Kolmogorov, uno de los grandes matemáticos soviéticos del siglo XX. No entraré mucho en detalle, pero intentaré mostrar cómo funciona. Y para hacerlo, voy a tener que hablar sobre mis pantalones.</p>
<div id="introducción-a-las-distribuciones-de-probabilidad" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Introducción a las distribuciones de probabilidad</h3>
<p>Un hecho comprobado sobre mi vida es que sólo tengo 5 pares de pantalones: tres pares de vaqueros, los pantalones de un traje y un par de pantalones de chándal. Lo más triste es que les he dado nombres: los llamo <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, <span class="math inline">\(X_3\)</span>, <span class="math inline">\(X_4\)</span> y <span class="math inline">\(X_5\)</span>. Diariamente, por la mañana, elijo un único par de esos pantalones que voy a usar. Si yo tuviera que describir esta situación usando el lenguaje de la teoría de la probabilidad, me referiría a cada par de pantalones (es decir, cada <span class="math inline">\(X\)</span>) como un <strong><em>evento elemental</em></strong>. La característica clave de estos eventos elementales es que cada vez que hacemos una observación (por ejemplo, cada vez que escojo un par de pantalones), el resultado será uno y solo uno de estos eventos. Como he dicho antes, siempre uso exactamente sólo un par de pantalones, así que mis pantalones cumplen con esta restricción. Del mismo modo, al conjunto de todos los eventos posibles se le denomina <strong><em>espacio muestral</em></strong>. Siguiendo con el ejemplo, mi espacio muestral sería el armario que contiene los 5 pantalones.</p>
<p>Bien, ahora que tenemos un espacio muestral (un armario), que está construido a partir de muchas posibles eventos elementales (pantalones), lo que queremos hacer es asignar una <strong><em>probabilidad</em></strong> a uno de estos eventos elementales. Por un evento <span class="math inline">\(X\)</span>, la probabilidad de ese evento <span class="math inline">\(P(X)\)</span> es un número que se encuentra entre 0 y 1. Cuanto mayor sea el valor de <span class="math inline">\(P(X)\)</span>, más probable será que ocurra el evento. Entonces, por ejemplo, si <span class="math inline">\(P(X) = 0\)</span>, significa que el evento <span class="math inline">\(X\)</span> es imposible (es decir, nunca uso esos pantalones). Por otro lado, si <span class="math inline">\(P(X) = 1\)</span> significa que el evento <span class="math inline">\(X\)</span> es seguro que ocurra (es decir, siempre uso esos pantalones). Valores de probabilidad intermedios, significan que a veces uso esos pantalones (y a veces no). Por ejemplo, una <span class="math inline">\(P(X) = 0.5\)</span> significa que uso esos pantalones la mitad de las veces.</p>
<p>Llegados a este punto, lo siguiente que debemos entender es que &quot;algo siempre sucede &quot;. Cada vez que me pongo unos pantalones, realmente termino usando esos pantalones. Lo que esto significa en términos probabilísticos, es que las probabilidades de todos los eventos elementales siempre suman 1. Esto se conoce como la <strong><em>ley de probabilidad total</em></strong>. Si se cumplen estos requisitos (tenemos número <span class="math inline">\(X\)</span> de pantalones, cada par con una probabilidad <span class="math inline">\(P(X)\)</span> de usarlos que en total suman 1), entonces lo que tenemos es una <strong><em>distribución de probabilidad</em></strong>.Veamos un ejemplo de distribución de probabilidad</p>
<table>
<thead>
<tr class="header">
<th align="left">Pantalones</th>
<th align="left">Vaqueros.azules</th>
<th align="left">Vaqueros.grises</th>
<th align="left">Vaqueros.negros</th>
<th align="left">Traje.negro</th>
<th align="left">Chándal.azul</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Nombre</td>
<td align="left"><span class="math inline">\(X_1\)</span></td>
<td align="left"><span class="math inline">\(X_2\)</span></td>
<td align="left"><span class="math inline">\(X_3\)</span></td>
<td align="left"><span class="math inline">\(X_4\)</span></td>
<td align="left"><span class="math inline">\(X_5\)</span></td>
</tr>
<tr class="even">
<td align="left">Probabilidad</td>
<td align="left"><span class="math inline">\(P(X_1) = .5\)</span></td>
<td align="left"><span class="math inline">\(P(X_2) = .3\)</span></td>
<td align="left"><span class="math inline">\(P(X_3) = .1\)</span></td>
<td align="left"><span class="math inline">\(P(X_4) = 0\)</span></td>
<td align="left"><span class="math inline">\(P(X_5) = .1\)</span></td>
</tr>
</tbody>
</table>
<p>Cada uno de estos eventos tiene una probabilidad que se encuentra entre 0 y 1, y si sumamos la probabilidad de todos eventos, suman 1. Incluso podemos dibujar un gráfico de barras (ver Sección <a href="#bargraph"><strong>??</strong></a>) para visualizar esta distribución, como se muestra en la Figura <a href="#fig:pantsprob">1.2</a>.</p>
<div class="figure"><span id="fig:pantsprob"></span>
<img src="FdI2_files/figure-html/pantsprob-1.png" alt="Demostración visual de la distribución de probabilidad de los &quot;pantalones&quot;. Existen 5 &quot;eventos elementales&quot;, que se corresponden con los mis 5 pares de pantalones. Cada evento tiene una probabilidad de ocurrir: esta probabilidad es un número entre 0 y 1. La suma de estas probabilidades es 1." width="672" />
<p class="caption">
Figure 1.2: Demostración visual de la distribución de probabilidad de los &quot;pantalones&quot;. Existen 5 &quot;eventos elementales&quot;, que se corresponden con los mis 5 pares de pantalones. Cada evento tiene una probabilidad de ocurrir: esta probabilidad es un número entre 0 y 1. La suma de estas probabilidades es 1.
</p>
</div>
<p>Es importante señalar que la teoría de probabilidades permite hablar acerca de eventos elementales pero también sobre los <strong><em>eventos no elementales</em></strong>. La forma más fácil de ilustrar este concepto es con un ejemplo. Siguiendo con el ejemplo de los pantalones, es perfectamente posible hablar sobre la probabilidad de usar vaqueros. Bajo esta premisa, podemos decir que el evento &quot;yo uso vaqueros&quot; es posible siempre y cuando ocurra alguno de los eventos elementales apropiados; en este caso &quot;vaqueros azules&quot;, &quot;vaqueros negros&quot; o &quot;vaqueros grises&quot;. En términos matemáticos, definimos al evento <span class="math inline">\(E\)</span> &quot;vaqueros&quot; como el conjunto de eventos elementales <span class="math inline">\((X_1, X_2, X_3)\)</span>. Si se produce alguno de estos eventos elementales, también podemos decir que <span class="math inline">\(E\)</span> ha ocurrido. Por lo tanto, podemos decir que la probabilidad <span class="math inline">\(P(E)\)</span> es simplemente la suma de esos tres eventos, así <span class="math display">\[
P(E) = P(X_1) + P(X_2) + P(X_3)
\]</span> y, dado que las probabilidades de los vaqueros azules, grises y negros son respectivamente .5, .3 y .1, la probabilidad total de usar vaqueros es igual a .9.</p>
<p>Todo esto parece obvio y simple. Sin embargo, a partir de estos simples comienzos, es posible construir algunas herramientas matemáticas extremadamente poderosas. En la Tabla <a href="#tab:probrules">1.1</a> se muestran algunas de las otras reglas que deben de cumplirse para poder calcular probabilidades. En este curso no entraremos en detalle con estas reglas, pero es importante conocerlas al menos.</p>
<table>
<caption><span id="tab:probrules">Table 1.1: </span>Algunas reglas básicas que deben cumplir las probabilidades. Realmente no necesitas conocer estas reglas para comprender los análisis de los que hablaremos en el curso, pero son importantes si se quiere entender la teoría de la probabilidad con un poco más de detalle.</caption>
<thead>
<tr class="header">
<th align="left">English</th>
<th align="left">Notation</th>
<th align="left">NANA</th>
<th align="left">Formula</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Not <span class="math inline">\(A\)</span></td>
<td align="left"><span class="math inline">\(P(\neg A)\)</span></td>
<td align="left">=</td>
<td align="left"><span class="math inline">\(1-P(A)\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span></td>
<td align="left"><span class="math inline">\(P(A \cup B)\)</span></td>
<td align="left">=</td>
<td align="left"><span class="math inline">\(P(A) + P(B) - P(A \cap B)\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span></td>
<td align="left"><span class="math inline">\(P(A \cap B)\)</span></td>
<td align="left">=</td>
<td align="left"><span class="math inline">\(P(A|B) P(B)\)</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="binomial" class="section level2">
<h2><span class="header-section-number">1.4</span> La distribución binomial</h2>
<p>Como hemos visto, las distribuciones de probabilidad pueden variar enormemente, por lo que existe un gran número de distribuciones. Sin embargo, no todas son igual de importantes. Las distribuciones más importantes, y de las que hablaremos en este curso son cinco tipos de distribuciones: la distribución binomial, la distribución normal, la distribución <span class="math inline">\(t\)</span>, la distribución <span class="math inline">\(\chi^2\)</span> (&quot;chi-cuadrada&quot;) y la distribución <span class="math inline">\(F\)</span>. Daremos una breve introducción a las cinco, prestando especial atención a las distribuciones binomial y normal. Comenzaremos con la distribución más simple de las cinco, la distribución binomial.</p>
<div id="introducción-al-binomio" class="section level3">
<h3><span class="header-section-number">1.4.1</span> Introducción al binomio</h3>
<p>La teoría de la probabilidad se originó para intentar describir cómo funcionaban los juegos de azar, por lo que parece adecuado que nuestra discusión sobre la <strong><em>distribución binomial</em></strong> involucre una discusión sobre tirar dados y lanzar monedas. Imaginemos el siguiente &quot;experimento&quot;: tengo en mi poder 20 dados iguales de seis caras. En una de las caras de cada dado hay una imagen de una calavera; las otras cinco caras están en blanco. Si tiro los 20 dados, ¿cuál es la probabilidad de que obtenga exactamente 4 calaveras? Asumiendo que los dados son justos, sabemos que la probabilidad de que en un dado salga la calavera es de de 1 en 6; dicho de otra forma, la probabilidad de que salga calavera en un solo dado es de aproximadamente <span class="math inline">\(.167\)</span>. Esta información es suficiente para responder nuestra pregunta anterior, así que veamos cómo se hace.</p>
<p>Primero, pondremos algunos nombres a los eventos y respectiva notación. Dejaremos que <span class="math inline">\(N\)</span> denote el número de dados que tiran en nuestro experimento; a esto se le conoce como el <strong><em>parámetro de tamaño</em></strong> de nuestra distribución binomial. También usaremos <span class="math inline">\(\theta\)</span> para referirnos a la probabilidad de que en un solo dado calavera, una cantidad que generalmente se denomina como la <strong><em>probabilidad de éxito</em></strong> del binomio.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> Finalmente, usaremos <span class="math inline">\(X\)</span> para referirnos a los resultados de nuestro experimento, es decir, la cantidad de calaveras que obtengo cuando lanzo los dados. Dado que el valor real de <span class="math inline">\(X\)</span> se debe al azar, nos podemos referir a ella como una <strong><em>variable aleatoria</em></strong>. En cualquier caso, ahora que tenemos toda esta terminología y notación, podemos usarlo para exponer el problema con mayor precisión. La cantidad que queremos calcular es la probabilidad de que <span class="math inline">\(X = 4\)</span> sabiendo que <span class="math inline">\(\theta = .167\)</span> y <span class="math inline">\(N=20\)</span>. La &quot;forma&quot; general de esto que me interesa calcular podría escribirse como <span class="math display">\[
P(X \ | \ \theta, N)
\]</span> y estamos interesados en el caso específico donde <span class="math inline">\(X=4\)</span>, <span class="math inline">\(\theta = .167\)</span> y <span class="math inline">\(N=20\)</span>. Hace falta un elemento de notación más antes de continuar con la solución del problema. Si yo quiero decir que <span class="math inline">\(X\)</span> se genera aleatoriamente a partir de una distribución binomial con los parámetros <span class="math inline">\(\theta\)</span> y <span class="math inline">\(N\)</span>, la notación que usaría es la siguiente: <span class="math display">\[
X \sim \mbox{Binomial}(\theta, N)
\]</span></p>
<p>Sí, sí. Sé lo que estás pensando: notación, notación, notación. Aunque no utilizaremos las fórmulas para hacer cálculos como, dejaré la fórmula de la distribución binomial en la Tabla <a href="#tab:distformulas">1.2</a>, ya que puede ser útil si se quieren entender temas más avanzados. Por lo pronto, analizaremos como se ve la distribución binomial. La Figura <a href="#fig:binomial1">1.3</a> dibuja la probabilidad binomial para todos los valores posibles de <span class="math inline">\(X\)</span> de nuestro experimento de lanzamiento de dados, partiendo desde <span class="math inline">\(X=0\)</span> (ninguna sale calavera) hasta <span class="math inline">\(X=20\)</span> (salen todas calaveras). Hay que tener en cuenta que esto es básicamente un gráfico de barras, al igual que la gráfica de la &quot;probabilidad de pantalones&quot;de la Figura <a href="#fig:pantsprob">1.2</a>. En el eje horizontal tenemos todos los eventos posibles, y en el eje vertical podemos leer la probabilidad de que ocurra cada uno de esos eventos. Por lo tanto, la probabilidad de que salgan 4 calaveras al tirar 20 dados es de aproximadamente 0,20 (la respuesta exacta es 0,2022036, como veremos en un momento). En otras palabras, esperaría que ese evento suceda aproximadamente el 20% de las veces que se lleve a cabo este experimento.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">include_app</span>(<span class="st">&#39;https://shinyserver.leudave.cloudns.cl/distributions/&#39;</span>, <span class="dt">height =</span> <span class="st">&quot;600px&quot;</span>)</code></pre></div>
<iframe src="https://shinyserver.leudave.cloudns.cl/distributions/?showcase=0" width="672" height="600px">
</iframe>
<table>
<caption><span id="tab:distformulas">Table 1.2: </span>Fórmulas para las distribuciones binomial y normal. En la ecuación de la binomial, <span class="math inline">\(X!\)</span> es una función factorial (es decir, multiplica todos los números enteros de 1 hasta <span class="math inline">\(X\)</span>), y en la de la distribución normal &quot;exp&quot; se refiere a una función exponencial.</caption>
<thead>
<tr class="header">
<th align="left">Binomial</th>
<th align="left">Normal</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(P(X | \theta, N) = \displaystyle\frac{N!}{X! (N-X)!} \theta^X (1-\theta)^{N-X}\)</span></td>
<td align="left"><span class="math inline">\(p(X | \mu, \sigma) = \displaystyle\frac{1}{\sqrt{2\pi}\sigma} \exp \left( -\frac{(X - \mu)^2}{2\sigma^2} \right)\)</span></td>
</tr>
</tbody>
</table>
<div class="figure"><span id="fig:binomial1"></span>
<img src="FdI2_files/figure-html/binomial1-1.png" alt=" La distribución binomial con parámetro de tamaño de $N=20$ y una probabilidad de éxito de $theta = 1/6$. Cada barra vertical representa la probabilidad de un resultado específico (un valor posible de $X$). Ya que esta es una distribución de probabilidad, cada una de las probabilidades debe ser un número entre 0 y 1, y la altura de las barras también deben sumar 1." width="672" />
<p class="caption">
Figure 1.3:  La distribución binomial con parámetro de tamaño de <span class="math inline">\(N=20\)</span> y una probabilidad de éxito de <span class="math inline">\(theta = 1/6\)</span>. Cada barra vertical representa la probabilidad de un resultado específico (un valor posible de <span class="math inline">\(X\)</span>). Ya que esta es una distribución de probabilidad, cada una de las probabilidades debe ser un número entre 0 y 1, y la altura de las barras también deben sumar 1.
</p>
</div>
<!-- ### Trabajar con la distribución binomial en R -->
<!-- Aunque a algunas personas les resulta útil conocer las fórmulas en la Tabla \@ref(tab:distformulas), la mayoría de la gente solo quiere saber cómo usar las distribuciones sin preocuparse demasiado por las matemáticas. Para ese fin, R tiene una función llamado `dbinom()`  que calcula las probabilidades binomiales para nosotros. Los principales argumentos de la función son -->
<!-- - `x`. Este es un número o vector de números, que especifica los resultados cuya probabilidad está intentando calcular. -->
<!-- - `tamaño`. Este es un número que le dice a R el tamaño del experimento. -->
<!-- - `prob`. Esta es la probabilidad de éxito de cualquier prueba en el experimento. -->
<!-- Entonces, para calcular la probabilidad de obtener `x = 4` cráneos, a partir de un experimento de `tamaño = 20` ensayos, en el que la probabilidad de obtener una calavera en cualquier prueba es `prob = 1/6` ...  bueno, el comando que haría el uso es simplemente esto: -->
<!-- ```{r} -->
<!-- dbinom( x = 4, size = 20, prob = 1/6 ) -->
<!-- ```  -->
<!-- Para darle una idea de cómo cambia la distribución binomial cuando modificamos los valores de $\theta$ y $N$, supongamos que en lugar de tirar dados, en realidad estoy lanzando monedas. Esta vez, mi experimento implica lanzar una moneda justa repetidamente, y el resultado que me interesa es la cantidad de caras que observo En este escenario, la probabilidad de éxito es ahora $\theta = 1/2$. Supongamos que tirara la moneda $N=20$  veces. En este ejemplo, he cambiado la probabilidad de éxito, pero mantuve el tamaño del experimento. lo mismo. ¿Qué le hace esto a nuestra distribución binomial? Bueno, como en la figura \@ref(fig:binomial2a)  muestra, el efecto principal de Esto es para cambiar toda la distribución, como era de esperar. De acuerdo, ¿y si lanzamos una moneda $N=100$  veces? Bueno, en ese caso, obtenemos la Figura \@ref(fig:binomial2b). La distribución se mantiene aproximadamente en el medio, pero hay un poco mayor variabilidad en los posibles resultados. -->
<!-- ```{r binomial2a, fig.cap="Dos distribuciones binomiales, que involucran un escenario en el que estoy lanzando una moneda justa, entonces el La probabilidad de éxito subyacente es $theta = 1/2$. En el panel (a), asumimos que estoy lanzando la moneda $N=20$ veces.", echo=FALSE} -->
<!-- # plots the three examples of a binomial distribution -->
<!--    # needed for printing -->
<!--    width <- 8 -->
<!--    height <- 6 -->
<!--    # function to produce a styled binomial plot -->
<!--    binomPlot <- function( n,p, ... ) { -->
<!--        # probabilities of each outcome -->
<!--        out <- 0:n -->
<!--        prob <- dbinom( x=out, size=n, prob=p ) -->
<!--        # plot -->
<!--        plot(  -->
<!--            out, prob, type="h", lwd=3, ylab="Probability",  -->
<!--            frame.plot=FALSE, col=ifelse(colour,emphCol,"black"), ... -->
<!--        ) -->
<!--    } -->
<!--    # coins image #1... -->
<!--    binomPlot( n=20, p=1/2, xlab="Number of heads observed" ) -->
<!-- ``` -->
<!-- ```{r binomial2b, fig.cap="Dos distribuciones binomiales, que involucran un escenario en el que estoy lanzando una moneda justa, entonces el La probabilidad de éxito subyacente es $theta = 1/2$. En el panel (a), asumimos que estoy lanzando la moneda $N=100$ veces.", echo=FALSE} -->
<!-- # plots the three examples of a binomial distribution -->
<!--    # needed for printing -->
<!--    width <- 8 -->
<!--    height <- 6 -->
<!--    # function to produce a styled binomial plot -->
<!--    binomPlot <- function( n,p, ... ) { -->
<!--        # probabilities of each outcome -->
<!--        out <- 0:n -->
<!--        prob <- dbinom( x=out, size=n, prob=p ) -->
<!--        # plot -->
<!--        plot(  -->
<!--            out, prob, type="h", lwd=3, ylab="Probability",  -->
<!--            frame.plot=FALSE, col=ifelse(colour,emphCol,"black"), ... -->
<!--        ) -->
<!--    } -->
<!--    # coins image #2... -->
<!--    binomPlot( n=100, p=1/2, xlab="Number of heads observed" ) -->
<!-- ``` -->
<!-- En este punto, probablemente debería explicar el nombre de la función `dbinom()` Obviamente, el "binom" parte proviene del hecho de que estamos trabajando con la distribución binomial, pero el prefijo "d" es probablemente un poco de misterio En esta sección daré una explicación parcial: específicamente, explicaré por qué hay un prefijo. En cuanto a por qué es una "d" específicamente, tendrá que esperar hasta la siguiente sección. Que está pasando aqui es que R en realidad proporciona *cuatro* funciones en relación con la distribución binomial. Estas cuatro funciones son `dbinom()`, `pbinom()`, `rbinom()` y `qbinom()`,  y cada uno calcula una cantidad diferente de interés. No solo eso, R hace lo mismo para *cada*  distribución de probabilidad que implementa. No importa de qué distribución estás hablando, hay una función `d`, una función `p`, una función `q` y una función `r`. Esto se ilustra en la Tabla \@ref(tab:pdistnames),  utilizando la distribución binomial y la distribución normal como ejemplos. -->
<!-- ```{r pdistnames, echo=FALSE} -->
<!-- knitr::kable(data.frame(stringsAsFactors=FALSE, -->
<!--             What.it.does = c("probability (density) of", -->
<!--                              "cumulative probability of", -->
<!--                              "generate random number from", "q qnorm() qbinom()"), -->
<!--                   Prefix = c("d", "p", "r", "q"), -->
<!--      Normal.distribution = c("dnorm()", "dnorm()", "rnorm()", "qnorm()"), -->
<!--    Binomial.distribution = c("dbinom()", "pbinom()", "rbinom()", "qbinom(") -->
<!-- ), caption= "El sistema de nombres para las funciones de distribución de probabilidad R. Cada distribución de probabilidad implementado en R en realidad está asociado con cuatro funciones separadas, y hay una bastante estandarizada manera de nombrar estas funciones.") -->
<!-- ``` -->
<!-- Echemos un vistazo a lo que hacen las cuatro funciones. En primer lugar, las cuatro versiones de la función requieren para especificar los argumentos `tamaño` y  `prob`: no importa lo que intente hacer que R calcule, debe saber cuáles son los parámetros. Sin embargo, difieren en términos de cuál es el otro argumento y qué la salida es Así que echémosles un vistazo a la vez. -->
<!-- - La forma `d` que ya hemos visto: especifica un resultado particular `x`,  y la salida es la probabilidad de obtener exactamente ese resultado. (la "d" es abreviatura de **_densidad_**,  pero ignore eso por ahora). -->
<!-- - La forma `p` calcula **_probabilidad acumulada_**. Usted especifica un cuantil particular `q`, y le dice la probabilidad de obtener un resultado *menor o igual que* `q`.  -->
<!-- - La forma `q` calcula los **_cuantiles_** de la distribución. Usted especifica un valor de probabilidad  `p`, y da usted el percentil correspondiente. Es decir, el valor de la variable para la cual hay una probabilidad `p` de obtener un resultado inferior a ese valor.  -->
<!-- - La forma `r` es un **_generador de números aleatorios_**: específicamente, genera `n` resultados aleatorios a partir de la distribución. -->
<!-- Esto es un poco abstracto, así que veamos algunos ejemplos concretos. De nuevo, ya hemos cubierto `dbinom()` así que centrémonos en las otras tres versiones. Comenzaremos con `pbinom()`,  y volveremos a los dados del cráneo ejemplo. De nuevo, estoy tirando 20 dados, y cada dado tiene una probabilidad de 1 en 6 de aparecer calaveras. Suponer, sin embargo, que quiero saber la probabilidad de rodar 4 *o menos*  calaveras. Si quisiera, podría usar el Función `dbinom()` para calcular la probabilidad exacta de rodar 0 calaveras, 1 calavera, 2 calaveras, 3 calaveras y 4 cráneos y luego sumar estos, pero hay una manera más rápida. En cambio, puedo calcular esto usando el `pbinom()` función. Aquí está el comando: -->
<!-- ```{r} -->
<!-- pbinom( q= 4, size = 20, prob = 1/6) -->
<!-- ``` -->
<!-- En otras palabras, hay un 76.9\% de posibilidades de que ruede 4 o menos calaveras. O, para decirlo de otra manera, R es diciéndonos que un valor de 4 es en realidad el percentil 76.9 de esta distribución binomial. -->
<!-- A continuación, consideremos la función `qbinom()`. Digamos que quiero calcular el percentil 75 de la Distribución binomial. Si nos quedamos con nuestro ejemplo de calaveras, usaría el siguiente comando para hacer esto: -->
<!-- ```{r} -->
<!-- qbinom( p = 0.75, size = 20, prob = 1/6) -->
<!-- ``` -->
<!-- Hm. Algo extraño está sucediendo aquí. Pensemos esto detenidamente. Lo Qué aparece la función `qbinom()` para decirnos es que el percentil 75 de la distribución binomial es 4, aunque vimos de la función `pbinom()` que 4 es en *realidad* el percentil 76.9. Y definitivamente es la función `pbinom()` eso es correcto. Lo prometo. La rareza aquí proviene del hecho de que nuestra distribución binomial no *realmente*  tengo un percentil 75. Realmente no. Por qué no? Bueno, hay un 56.7\% de posibilidades de obtener 3 o menos cráneos (puede escribir `pbinom(3, 20, 1/6)` para confirmar esto si lo desea), y un 76.9\%  de posibilidades de obtener 4 o menos cráneos. Entonces, hay un sentido en el que el percentil 75 debe estar "entre" 3 y 4 cráneos. ¡Pero eso no tiene ningún sentido! No puedes tirar 20 dados y obtener 3,9 de ellos salen calaveras. Este problema puede manejarse de diferentes maneras: puede informar un valor intermedio (o valor *interpolado*  para usar el nombre técnico) como 3.9, puede redondear hacia abajo (a 3) o puede redondear hacia arriba (a 4). El `qbinom()` la función se redondea hacia arriba: si solicita un percentil que en realidad no existe (como el 75 en este ejemplo), R encuentra el valor más pequeño para el cual el rango de percentil es *al menos* lo que solicitó. En este caso, ya que el percentil 75 "verdadero" (lo que sea que eso signifique) se encuentra en algún lugar entre 3 y 4 calaveras, R redondea y te da una respuesta de 4. Esta sutileza es tediosa, lo admito, pero afortunadamente es solo un problema para distribuciones discretas como el binomio (consulte la Sección \@ref(continuousdiscrete)  para una discusión sobre el continuo versus discreto). Las otras distribuciones de las que hablaré (normal, $t$, $\chi^2$ y $F$) son todas continuas, y entonces R siempre puede devolver un cuantil exacto siempre que lo solicite.   -->
<!-- Finalmente, tenemos el generador de números aleatorios. Para usar la función `rbinom()` especifique cuántos veces R debería "simular" el experimento usando el argumento `n`  y generará resultados aleatorios de la distribución binomial. Entonces, por ejemplo, supongamos que repitiera mi experimento de lanzamiento de dados 100 veces. Podría hacer que R simule los resultados de estos experimentos usando el siguiente comando: -->
<!-- ```{r} -->
<!-- rbinom( n = 100, size = 20, prob = 1/6 ) -->
<!-- ``` -->
<!-- Como puede ver, estos números son más o menos lo que esperaría dada la distribución que se muestra en Figura \@ref(fig:binomial1). La mayoría de las veces ruedo entre 1 y 5 cráneos. Hay muchas sutilezas asociado con la generación de números aleatorios usando una computadora,^[Dado que las computadoras son máquinas deterministas, en realidad no pueden producir un comportamiento verdaderamente aleatorio. En cambio, lo que ellos hacer es aprovechar varias funciones matemáticas que comparten muchas similitudes con la verdadera aleatoriedad. Que es esto significa que cualquier número aleatorio generado en una computadora es *pseudoaleatorios*,  y la calidad de esos números depende sobre el método específico utilizado. Por defecto, R utiliza el método "Mersenne twister". En cualquier caso, puede obtener más información al escribiendo `?Random`,  pero como de costumbre, los archivos de ayuda de R son bastante densos.] pero para los propósitos de este libro nosotros No necesita preocuparse demasiado por ellos. -->
</div>
</div>
<div id="normal" class="section level2">
<h2><span class="header-section-number">1.5</span> La distribución normal</h2>
<p>Si bien la distribución binomial es conceptualmente la distribución más sencilla de entender, no es la más importante. Ese honor le corresponde a la <strong><em>distribución normal</em></strong>, también conocida como &quot;curva de campana&quot; o como &quot;distribución gaussiana&quot; o &quot;campana de Gauss&quot;. Una distribución normal se describe utilizando dos parámetros, la media de la distribución <span class="math inline">\(\mu\)</span> y la desviación estándar de la distribución <span class="math inline">\(\sigma\)</span>. La notación que utilizamos para decir que una variable <span class="math inline">\(X\)</span> se distribuye normalmente es la siguiente: <span class="math display">\[
X \sim \mbox{Normal}(\mu,\sigma)
\]</span> Al igual que con la distribución binomial, he incluido la fórmula para la distribución normal en la tabla <a href="#tab:distformulas">1.2</a>, porque creo que es lo suficientemente importante como para que todos los que aprenden algo de estadística al menos la conozcan, aunque no nos enfoquemos en ella. Del mismo modo, las funciones R para la distribución normal son <code>dnorm()</code>, <code>pnorm()</code>, <code>qnorm()</code> y <code>rnorm()</code>.</p>
<p>Vamos intentar descubrir lo que significa que una variable esté normalmente distribuida. Echemos un vistazo a la Figura <a href="#fig:normdist">1.4</a>, que muestra una distribución normal con media <span class="math inline">\(\mu = 0\)</span> y desviación estándar <span class="math inline">\(\sigma = 1\)</span>. Con un poco de imaginación, podemos apreciar de dónde viene el nombre “curva de campana”. A diferencia de los gráficos sobre la distribución binomial, la imagen de la distribución normal en la Figura <a href="#fig:normdist">1.4</a> muestra una curva suave en lugar de barras &quot;tipo histograma&quot;. Esto no es arbitrario: la distribución normal es continua, mientras que la distribución binomial es discreta. Por ejemplo, en el experimento de tiro de dados de la sección anterior, era posible obtener 3 calaveras o 4 calaveras, mientras que un valor intermedio como 3.9 era imposible de obtener. Este hecho se ve reflejado en la Figura <a href="#fig:binomial1">1.3</a>, donde tenemos una barra ubicada en <span class="math inline">\(X=3\)</span> y otra en <span class="math inline">\(X=4\)</span>, pero entre ellas no hay nada. En cambio, los valores continuos no tienen esta restricción. Por ejemplo, supongamos que estamos hablando del tiempo. La temperatura de un día primavera podría ser de 23 grados, 24 grados, 23.9 grados o cualquier cosa intermedia, ya que la temperatura es una variable continua, por lo que una distribución normal podría ser la herramienta apropiada para describir las diferentes temperaturas en los días de primavera.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<div class="figure"><span id="fig:normdist"></span>
<img src="FdI2_files/figure-html/normdist-1.png" alt=" Distribución normal con media $mu = 0$ y desviación estándar $sigma = 1$. El eje $x$ corresponde con el valor de alguna variable, y el eje $y$ nos dice qué tan probable es que observemos ese valor. Sin embargo, vemos como el eje $y$ se denomina &quot;Densidad de Probabilidad&quot; y no &quot;Probabilidad&quot;. La altura de la curva no representa como tal la probabilidad de observar un valor particular de $x$. Sin embargo, las alturas nos informan sobre qué valores de $x$ son más probables (¡los más altos!)." width="672" />
<p class="caption">
Figure 1.4:  Distribución normal con media <span class="math inline">\(mu = 0\)</span> y desviación estándar <span class="math inline">\(sigma = 1\)</span>. El eje <span class="math inline">\(x\)</span> corresponde con el valor de alguna variable, y el eje <span class="math inline">\(y\)</span> nos dice qué tan probable es que observemos ese valor. Sin embargo, vemos como el eje <span class="math inline">\(y\)</span> se denomina &quot;Densidad de Probabilidad&quot; y no &quot;Probabilidad&quot;. La altura de la curva no representa como tal la probabilidad de observar un valor particular de <span class="math inline">\(x\)</span>. Sin embargo, las alturas nos informan sobre qué valores de <span class="math inline">\(x\)</span> son más probables (¡los más altos!).
</p>
</div>
<p>Con esto en mente, veamos si podemos intuir cómo funciona una distribución normal. En primer lugar, veamos qué es lo que sucede cuando jugamos con los parámetros de la distribución. Con ese fin, la Figura <a href="#fig:normmean">1.5</a> muestra distribuciones normales que tienen medias diferentes, pero la misma desviación estándar. Como es de esperar, todas estas distribuciones tienen la mismo &quot;anchura&quot;. La unica diferencia entre ellas es que se han desplazado hacia la izquierda o hacia la derecha. En todos los demás aspectos son idénticas. Por el contrario, si aumentamos la desviación estándar mientras mantenemos la media constante, el pico de la distribución permanece en el mismo lugar, pero la distribución se amplía, como podemos ver en la Figura <a href="#fig:normsd">1.6</a>. Sin embargo, cuando ampliamos la distribución, la altura del pico disminuye. Esto <em>tiene</em> que suceder: de la misma forma que las alturas de las barras de una distribución binomial discreta tienen que <em>sumar</em> 1, el total del <em>área bajo la curva</em> de una distribución normal debe ser igual a 1.</p>
<div class="figure"><span id="fig:normmean"></span>
<img src="FdI2_files/figure-html/normmean-1.png" alt="Una ilustración de lo que sucede cuando se cambia la media de una distribución normal. La línea sólida representa una distribución normal con media de $mu=4$.  La línea discontinua muestra una distribución normal con una media de $mu=7$.  En ambos casos, la desviación estándar es de $sigma=1$. Vemos como las dos distribuciones tienen la misma forma, pero la distribución con la línea discontinua se desplaza hacia la derecha." width="672" />
<p class="caption">
Figure 1.5: Una ilustración de lo que sucede cuando se cambia la media de una distribución normal. La línea sólida representa una distribución normal con media de <span class="math inline">\(mu=4\)</span>. La línea discontinua muestra una distribución normal con una media de <span class="math inline">\(mu=7\)</span>. En ambos casos, la desviación estándar es de <span class="math inline">\(sigma=1\)</span>. Vemos como las dos distribuciones tienen la misma forma, pero la distribución con la línea discontinua se desplaza hacia la derecha.
</p>
</div>
<div class="figure"><span id="fig:normsd"></span>
<img src="FdI2_files/figure-html/normsd-1.png" alt="Una ilustración de lo que sucede cuando cambia la desviación estándar de una distribución normal. Ambas distribuciones tienen una media de $mu=5$, pero diferentes desviaciones estándar. La línea continua dibuja una distribución con una desviación estándar $sigma=1$, y la línea discontinua la línea muestra una distribución con desviación estándar de $sigma=2$. Como consecuencia, ambas distribuciones están centradas en el mismo lugar, pero la distribución con la  línea discontinua es más ancha que la otra." width="672" />
<p class="caption">
Figure 1.6: Una ilustración de lo que sucede cuando cambia la desviación estándar de una distribución normal. Ambas distribuciones tienen una media de <span class="math inline">\(mu=5\)</span>, pero diferentes desviaciones estándar. La línea continua dibuja una distribución con una desviación estándar <span class="math inline">\(sigma=1\)</span>, y la línea discontinua la línea muestra una distribución con desviación estándar de <span class="math inline">\(sigma=2\)</span>. Como consecuencia, ambas distribuciones están centradas en el mismo lugar, pero la distribución con la línea discontinua es más ancha que la otra.
</p>
</div>
<p>Antes de seguir adelante, quiero señalar una característica importante de la distribución normal. Independientemente de los valores de la media y la desviación estándar, un 68.3% del área de la curva cae dentro de 1 desviación estándar sobre la media. Del mismo modo, el 95.4% de la distribución cae dentro de 2 desviaciones estándar sobre la media, y el 99.7% de la distribución está dentro de 3 desviaciones estándar. Esta idea se ilustra en las Figuras <a href="#fig:sdnorm1">1.7</a> y <a href="#fig:sdnorm2">1.8</a>.</p>
<div class="figure"><span id="fig:sdnorm1"></span>
<img src="FdI2_files/figure-html/sdnorm1-1.png" alt="El área bajo la curva indica la probabilidad de que una observación se encuentre dentro de un rango determinado. Las línea continua traza una distribución normal con media $mu=0$ y desviación estándar $sigma=1$. El área sombreada ilustra el 'área bajo la curva' para dos casos importantes. En el panel a, podemos ver que hay es un  68.3% de probabilidad de que una observación caiga dentro de 1 desviación estándar sobre la media. En el panel b, vemos que existe una probabilidad del 95.4% de que una observación se encuentre dentro de 2 desviaciones estándar sobre la media." width="672" />
<p class="caption">
Figure 1.7: El área bajo la curva indica la probabilidad de que una observación se encuentre dentro de un rango determinado. Las línea continua traza una distribución normal con media <span class="math inline">\(mu=0\)</span> y desviación estándar <span class="math inline">\(sigma=1\)</span>. El área sombreada ilustra el 'área bajo la curva' para dos casos importantes. En el panel a, podemos ver que hay es un 68.3% de probabilidad de que una observación caiga dentro de 1 desviación estándar sobre la media. En el panel b, vemos que existe una probabilidad del 95.4% de que una observación se encuentre dentro de 2 desviaciones estándar sobre la media.
</p>
</div>
<div class="figure"><span id="fig:sdnorm2"></span>
<img src="FdI2_files/figure-html/sdnorm2-1.png" alt="Dos ejemplos más sobre el concepto del 'área bajo la curva'. Existe un 15.9% de probabilidad de que una observación se encuentre 1 desviación estándar o menos por debajo de la media (panel a), y una probabilidad del 34.1% de que una observación sea mayor que una desviación estándar por debajo de la media pero menor que la media (panel b). Si sumamos estos dos valores, obtendremos 15.9% + 34.1% = 50%. Para datos que estén normalmente distribuidos, existe un 50% de probabilidad de que una observación caiga por debajo de la media. Esto implica que existe un 50% de probabilidad de que caiga por encima de la media." width="672" />
<p class="caption">
Figure 1.8: Dos ejemplos más sobre el concepto del 'área bajo la curva'. Existe un 15.9% de probabilidad de que una observación se encuentre 1 desviación estándar o menos por debajo de la media (panel a), y una probabilidad del 34.1% de que una observación sea mayor que una desviación estándar por debajo de la media pero menor que la media (panel b). Si sumamos estos dos valores, obtendremos 15.9% + 34.1% = 50%. Para datos que estén normalmente distribuidos, existe un 50% de probabilidad de que una observación caiga por debajo de la media. Esto implica que existe un 50% de probabilidad de que caiga por encima de la media.
</p>
</div>
<div id="density" class="section level3">
<h3><span class="header-section-number">1.5.1</span> Densidad de probabilidad</h3>
<p>A lo largo de la discusión sobre la distribución normal, ha habido un par de cosas que parecen no tener sentido. Quizás hayas notado que en eje <span class="math inline">\(y\)</span> en estas Figuras se denomina como &quot;Densidad de probabilidad&quot; en lugar de &quot;Probabilidad&quot;. Tal vez notaste que utilizamos <span class="math inline">\(p(X)\)</span> en lugar de <span class="math inline">\(P(X)\)</span> en la fórmula de la distribución normal.</p>
<p>Si utilizamos la Figura y calculamos la probabilidad de <code>x = 1</code>, para una variable normalmente distribuida con <code>media = 1</code> y desviación estándar <code>sd = 0.1</code>, nos arrojará como resultado una probabilidad de 3.99.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dnorm</span>( <span class="dt">x =</span> <span class="dv">1</span>, <span class="dt">mean =</span> <span class="dv">1</span>, <span class="dt">sd =</span> <span class="fl">0.1</span> )</code></pre></div>
<pre><code>## [1] 3.989423</code></pre>
<p>Sin embargo, hemos visto anteriormente que las probabilidades <em>no</em> pueden ser mayores que 1. Entonces, ¿qué es lo que hemos calculado?</p>
<p>Lo que hemos calculado aquí en realidad no es una probabilidad: Para entender qué es ese algo, tenemos que pensar qué es lo que realmente <em>significa</em> decir que <span class="math inline">\(X\)</span> es una variable continua. Digamos que estamos hablando de la temperatura otra vez. El termómetro me dice que hacen 23 grados, pero yo sé que eso no es del todo cierto. No hacen 23 grados <em>exactamente</em>. Quizás sea algo más cercano a los 23.1 grados o, si seguimos, en realidad podrían ser 23.095 grados. Esto es lo que sucede con los valores continuos: nunca se sabe el valor exacto.</p>
<p>Ahora pensemos en lo que esto implica cuando hablamos de probabilidades. Supongamos la temperatura máxima para mañana se toma de una distribución normal con media 23 y desviación estándar 1. ¿Cuál es la probabilidad de que la temperatura sea <em>exactamente</em> 23 grados? La respuesta es &quot;cero&quot;, o posiblemente, &quot;un número tan cercano a cero que bien podría ser cero&quot;. ¿Por qué es esto? Es como intentar tirar un dardo en un tablero de dardos infinitamente pequeño: no importa cuán buena sea tu puntería, nunca acertarás. En la vida real nunca obtendremos el valor exacto de 23. Siempre será 23.1 o 22.99998 o algo así. En en otras palabras, no tiene sentido hablar de la probabilidad de que la temperatura sea exactamente 23 grados. Sin embargo, en el día a día, si el termómetro indica 23 grados pero en realidad hacen 22.9998 grados, probablemente no nos importaría demasiado. Esto es porque en el día a día, &quot;23 grados&quot; por lo general significa algo así como &quot;en algún lugar entre 22.5 y 23.5 grados&quot;. Y aunque no parezca muy importante preguntar por la probabilidad de que la temperatura sea exactamente 23 grados, lo que sí lo parece es preguntar sobre la probabilidad de que la temperatura se encuentre entre 22.5 y 23.5, o entre 20 y 30, o cualquier otro rango de temperaturas en el que estemos interesados.</p>
<p>El objetivo de esta explicación es dejar claro que, cuando hablamos de distribuciones continuas, no tiene sentido hablar sobre la probabilidad de un valor específico. Sin embargo, sí que <em>podemos</em> hablar sobre la probabilidad de que el valor se encuentre dentro de un rango particular de valores. Para encontrar probabilidad asociada con un rango particular, lo que debe hacer es calcular el &quot;área bajo la curva&quot;. Este concepto lo conocemos: en la figura <a href="#fig:sdnorm1">1.7</a>, las áreas sombreadas representan probabilidades genuinas (por ejemplo, la Figura <a href="#fig:sdnorm1">1.7</a> muestra la probabilidad de observar un valor que cae dentro de 1 desviación estándar sobre la media).</p>
<p>Para finalizar, volveremos con la fórmula para <span class="math inline">\(p(x)\)</span> que vimos anteriormente. Los resultados de <span class="math inline">\(p(x)\)</span> no describe una probabilidad, sino una <strong><em>densidad de probabilidad</em></strong>, que en las gráficas corresponde a la altura de la curva. De la misma forma en que las probabilidades son números no-negativos que deben sumar 1, las densidades de probabilidad son números no-negativos que deben integrar a 1 (donde la integral se toma a través de todos los valores posibles de <span class="math inline">\(X\)</span>). Para calcular la probabilidad de que <span class="math inline">\(X\)</span> caiga entre <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> calculamos la integral definida de la función de densidad sobre el rango correspondiente, <span class="math inline">\(\int_a^b p(x) \ dx\)</span>. Se trata simplemente de otra forma de llegar al mismo resultado.</p>
</div>
</div>
<div id="otherdists" class="section level2">
<h2><span class="header-section-number">1.6</span> Otras distribuciones útiles</h2>
<p>La distribución normal es la distribución más utilizada por los estadísticos (por razones que se discutirán en breve), y la distribución binomial es útil muchos escenarios. Sin embargo, existen otros tipos de distribuciones de probabilidad. Revisaremos brevemente 3 de ellas: la distribución <span class="math inline">\(t\)</span>, la distribución <span class="math inline">\(\chi^2\)</span> y la distribución <span class="math inline">\(F\)</span> - La <strong><em>distribución <span class="math inline">\(t\)</span></em></strong> es una distribución continua que se parece mucho a una distribución normal, pero que tiene colas más pesadas (ver Figura) <a href="#fig:tdist">1.9</a>. Esta distribución tiende a surgir en situaciones en las que piensa que los datos siguen una distribución normal, pero no se conoce la media o la desviación estándar.</p>
<div class="figure"><span id="fig:tdist"></span>
<img src="FdI2_files/figure-html/tdist-1.png" alt="Una distribución $t$ con 3 grados de libertad (línea continua). Se asemeja a una distribución normal, pero no es igual (línea discontinua). Ten en cuenta que las &quot;colas&quot; de la distribución $t$ son más &quot;pesadas&quot;  (es decir, se extienden más hacia afuera) que las colas de la distribución normal." width="672" />
<p class="caption">
Figure 1.9: Una distribución <span class="math inline">\(t\)</span> con 3 grados de libertad (línea continua). Se asemeja a una distribución normal, pero no es igual (línea discontinua). Ten en cuenta que las &quot;colas&quot; de la distribución <span class="math inline">\(t\)</span> son más &quot;pesadas&quot; (es decir, se extienden más hacia afuera) que las colas de la distribución normal.
</p>
</div>
<ul>
<li>La <strong><em>distribución <span class="math inline">\(\chi^2\)</span></em></strong> es otra distribución que podemos encontrar con cierta frecuencia. Es habitual encontrarla cuando hacemos análisis de datos categóricos (Capítulo <a href="#chisquare"><strong>??</strong></a>). Los valores de una distribución <span class="math inline">\(\chi^2\)</span> se consiguen al elevar al cuadrado los valores de una variable distribuída normalmente y luego sumarlos (un procedimiento denominado &quot;suma de cuadrados&quot;). Después veremos porqué es útil hacer una &quot;suma de cuadrados&quot;. La apariencia de una distribución <span class="math inline">\(\chi^2\)</span> la puedes encontrar en la Figura <a href="#fig:chisqdist">1.10</a>.</li>
</ul>
<div class="figure"><span id="fig:chisqdist"></span>
<img src="FdI2_files/figure-html/chisqdist-1.png" alt="Una distribución $chi^2$ con 3 grados de libertad. Observa que los valores siempre deben ser mayores que cero (los valores se elevan al cuadrado y se suman), y que la distribución es bastante sesgada (en este caso hacia la izquierda). Estas son las características clave de una distribución chi-cuadrado." width="672" />
<p class="caption">
Figure 1.10: Una distribución <span class="math inline">\(chi^2\)</span> con 3 grados de libertad. Observa que los valores siempre deben ser mayores que cero (los valores se elevan al cuadrado y se suman), y que la distribución es bastante sesgada (en este caso hacia la izquierda). Estas son las características clave de una distribución chi-cuadrado.
</p>
</div>
<ul>
<li>La <strong><em>distribución <span class="math inline">\(F\)</span></em></strong> se parece un poco a la distribución <span class="math inline">\(\chi^2\)</span> y surge cada vez que necesitamos comparar dos distribuciones <span class="math inline">\(\chi^2\)</span> entre sí. Es decir, si queremos comparar dos &quot;sumas de cuadrados&quot; diferentes, nos encontraremos con una distribución <span class="math inline">\(F\)</span>. Aún no hemos visto un ejemplo de todo lo que implica una suma de cuadrados, pero lo veremos en el Capítulo <a href="#anova"><strong>??</strong></a> donde nos encontraremos nuevamente con la distribución <span class="math inline">\(F\)</span>.</li>
</ul>
<div class="figure"><span id="fig:Fdist"></span>
<img src="FdI2_files/figure-html/Fdist-1.png" alt="Una distribución $F$ con 3 y 5 grados de libertad. Cualitativamente hablando,es similar a una distribución de chi-cuadrado, pero por lo general el significado no es el mismo." width="672" />
<p class="caption">
Figure 1.11: Una distribución <span class="math inline">\(F\)</span> con 3 y 5 grados de libertad. Cualitativamente hablando,es similar a una distribución de chi-cuadrado, pero por lo general el significado no es el mismo.
</p>
</div>
<p>Debido a que estas distribuciones están estrechamente relacionadas con la distribución normal y entre sí, y porque se convertirán en las distribuciones importantes al hacer análisis estadísticos inferenciales en este curso, creo que es útil hacer una pequeña demostración de cómo estas distribuciones realmente están relacionadas entre sí. Primero, veamos una variable <code>normal.a</code> que tiene 1000 observaciones aleatorias distribuidas normalmente:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">normal.a &lt;-<span class="st"> </span><span class="kw">rnorm</span>( <span class="dt">n=</span><span class="dv">1000</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span> )  
<span class="kw">print</span>(<span class="kw">head</span>(normal.a))
<span class="kw">hist</span>( normal.a ) </code></pre></div>
<p>La variable <code>normal.a</code> contiene 1000 números que se distribuyen normalmente, y tienen una media de 0 y desviación estándar 1. En la Figura <a href="#fig:variaterelations">1.12</a> podemos ver un histograma con la distribución de los valores organizados por columnas así como una línea negra sólida que representa la distribución verdadera de los datos (es decir, una distribución normal con media 0 y desviación estándar 1). Así podemos comparar los datos recién generados con los de una distribución normal verdadera.</p>
<div class="figure"><span id="fig:variaterelations"></span>
<img src="FdI2_files/figure-html/variaterelations-1.png" alt="A histogram of different distributions with some advanced formatting" width="672" />
<p class="caption">
Figure 1.12: A histogram of different distributions with some advanced formatting
</p>
</div>
<p>En el primer panel de la Figura podemos observar cómo han sido generados muchos valores distribuidos normalmente que luego han sido comparados con la distribución de probabilidad verdadera (línea sólida). Supongamos que queremos una distribución chi-cuadrada con 3 grados de libertad. Como hemos mencionado anteriormente, una distribución chi-cuadrado con <span class="math inline">\(k\)</span> grados de libertad es es el resultado de tomar <span class="math inline">\(k\)</span> variables normalmente distribuidas (con media 0 y desviación estándar 1), elevarlas al cuadrado y sumarlas. Como queremos una distribución de chi-cuadrada con 3 grados de libertad, además de nuestra variable <code>normal.a</code>, necesitamos dos conjuntos más de valores (también distribuidos normalmente). A estas nuevas dos variables las llamaremos <code>normal.b</code> y <code>normal.c</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">normal.b &lt;-<span class="st"> </span><span class="kw">rnorm</span>( <span class="dt">n=</span><span class="dv">1000</span> )  <span class="co"># another set of normally distributed data</span>
normal.c &lt;-<span class="st"> </span><span class="kw">rnorm</span>( <span class="dt">n=</span><span class="dv">1000</span> )  <span class="co"># and another!</span></code></pre></div>
<p>Una vez que tenemos las tres variables, la teoría dice que debemos elevarlos al cuadrado y sumarlos, así</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chi.sq.<span class="dv">3</span> &lt;-<span class="st"> </span>(normal.a)<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>(normal.b)<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>(normal.c)<span class="op">^</span><span class="dv">2</span>  </code></pre></div>
<p>con lo que la variable <code>chi.sq.3</code> resultante deberá contener 1000 observaciones que siguen una distribución de chi-cuadrada con 3 grados de libertad. Visualmente, obtendremos una distribución como en la Figura <a href="#fig:variaterelations">1.12</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>( chi.sq.<span class="dv">3</span> )  </code></pre></div>
<p>Es importante entender este concepto -el hecho de que estas distribuciones están relacionadas la una con la otra-, ya que después nos encontraremos con la distribución chi-cuadrada en el Capítulo <a href="#chisquare"><strong>??</strong></a>.</p>
<p>Podemos extender esta demostración y tratar de entender el origen de la distribución <span class="math inline">\(t\)</span> y la distribución <span class="math inline">\(F\)</span>. Antes, hemos dicho que la distribución <span class="math inline">\(t\)</span> está relacionada con la distribución normal cuando se desconoce la media o la desviación estándar. Sin embargo, existe una relación más precisa entre las distribuciones normal, chi-cuadrada y <span class="math inline">\(t\)</span>. Supongamos que &quot;escalamos&quot; nuestros datos anteriores de la chi-cuadrada al dividirla entre los grados de libertad, así</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">scaled.chi.sq.<span class="dv">3</span> &lt;-<span class="st"> </span>chi.sq.<span class="dv">3</span> <span class="op">/</span><span class="st"> </span><span class="dv">3</span></code></pre></div>
<p>Luego tomamos un nuevo conjunto de variables normalmente distribuidas y las dividimos por (la raíz cuadrada de) nuestra variable chi-cuadrada que tenía <span class="math inline">\(k=3\)</span> grados de libertad, lo cual dará como resultado una distribución <span class="math inline">\(t\)</span> con 3 grados de libertad. Si trazamos el histograma de esta nueva distribución <code>t.3</code>, observaremos algo parecido a la Figura <a href="#fig:variaterelations">1.12</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">normal.d &lt;-<span class="st"> </span><span class="kw">rnorm</span>( <span class="dt">n=</span><span class="dv">1000</span> )                <span class="co"># yet another set of normally distributed data</span>
t.<span class="dv">3</span> &lt;-<span class="st"> </span>normal.d <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>( scaled.chi.sq.<span class="dv">3</span> )  <span class="co"># divide by square root of scaled chi-square to get t</span>
<span class="kw">hist</span> (t.<span class="dv">3</span>)</code></pre></div>
<p>Del mismo modo, podemos obtener una distribución <span class="math inline">\(F\)</span> al dividir dos distribuciones chi-cuadrada escaladas. Supongamos, por ejemplo, que deseamos generar datos a partir de una distribución <span class="math inline">\(F\)</span> con 3 y 20 grados de libertad (es decir, con 3 y 20 variables respectivamente).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chi.sq.<span class="dv">20</span> &lt;-<span class="st"> </span><span class="kw">rchisq</span>( <span class="dv">1000</span>, <span class="dv">20</span>)                 <span class="co"># generate chi square data with df = 20...</span>
scaled.chi.sq.<span class="dv">20</span> &lt;-<span class="st"> </span>chi.sq.<span class="dv">20</span> <span class="op">/</span><span class="st"> </span><span class="dv">20</span>             <span class="co"># scale the chi square variable...</span>
F.<span class="fl">3.20</span> &lt;-<span class="st">  </span>scaled.chi.sq.<span class="dv">3</span>  <span class="op">/</span><span class="st"> </span>scaled.chi.sq.<span class="dv">20</span> <span class="co"># take the ratio of the two chi squares...</span>
<span class="kw">hist</span>( F.<span class="fl">3.20</span> )                                 <span class="co"># ... and draw a picture</span></code></pre></div>
<p>La división de los valores de ambas distribuciones nos da como resultado una nueva variable <code>F.3.20</code> y su distrubución se ilustra en la Figura <a href="#fig:variaterelations">1.12</a>, en conjunto con la distribución <span class="math inline">\(F\)</span> verdadera para <span class="math inline">\(df_1 = 3\)</span> y <span class="math inline">\(df_2 = 20\)</span>.</p>
<p>Hemos visto tres nuevas distribuciones: <span class="math inline">\(\chi^2\)</span>, <span class="math inline">\(t\)</span> y <span class="math inline">\(F\)</span>. Todas son distribuciones continuas, y todas están estrechamente relacionadas con la distribución normal. Hemos hablado un poco poco sobre la naturaleza de esta relación. Sin embargo, la clave no es que tengas una comprensión profunda y detallada de todas estas diferentes distribuciones, ni que recuerdes las relaciones precisas que existen entre ellas. Lo más importante es entender la idea básica de que estas distribuciones están profundamente relacionadas entre sí y a su vez con la distribución normal. Más adelante en el curso nos vamos a encontrar con datos que se distribuyen normalmente, o que al menos suponemos que se distribuyen normalmente. Por lo tanto, si suponemos que nuestros datos se distribuyen normalmente, debemos saber reconocer las distribuciones <span class="math inline">\(\chi^2\)</span>, <span class="math inline">\(t\)</span> y <span class="math inline">\(F\)</span> cuando realicemos análisis de datos.</p>
</div>
<div id="resumen" class="section level2">
<h2><span class="header-section-number">1.7</span> Resumen</h2>
<p>En este capítulo hemos hablado de probabilidad. Hemos hablado de lo que significa la probabilidad y por qué los estadísticos no están muy de acuerdo en lo que significa. Hablamos sobre las reglas que las probabilidades tienen que obedecer. Hemos introducido la idea de una distribución de probabilidad y conocido algunas de las distribuciones de probabilidad más importantes con las que nos podemos encontrar. Los temas han sido los siguientes:</p>
<ul>
<li>Teoría de probabilidad vs estadística (Sección <a href="#probstats">1.1</a>)</li>
<li>Visión frecuenciantista vs visión bayesiana de probabilidad (Sección <a href="#probmeaning">1.2</a>)</li>
<li>Conceptos básicos de la teoría de probabilidad (Sección <a href="#basicprobability">1.3</a>)</li>
<li>Distribución binomial (Sección <a href="#binomial">1.4</a>), distribución normal (sección <a href="#normal">1.5</a>), y otras distribuciones (Sección <a href="#otherdists">1.6</a>)</li>
</ul>
<p>Esto es una simple introducción dentro de un gran tema. La teoría de la probabilidad es una rama de las matemáticas, completamente separada de su aplicación a la estadística y al análisis de datos. Como tales, hay miles de libros escritos sobre el tema y las universidades generalmente ofrecen clases dedicadas por completo a la teoría de la probabilidad. En este capítulo se han descrito cinco distribuciones de probabilidad estándar, pero existen <em>muchas</em> más que esas. Afortunadamente, estas distribuciones bastarán por el momento.</p>
<p>Los conceptos básicos que hemos adquirido en este capítulo servirán como fundamento para los siguientes dos. Existen muchas reglas sobre lo que se nos &quot;permite&quot; decir cuando hacemos inferencia estadística, y muchas de ellas pueden parecer arbitrarias. Sin embargo, veremos que comienzan a tener sentido si entiendemos que existe la distinción bayesiana/frecuentista. Del mismo modo, en el Capítulo <a href="#ttest"><strong>??</strong></a> vamos a hablar sobre la prueba <span class="math inline">\(t\)</span>, y si realmente queremos entender el concepto de la prueba <span class="math inline">\(t\)</span>, el haber entendido qué es y cómo se ve realmente una distribución <span class="math inline">\(t\)</span> nos será de gran ayuda.</p>

</div>
</div>







<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Hay que tener en cuenta que el término &quot;éxito&quot; es bastante arbitrario, y en realidad no implica que el resultado sea algo deseado. Si <span class="math inline">\(\theta\)</span> se refiriera a la probabilidad de que un pasajero se lesione en un accidente de autobús, seguiría siendo una probabilidad de éxito, aunque en realidad no queremos que la gente salga lastimada<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>En la práctica, la distribución normal es tan útil que las personas tienden a usarla incluso cuando la variable no es continua. Siempre que haya suficientes categorías (por ejemplo, respuestas de escala Likert de un cuestionario), suele ser frecuente el uso de la distribución normal.<a href="#fnref2">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["FdI2.pdf", "FdI2.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
