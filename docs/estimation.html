<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 2 Estimando cantidades desconocidas de una muestra | Fundamentos de Investigación II</title>
  <meta name="description" content="Apuntes de la asignatura de Fundamentos de Investigación II" />
  <meta name="generator" content="bookdown 0.12 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 2 Estimando cantidades desconocidas de una muestra | Fundamentos de Investigación II" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.png" />
  <meta property="og:description" content="Apuntes de la asignatura de Fundamentos de Investigación II" />
  <meta name="github-repo" content="negatoscope/FdI2" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 2 Estimando cantidades desconocidas de una muestra | Fundamentos de Investigación II" />
  
  <meta name="twitter:description" content="Apuntes de la asignatura de Fundamentos de Investigación II" />
  <meta name="twitter:image" content="images/cover.png" />

<meta name="author" content="Luis Eudave" />


<meta name="date" content="2020-10-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="probability.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Fundamentos de Investigación II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>1</b> Introducción a la probabilidad</a><ul>
<li class="chapter" data-level="1.1" data-path="probability.html"><a href="probability.html#probstats"><i class="fa fa-check"></i><b>1.1</b> ¿Cómo de diferentes son la probabilidad y la estadística?</a></li>
<li class="chapter" data-level="1.2" data-path="probability.html"><a href="probability.html#probmeaning"><i class="fa fa-check"></i><b>1.2</b> ¿Qué significa la probabilidad?</a><ul>
<li class="chapter" data-level="1.2.1" data-path="probability.html"><a href="probability.html#la-vision-frecuentista"><i class="fa fa-check"></i><b>1.2.1</b> La visión frecuentista</a></li>
<li class="chapter" data-level="1.2.2" data-path="probability.html"><a href="probability.html#la-vision-bayesiana"><i class="fa fa-check"></i><b>1.2.2</b> La visión bayesiana</a></li>
<li class="chapter" data-level="1.2.3" data-path="probability.html"><a href="probability.html#cual-es-la-diferencia-y-quien-tiene-razon"><i class="fa fa-check"></i><b>1.2.3</b> ¿Cuál es la diferencia? ¿Y quién tiene razón?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="probability.html"><a href="probability.html#basicprobability"><i class="fa fa-check"></i><b>1.3</b> Teoría de probabilidad básica</a><ul>
<li class="chapter" data-level="1.3.1" data-path="probability.html"><a href="probability.html#introduccion-a-las-distribuciones-de-probabilidad"><i class="fa fa-check"></i><b>1.3.1</b> Introducción a las distribuciones de probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="probability.html"><a href="probability.html#binomial"><i class="fa fa-check"></i><b>1.4</b> La distribución binomial</a><ul>
<li class="chapter" data-level="1.4.1" data-path="probability.html"><a href="probability.html#introduccion-al-binomio"><i class="fa fa-check"></i><b>1.4.1</b> Introducción al binomio</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="probability.html"><a href="probability.html#normal"><i class="fa fa-check"></i><b>1.5</b> La distribución normal</a><ul>
<li class="chapter" data-level="1.5.1" data-path="probability.html"><a href="probability.html#density"><i class="fa fa-check"></i><b>1.5.1</b> Densidad de probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="probability.html"><a href="probability.html#otherdists"><i class="fa fa-check"></i><b>1.6</b> Otras distribuciones útiles</a></li>
<li class="chapter" data-level="1.7" data-path="probability.html"><a href="probability.html#resumen"><i class="fa fa-check"></i><b>1.7</b> Resumen</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>2</b> Estimando cantidades desconocidas de una muestra</a><ul>
<li class="chapter" data-level="2.1" data-path="estimation.html"><a href="estimation.html#srs"><i class="fa fa-check"></i><b>2.1</b> Muestras, poblaciones y muestreo</a><ul>
<li class="chapter" data-level="2.1.1" data-path="estimation.html"><a href="estimation.html#pop"><i class="fa fa-check"></i><b>2.1.1</b> Definición de una población</a></li>
<li class="chapter" data-level="2.1.2" data-path="estimation.html"><a href="estimation.html#muestras-aleatorias-simples"><i class="fa fa-check"></i><b>2.1.2</b> Muestras aleatorias simples</a></li>
<li class="chapter" data-level="2.1.3" data-path="estimation.html"><a href="estimation.html#la-mayoria-de-las-muestras-no-son-muestras-aleatorias-simples"><i class="fa fa-check"></i><b>2.1.3</b> La mayoría de las muestras no son muestras aleatorias simples</a></li>
<li class="chapter" data-level="2.1.4" data-path="estimation.html"><a href="estimation.html#cuanto-importa-si-no-tiene-una-muestra-aleatoria-simple"><i class="fa fa-check"></i><b>2.1.4</b> ¿Cuánto importa si no tiene una muestra aleatoria simple?</a></li>
<li class="chapter" data-level="2.1.5" data-path="estimation.html"><a href="estimation.html#parametros-poblacionales-y-estadisticos-muestrales"><i class="fa fa-check"></i><b>2.1.5</b> Parámetros poblacionales y estadísticos muestrales</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="estimation.html"><a href="estimation.html#lawlargenumbers"><i class="fa fa-check"></i><b>2.2</b> La ley de los grandes números</a></li>
<li class="chapter" data-level="2.3" data-path="estimation.html"><a href="estimation.html#samplesandclt"><i class="fa fa-check"></i><b>2.3</b> Distribuciones muestrales y el teorema del límite central</a><ul>
<li class="chapter" data-level="2.3.1" data-path="estimation.html"><a href="estimation.html#samplingdists"><i class="fa fa-check"></i><b>2.3.1</b> Distribución muestral de la media</a></li>
<li class="chapter" data-level="2.3.2" data-path="estimation.html"><a href="estimation.html#sampling-distributions-exist-for-any-sample-statistic"><i class="fa fa-check"></i><b>2.3.2</b> Sampling distributions exist for any sample statistic!</a></li>
<li class="chapter" data-level="2.3.3" data-path="estimation.html"><a href="estimation.html#clt"><i class="fa fa-check"></i><b>2.3.3</b> The central limit theorem</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="estimation.html"><a href="estimation.html#pointestimates"><i class="fa fa-check"></i><b>2.4</b> Estimating population parameters</a><ul>
<li class="chapter" data-level="2.4.1" data-path="estimation.html"><a href="estimation.html#estimating-the-population-mean"><i class="fa fa-check"></i><b>2.4.1</b> Estimating the population mean</a></li>
<li class="chapter" data-level="2.4.2" data-path="estimation.html"><a href="estimation.html#estimating-the-population-standard-deviation"><i class="fa fa-check"></i><b>2.4.2</b> Estimating the population standard deviation</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="estimation.html"><a href="estimation.html#ci"><i class="fa fa-check"></i><b>2.5</b> Estimating a confidence interval</a><ul>
<li class="chapter" data-level="2.5.1" data-path="estimation.html"><a href="estimation.html#a-slight-mistake-in-the-formula"><i class="fa fa-check"></i><b>2.5.1</b> A slight mistake in the formula</a></li>
<li class="chapter" data-level="2.5.2" data-path="estimation.html"><a href="estimation.html#interpreting-a-confidence-interval"><i class="fa fa-check"></i><b>2.5.2</b> Interpreting a confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="estimation.html"><a href="estimation.html#summary"><i class="fa fa-check"></i><b>2.6</b> Summary</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de Investigación II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="estimation" class="section level1">
<h1><span class="header-section-number">Capítulo 2</span> Estimando cantidades desconocidas de una muestra</h1>
<p>Al comienzo del capítulo inicial, vimos la distinción que existe entre la <em>estadística descriptiva</em> y la <em>estadística inferencial</em>. El papel de la estadística descriptiva es resumir de manera concisa lo que <em>ya sabemos</em>. Por otro lado, el propósito de la estadística inferencial es “aprender lo que no sabemos a partir de lo que hacemos”. Ahora que tenemos cierto conocimiento sobre la teoría de la probabilidad, podemos pensar en el problema de la inferencia estadística. ¿Qué tipo de información nos gustaría conocer o aprender? ¿Y cómo lo aprendemo? Estas son las preguntas que se encuentran en el corazón de la estadística inferencial y tradicionalmente se dividen en dos “grandes ideas”: la estimación y la prueba o contraste de hipótesis. El objetivo de este capítulo es presentar la primera de estas grandes ideas, la teoría de la estimación. Pero antes, hablaré sobre la teoría del muestreo, ya que la teoría de la estimación no tiene sentido hasta que no se comprende el muestreo. Como consecuencia, este capítulo se divide en dos partes, las secciones <a href="estimation.html#srs">2.1</a> a <a href="estimation.html#samplesandclt">2.3</a> se centran en la teoría del muestreo, y las secciones <a href="estimation.html#pointestimates">2.4</a> y <a href="estimation.html#ci">2.5</a> hacen uso de esa teoría del muestreo para discutir cómo piensan los estadísticos sobre la estimación.</p>
<div id="srs" class="section level2">
<h2><span class="header-section-number">2.1</span> Muestras, poblaciones y muestreo</h2>
<p>Antes hemos hablado sobre el proceso de inducción inferencial, donde recalcamos que <em>todo</em> aprendizaje (o aquello que queremos llegar a conocer) requiere que hagamos suposiciones. Aceptando que esto es cierto, hemos de aceptar algunas suposiciones generales sobre los datos que hemos adquirido para poder utilizarlos. Aquí es donde entra en juego la <strong><em>teoría del muestreo</em></strong>. Si la teoría de la probabilidad representa los cimientos sobre los que se construye toda la teoría estadística, la teoría del muestreo es el marco alrededor del cual se puede construir el resto de la casa. La teoría del muestreo juega un papel muy importante en la especificación de los supuestos en los que se basan sus inferencias estadísticas. Y para hablar sobre “hacer inferencias” de la forma en que los estadísticos lo piensan, debemos ser un poco más explícitos acerca de <em>qué</em> es lo que estamos extrayendo (la muestra) y <em>sobre qué</em> es de lo que estamos haciendo inferencias (la población).</p>
<p>En casi todas las situaciones de interés, lo que tenemos a nuestra disposición como investigadores es una <em>muestra</em> de datos. Podríamos, por ejemplo, haber realizado un experimento con un cierto número de participantes; una empresa de encuestas podría haber telefoneado a algunas personas para hacer preguntas sobre las intenciones de voto, etc. Independientemente de cual sea el caso, el conjunto de datos disponibles que tengamos es finito e incompleto. No podemos conseguir que todas las personas del mundo realicen nuestro experimento; una empresa de encuestas no tiene el tiempo ni el dinero para llamar a todos los votantes del país, etc. Para la estadística descriptiva esta muestra es lo único que importa. Con la estadística inferencial daremos un paso más allá.</p>
<div id="pop" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Definición de una población</h3>
<p>Una muestra es una cosa muy concreta. Puedes abrir un archivo de Excel y ahí podrás encontrar los datos de una muestra. Una <strong><em>población</em></strong>, por otro lado, es una idea más abstracta. Se refiere al conjunto de todas las personas posibles, o todas las observaciones posibles, sobre las que desea sacar conclusiones y, en general, es <em>mucho</em> más grande que la muestra. En un mundo ideal, el investigador comenzaría el estudio con una idea clara de cuál es la población de interés, ya que el proceso de diseñar un estudio y probar una hipótesis sobre los datos que produce depende de la población sobre la que se quiere hacer declaraciones. Sin embargo, en la práctica esto no sucede siempre: por lo general, el investigador tiene una idea bastante vaga de lo que es la población y diseña el estudio lo mejor que puede sobre esa base.</p>
<p>A veces es fácil indicar cuál es la población de interés. En el ejemplo de la “empresa de encuestas” que vimos en el capítulo anterior, la población consistía en todos los votantes inscritos en un momento del estudio: varios millones de personas. En cambio, la muestra fue un conjunto de 1000 personas que pertenecen todas a esa población. Sin embargo, en la mayoría de los casos, esta definición muestra/población no es tan fácil. En estudios o experimentos con seres humanos, determinar la población de interés es un poco más complicado. Supongamos que realizo un experimento con 100 estudiantes de pregrado que representan mi muestra. Mi objetivo es, por ejemplo, intentar aprender algo sobre cómo una intervención modifica la dinámica de una clase. Tomando en cuento a la muestra que tenemos, ¿cuál de las siguientes opciones contará como “la población”?:</p>
<ul>
<li>¿Todos los estudiantes de educación de la Universidad de Navarra?<br />
</li>
<li>¿Estudiantes de grado en educación en general, de cualquier parte del mundo?<br />
</li>
<li>¿Españoles vivos actualmente?<br />
</li>
<li>¿Españoles de edades similares a las de mi muestra?</li>
<li>¿Hispanoparlantes?</li>
<li>¿Cualquier persona viva actualmente?<br />
</li>
<li>¿Cualquier ser humano, pasado, presente o futuro?</li>
</ul>
<p>Cada una de estas opciones define un grupo real de personas, las cuales podrían ser todas de interés para mí como investigador en educación, y no es tan obvio cuál debería ser la verdadera población de interés.</p>
</div>
<div id="muestras-aleatorias-simples" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Muestras aleatorias simples</h3>
<div class="figure"><span id="fig:srs1"></span>
<img src="img/estimation/srs1.png" alt="Simple random sampling without replacement from a finite population" width="463" />
<p class="caption">
Figure 2.1: Simple random sampling without replacement from a finite population
</p>
</div>
<p>Independientemente de cómo definamos a una población, la clave es que la muestra es un subgrupo de esa población, y nuestro objetivo es utilizar nuestro conocimiento de la muestra para hacer inferencias sobre las propiedades de la población. La relación que exista entre los dos dependerá del <em>procedimiento</em> mediante el cual se seleccionó la muestra. Este procedimiento se conoce como <strong><em>método de muestreo</em></strong> y es importante comprender su importancia.</p>
<p>Pongamos un ejemplo sencillo. Imaginemos que tenemos una bolsa que contiene 10 fichas. Cada ficha tiene una letra única impresa, por lo que la podemos distinguir de entre las otras 10 fichas. Las fichas vienen en dos colores, blanco y negro. Este conjunto de fichas es la población de interés y se muestra gráficamente a la izquierda de la Figura <a href="estimation.html#fig:srs1">2.1</a>. Como podrás ver en la imagen, tenemos 4 fichas negras y 6 fichas blancas, pero recuerda que en la vida real esto no lo sabríamos a menos que miráramos en la bolsa. Ahora imagina que realizas el siguiente “experimento”: agitas la bolsa, cierras los ojos y sacas 4 fichas sin devolver ninguna de ellas a la bolsa. Primero sale la ficha <span class="math inline">\(a\)</span> (negra), seguida de la ficha <span class="math inline">\(c\)</span> (blanca), luego la <span class="math inline">\(j\)</span> (blanca) y finalmente la ficha <span class="math inline">\(b\)</span> (negra). Una vez extraídas 4 fichas, podrás volver a poner todas las fichas en la bolsa y repetir el experimento, como se muestra en el lado derecho de la Figura <a href="estimation.html#fig:srs1">2.1</a>. Cada vez que repites el experimento obtienes resultados diferentes, pero el procedimiento es idéntico en cada caso. El hecho de que el mismo procedimiento pueda dar lugar a resultados diferentes cada vez, lo define como un proceso <em>aleatorio</em>. Y debido a que hemos agitado la bolsa antes de sacar las fichas, parece razonable pensar que todas las fichas tienen las mismas posibilidades de ser seleccionadas. Un procedimiento en el que todos los miembros de la población tienen las mismas posibilidades de ser seleccionados se denomina <strong><em>muestra aleatoria simple</em></strong>. El hecho de que se <em>no</em> se devuelvan las fichas a la bolsa después de salir, significa que no podremos observar la misma ficha dos veces, y en tales casos se dice que ha habido un muestreo <strong><em>sin reemplazo</em></strong>.</p>
<p>Para comprender la importancia del procedimiento de muestreo, consideremos ahora una forma alternativa en la que podría haberse realizado el experimento. Supongamos que mi sobrino de 3 años coge la bolsa y decide sacar las cuatro fichas negras (le gusta el color negro) sin devolverlas la bolsa. Este esquema de muestreo <em>sesgado</em> se muestra en la Figura <a href="estimation.html#fig:brs">2.2</a>. Ahora considera el valor que tiene obtener una muestra con 4 fichas negras y 0 fichas blancas siguiendo el procedimiento de mi sobrino. Vemos pues, como el valor dependerá mucho del método de muestreo. Si sabemos que el método de muestreo está sesgado para seleccionar únicamente fichas negras, entonces una muestra que consta únicamente de fichas negras no dice mucho sobre nuestra población de fichas. Por esta razón, los estadísticos prefieren que un conjunto de datos provenga de una muestra aleatoria simple, ya que facilita <em>mucho</em> el análisis de los datos.</p>
<div class="figure"><span id="fig:brs"></span>
<img src="img/estimation/brs.png" alt="Biased sampling without replacement from a finite population" width="461" />
<p class="caption">
Figure 2.2: Biased sampling without replacement from a finite population
</p>
</div>
<div class="figure"><span id="fig:srs2"></span>
<img src="img/estimation/srs2.png" alt="Simple random sampling *with* replacement from a finite population" width="466" />
<p class="caption">
Figure 2.3: Simple random sampling <em>with</em> replacement from a finite population
</p>
</div>
<p>Vale la pena mencionar un tercer procedimiento. Esta vez cerramos los ojos, agitamos la bolsa y sacamos una ficha. Sin embargo, esta vez registramos la observación y luego volvemos a poner la ficha dentro de la bolsa. Nuevamente, cerramos los ojos, agitamos la bolsa y sacamos otra ficha. Repetimos este procedimiento hasta que tengamos 4 fichas. Los conjuntos de datos que hemos generado de esta manera siguen siendo muestras aleatorias simples, pero debido a que volvemos a meter las fichas dentro de la bolsa inmediatamente después de haberlas sacado, se denomina como una muestra <strong><em>con reemplazo</em></strong>. La diferencia entre este caso y el primero es que es posible observar al mismo elemento de la población varias veces (en este caso la misma ficha), tal como se ilustra en la Figura <a href="estimation.html#fig:srs2">2.3</a>.</p>
<p>Por lo general, la mayoría de los experimentos que veamos en ciencias de la educación tienden a tomar muestras sin reemplazo, ya que la misma persona no puede participar en el experimento dos veces. Sin embargo, una gran parte de la teoría estadística se basa en el supuesto de que los datos surgen de una muestra aleatoria simple <em>con</em> reemplazo. En la vida real, esto rara vez importa. Si la población de interés es grande, la diferencia entre el muestreo con y sin reemplazo es demasiado pequeña como para preocuparnos. Sin embargo, la diferencia que existe entre muestras aleatorias simples y muestras sesgadas no es algo no es aglo que podemos ignorar tan facilmente.</p>
</div>
<div id="la-mayoria-de-las-muestras-no-son-muestras-aleatorias-simples" class="section level3">
<h3><span class="header-section-number">2.1.3</span> La mayoría de las muestras no son muestras aleatorias simples</h3>
<p>Si miras la lista anterior de posibles poblaciones, te darás cuenta que es casi imposible obtener una muestra aleatoria simple de la mayoría de esas poblaciones de interés. Cuando hacemos experimentos con estudiantes universitarios, el obtener una verdadera muestra aleatoria de estos estudiantes los podemos considerar como un milagro menor, aunque al final se trate de una población muy específica a partir de la cual generalizar. Mencionaré brevemente algunos de los otros tipos de muestreo que existen y que solemos encontrar con bastante frecuencia:</p>
<ul>
<li><p><em>Muestreo estratificado</em>. Supongamos que tu población está (o puede estar) dividida en varias subpoblaciones o <em>estratos</em> diferentes. Quizás sea porque estás realizando un estudio en varios paises diferentes, por ejemplo. En lugar de intentar tomar una muestra aleatoria de toda la población en su conjunto, recolectamos una muestra aleatoria de cada uno de las subpoblaciones o estratos. El muestreo estratificado suele ser más fácil de llevar a cabo que el muestreo aleatorio simple, especialmente cuando la población ya está dividida en los distintos estratos. También puede ser más eficiente que el muestreo aleatorio simple, especialmente cuando algunas de las subpoblaciones son raras o poco frecuentes. Por ejemplo, en el estudio de la esquizofrenia, resulta más sencillo dividir la población en dos estratos (con-esquizofrenia y sin-esquizofrenia) y adquirir una muestra de cada grupo. Si seleccionaramos personas al azar, obtendríamos tan pocas personas con esquizofrenia en la muestra que el estudio resultaría inútil.</p></li>
<li><p><em>Muestreo de bola de nieve</em>. Es una técnica que es especialmente útil cuando se toman muestras de una población “oculta” o de difícil acceso, y es especialmente común en las ciencias sociales. Por ejemplo, supongamos que los investigadores quieren realizar una encuesta de opinión a personas VIH positivo. Es posible que el equipo de investigación solo tenga los datos de contacto de algunas personas VIH positivo, por lo que la encuesta comienza pidiéndoles a esas personas que participen (etapa 1). Al final de la encuesta, se pide a los participantes que proporcionen los datos de contacto de otras personas que podrían querer participar. En la etapa 2, se encuesta a estos nuevos contactos. El proceso continúa hasta que los investigadores obtengan datos suficientes. La gran ventaja del muestreo de bola de nieve es que es capaz de proporcionar datos en situaciones que de otro modo serían imposibles de obtener. Desde el punto de vista estadístico, la principal desventaja es que la muestra es altamente no aleatoria y no aleatoria en formas que son difíciles de abordar.</p></li>
<li><p><em>Muestreo de conveniencia</em>. En este tipo de muestreo las muestras se eligen de una forma conveniente para el investigador, sin que exista una selección al azar a partir de la población de interés. El muestreo de bola de nieve es un tipo de muestreo de conveniencia, pero hay muchos otros. Un ejemplo son los estudios que se basan en estudiantes de universitarios. Estas muestras generalmente no son aleatorias desde dos puntos de vista: en primer lugar, depender de una muestra de estudiantes universitarios significa automáticamente que estos datos están restringidos a una sola subpoblación. En segundo lugar, los estudiantes suelen elegir los estudios en los que participan, por lo que la muestra es un subconjunto de estudiantes autoseleccionado, no un subconjunto seleccionado al azar. En general, la mayoría de los estudios incluyen muestras de conveniencia de una forma u otra. A veces, puede suponer una limitación en la interpretación de los resultados, pero no siempre.</p></li>
</ul>
</div>
<div id="cuanto-importa-si-no-tiene-una-muestra-aleatoria-simple" class="section level3">
<h3><span class="header-section-number">2.1.4</span> ¿Cuánto importa si no tiene una muestra aleatoria simple?</h3>
<p>Hemos visto que en muchos casos no es posible recolectar muestras aleatorias simples. ¿Eso qué impacto tiene? Un ejemplo de ese impacto lo podemos apreciar con la diferencia que existe entre las Figuras <a href="estimation.html#fig:srs1">2.1</a> y <a href="estimation.html#fig:brs">2.2</a>. Sin embargo, no es tan malo como parece. Algunos tipos de muestras sesgadas no representan ningún problema. Por ejemplo, cuando utilizamos el muestreo estratificado, realmente sabemos <em>cuál</em> es el sesgo ya que lo hemos creado deliberadamente, con la intención de <em>aumentar</em> la efectividad de su estudio, y existen técnicas estadísticas que podemos utilizar para ajustar estos sesgos que hemos introducido. En estos casos, por lo tanto, no tenemos un problema.</p>
<p>Sin embargo, es importante recordar que el muestreo aleatorio es un medio para un fin, no el fin en sí mismo. Supongamos que recolectamos una muestra de conveniencia y, como tal, podemos asumir que está sesgada. Un sesgo en el método de muestreo solo es un problema si nos hace sacar conclusiones equivocadas. Desde esta perspectiva, podemos afirmar que no necesitamos que la muestra sea aleatoria en <em>todos</em> los aspectos: necesitamos que sea aleatoria con respecto al fenómeno de interés que buscamos estudiar. Supongamos que estoy haciendo un estudio sobre la capacidad de atención sostenida en niños de 6 años. En el estudio 1, tengo la capacidad de tomar muestras al azar de todos los niños de 6 años del mundo actualmente vivos, con una pequeña excepción: sólo puedo incluir niños nacidos en lunes. En el estudio 2, puedo tomar una muestra al azar de la población española. Con estos estudios quiero generalizar mis resultados a la población de todos los niños de 6 años. ¿Qué estudio es mejor? La respuesta, obviamente, es el estudio 1. ¿Por qué? Porque no tenemos ninguna razón para pensar que “nacer en lunes” influye en la capacidad de atención sostenida. Por otro lado, puedo pensar en varias razones por las que “ser español” podría ser importante. España es un país rico e industrializado con un sistema educativo muy desarrollado. Las personas que crecieron con este sistema habrán tenido experiencias de vida mucho más similares a las experiencias de vida de las personas que diseñaron las pruebas de capacidad de atención sostenida. Esta experiencia compartida podría traducirse fácilmente en creencias similares sobre cómo se debe “realizar una prueba”, entre otros. Este tipo de características son importantes y pueden, por ejemplo, llevar a una imagen engañosa de lo que es la capacidad atención sostenida.</p>
<p>Existe un reflexión clave oculta en esta discusión. Al diseñar estudios, es importante pensar en la población de interés y en esforzarse por elegir un método de muestreo que sea apropiado para esa población. En la práctica, muchas veces nos veremos obligados a utilizar una “muestra de conveniencia” (por ejemplo, estudiantes de unos pocos centros), pero deberíamos, al menos, dedicar un tiempo a pensar en los riesgos e implicaciones de esta práctica.</p>
</div>
<div id="parametros-poblacionales-y-estadisticos-muestrales" class="section level3">
<h3><span class="header-section-number">2.1.5</span> Parámetros poblacionales y estadísticos muestrales</h3>
<p>Hasta ahora hemos estado hablando de poblaciones como lo haría un científico. Para un educador, una población puede ser un grupo de niños. Para un ecologista, una población puede ser un grupo de osos. En la mayoría de los casos, las poblaciones son cosas concretas que realmente existen en el mundo real. Los estadísticos, sin embargo, tienen un interés dual. Por un lado, <em>están</em> interesados en los datos del mundo real de la misma forma que los científicos. Por otro lado, también operan en el ámbito de la abstracción pura como lo hacen los matemáticos. En consecuencia, la teoría estadística puede ser un poco abstracta cuando define una población. Para ello, los estadísticos operacionalizan el concepto de “población” en términos de objetos matemáticos los cuales ya conocemos: se llaman distribuciones de probabilidad.</p>
<p>La idea es muy simple. Digamos que estamos hablando (otra vez) de puntajes de coeficiente intelectual (CI). Para un educador, la población de interés es un grupo de humanos reales que tienen puntajes de CI. Un estadístico “simplifica” esto al definir operativamente a la población como la distribución de probabilidad representada en la Figura <a href="#fig:IQdista"><strong>??</strong></a>. Las pruebas de CI están <em>diseñadas</em> de tal forma que la media sea 100, que la desviación estándar sea 15 y que la distribución de los puntajes sea normal. Estos valores se denominan <strong><em>parámetros poblacionales</em></strong> porque son característicos de toda la población. Es decir, decimos que la media de la población <span class="math inline">\(\mu\)</span> es 100, y la desviación estándar de la población <span class="math inline">\(\sigma\)</span> es 15.</p>
<div class="figure"><span id="fig:IQdist1"></span>
<img src="FdI2_files/figure-html/IQdist-1.png" alt="Distribución poblacional de los puntajes de CI (Panel A) y dos muestra extraídas de forma aleatoria de esta población. En el Panel B una muestra con 100 observaciones y en el Panel C una muestra con 10,000 observaciones." width="672" />
<p class="caption">
Figure 2.4: Distribución poblacional de los puntajes de CI (Panel A) y dos muestra extraídas de forma aleatoria de esta población. En el Panel B una muestra con 100 observaciones y en el Panel C una muestra con 10,000 observaciones.
</p>
</div>
<div class="figure"><span id="fig:IQdist2"></span>
<img src="FdI2_files/figure-html/IQdist-2.png" alt="Distribución poblacional de los puntajes de CI (Panel A) y dos muestra extraídas de forma aleatoria de esta población. En el Panel B una muestra con 100 observaciones y en el Panel C una muestra con 10,000 observaciones." width="672" />
<p class="caption">
Figure 2.5: Distribución poblacional de los puntajes de CI (Panel A) y dos muestra extraídas de forma aleatoria de esta población. En el Panel B una muestra con 100 observaciones y en el Panel C una muestra con 10,000 observaciones.
</p>
</div>
<pre><code>## [1] &quot;n= 5 mean= 110.798179182835 sd= 14.049847456097&quot;</code></pre>
<div class="figure"><span id="fig:IQdist3"></span>
<img src="FdI2_files/figure-html/IQdist-3.png" alt="Distribución poblacional de los puntajes de CI (Panel A) y dos muestra extraídas de forma aleatoria de esta población. En el Panel B una muestra con 100 observaciones y en el Panel C una muestra con 10,000 observaciones." width="672" />
<p class="caption">
Figure 2.6: Distribución poblacional de los puntajes de CI (Panel A) y dos muestra extraídas de forma aleatoria de esta población. En el Panel B una muestra con 100 observaciones y en el Panel C una muestra con 10,000 observaciones.
</p>
</div>
<pre><code>## [1] &quot;n= 5000 mean= 99.9824886764696 sd= 14.9111378272631&quot;</code></pre>
<p>Supongamos que hacemos un experimento. Seleccionamos 100 personas al azar para que elaboren nuestro test de CI, lo cual me dará una muestra aleatoria de la población. Mi muestra consistirá de una serie de números como estos:</p>
<pre><code>                          106 101 98 80 74 ... 107 72 100</code></pre>
<p>Estos puntajes son una muestra extraída de una población con distribución norma, media de 100 y desviación estándar de 15. Si trazamos un histograma de esta muestra, obtendremos algo como el que se muestra en la Figura <a href="#fig:IQdist"><strong>??</strong></a>b. Podemos ver que el histograma tiene una forma <em>aproximadamente</em> normal, pero aún queda como una aproximación burda de la verdadera distribución de la población que se muestra en la Figura <a href="#fig:IQdist"><strong>??</strong></a>a. Si calculamos la media muestral, obtendremos un número que está bastante cerca de la media de la población 100, pero no es idéntico. En este caso, vemos que las personas de mi muestra tienen un CI medio de 98,5 y la desviación estándar de sus puntuaciones de CI es de 15,9. Estos <strong><em>estadísticos muestrales</em></strong> nos presentan una descripción de nuestro conjunto de datos y, aunque son bastante similares a los valores reales de población, no son iguales. En general, los estadísticos muestrales son lo que podemos calcular a partir de un conjunto de datos mientras que los parámetros poblacionales son las cosas sobre las que deseamos aprender. Más adelante, hablaremos sobre cómo podemos estimar los parámetros poblacionales utilizando sus estadísticos muestrales (Sección <a href="estimation.html#pointestimates">2.4</a>) así como qué tan seguros estamos de esos estimadores (Sección <a href="estimation.html#ci">2.5</a>) pero antes necesitamos conocer algunos conceptos adicionales sobre la teoría de muestreo.</p>
</div>
</div>
<div id="lawlargenumbers" class="section level2">
<h2><span class="header-section-number">2.2</span> La ley de los grandes números</h2>
<p>En la sección anterior vimos los resultados de un experimento ficticio con un tamaño de muestra de <span class="math inline">\(N=100\)</span>. Los resultados fueron algo alentadores: la media real de la población es 100 y la media muestral 98.5, una aproximación razonable. En muchos estudios científicos, este nivel de precisión es perfectamente aceptable, pero existen situaciones en las que nos gustaría ser bastante más precisos. Si queremos que nuestros estadísticos muestrales se acerquen más a los parámetros poblaciones, ¿qué podemos hacer al respecto?</p>
<p>La respuesta lógica sería recolectar más datos. Supongamos que hacemos un experimento más grande, en el cual medimos el CI de 10,000 personas. Si entrás <a href="https://leudave.shinyapps.io/sampling/">aquí</a> podrás hacer una simulación. El histograma de esta simulación se muestra en la Figura <a href="#fig:IQdist"><strong>??</strong></a>c. Una inspección rápida nos revelará que una muestra de mayor tamaño es representa una mucho mejor aproximación la distribución poblacional real, especialmente si la comparamos con la muestra más pequeña. Esto también se ve reflejado en los estadísticos muestrales: el CI medio de la muestra grande es de 99.9 y su desviación estándar es de 15.1. Estos valores son muy cercanos a los valores reales de la población.</p>
<p>Con esto, podemos observar algo que parece obvio: entre más datos tengamos, mejores resultados obtendremos. Esta intuición tan evidente que compartimos todos, los estadísticos la definen como la <strong><em>ley de los grandes números</em></strong>. La ley de los grandes números es una ley matemática que aplica a muchos estadísticos muestrales, pero la forma más sencilla de entenderla es a través de la ley aplicada a las medias. Cuando se aplica a la media muestral, la ley de los grande números nos dice que conforme aumenta el tamaño de muestra, el valor de la media muestral se acercará al valor de la media poblacional real. O, para ser más precisos, conforme el tamaño muestral se aproxima al infinito (escrito como <span class="math inline">\(N \rightarrow \infty\)</span>) la media nuestral se aproximará a la media poblacional (<span class="math inline">\(\bar{X} \rightarrow \mu\)</span>).<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
<p>Espero que quede patente la importancia de la ley de los grandes números como una herramienta elemental en la teoría estadística. Esta ley de los grandes números es nuestro argumento para justificar nuestra creencia de que recolectar cada vez más y más datos nos acercará a la verdad. Para cualquier conjunto de datos, los estadísticos muestrales que calculemos estarán equivocados, pero la ley de los grandes números nos dice que si seguimos recolectando datos esos estadísticos muestrales tenderán a a acerca más y más a los parámetros poblacionales reales.</p>
</div>
<div id="samplesandclt" class="section level2">
<h2><span class="header-section-number">2.3</span> Distribuciones muestrales y el teorema del límite central</h2>
<p>La ley de los grandes números es una herramienta muy poderosa, pero no será suficiente para responder a todas nuestras preguntas. Entre otras cosas, lo que nos da esta ley es una “garantía a largo plazo”. A largo plazo, si pudiéramos recolectar una cantidad infinita de datos, la ley de los grandes números nos garantiza que los estadísticos muestrales serán correctos.</p>
<p>Sin embargo, esta “garantía a largo plazo” es de poca utilidad en la vida real: no basta con decir que <em>con el tiempo</em> llegaremos a la respuesta correcta cuando calculemos la media muestral. Saber que un conjunto de datos infinitamente largo me dará el valor exacto de la media poblacional es inconciliable con el <em>hecho</em> de que mi conjunto de datos tiene un tamaño de muestra de <span class="math inline">\(N=100\)</span>. En la vida real, tenemos que saber algo más sobre el comportamiento de la media muestral de una muestra modesta como la nuestra.</p>
<div id="samplingdists" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Distribución muestral de la media</h3>
<p>Abandonemos por un momento la idea de tener tamaños de muestra de 10,000 y pensemos en un experimento más modesto (y realista). Esta vez extraemos una muestra de <span class="math inline">\(N=5\)</span> personas y medimos su CI. Este es el resultado:</p>
<pre><code>90  82  94  99 110</code></pre>
<p>El CI medio de esta muestra es exactamente 95. Esta muestra nos revela un valor mucho menos preciso que en el experimento previo. Ahora imagina que decides <strong><em>replicar</em></strong> este mismo experimento. Es decir, quieres repetir el mismo procedimiento de tal forma que selecciones una nueva muestra aleatoria de 5 personas y obtener su CI una vez más. Estos son los CI de nuestra nueva muestra:</p>
<pre><code>78  88 111 111 117</code></pre>
<p>Al calcular la media de esta muestra vemos que es de 101. Si repetimos el experimento 10 veces más obtendremos los resultados que se muestran en la Tabla <a href="#tab:replications"><strong>??</strong></a>. Con ella podrás que la media muestra cambia con cada replicación del experimento.</p>
<table>
<thead>
<tr class="header">
<th align="left">.</th>
<th align="right">P1</th>
<th align="right">P2</th>
<th align="right">P3</th>
<th align="right">P4</th>
<th align="right">P5</th>
<th align="right">Media.Muestral</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Rep 1</td>
<td align="right">90</td>
<td align="right">82</td>
<td align="right">94</td>
<td align="right">99</td>
<td align="right">110</td>
<td align="right">95.0</td>
</tr>
<tr class="even">
<td align="left">Rep 2</td>
<td align="right">78</td>
<td align="right">88</td>
<td align="right">111</td>
<td align="right">111</td>
<td align="right">117</td>
<td align="right">101.0</td>
</tr>
<tr class="odd">
<td align="left">Rep 3</td>
<td align="right">111</td>
<td align="right">122</td>
<td align="right">91</td>
<td align="right">98</td>
<td align="right">86</td>
<td align="right">101.6</td>
</tr>
<tr class="even">
<td align="left">Rep 4</td>
<td align="right">98</td>
<td align="right">96</td>
<td align="right">119</td>
<td align="right">99</td>
<td align="right">107</td>
<td align="right">103.8</td>
</tr>
<tr class="odd">
<td align="left">Rep 5</td>
<td align="right">105</td>
<td align="right">113</td>
<td align="right">103</td>
<td align="right">103</td>
<td align="right">98</td>
<td align="right">104.4</td>
</tr>
<tr class="even">
<td align="left">Rep 6</td>
<td align="right">81</td>
<td align="right">89</td>
<td align="right">93</td>
<td align="right">85</td>
<td align="right">114</td>
<td align="right">92.4</td>
</tr>
<tr class="odd">
<td align="left">Rep 7</td>
<td align="right">100</td>
<td align="right">93</td>
<td align="right">108</td>
<td align="right">98</td>
<td align="right">133</td>
<td align="right">106.4</td>
</tr>
<tr class="even">
<td align="left">Rep 8</td>
<td align="right">107</td>
<td align="right">100</td>
<td align="right">105</td>
<td align="right">117</td>
<td align="right">85</td>
<td align="right">102.8</td>
</tr>
<tr class="odd">
<td align="left">Rep 9</td>
<td align="right">86</td>
<td align="right">119</td>
<td align="right">108</td>
<td align="right">73</td>
<td align="right">116</td>
<td align="right">100.4</td>
</tr>
<tr class="even">
<td align="left">Rep 10</td>
<td align="right">95</td>
<td align="right">126</td>
<td align="right">112</td>
<td align="right">120</td>
<td align="right">76</td>
<td align="right">105.8</td>
</tr>
</tbody>
</table>
<p>Supongamos ahora que decidimos continuar con este procedimiento, replicando el experimento de “5 puntuaciones de CI” una y otra vez. Y cada vez, obtendremos una media muestra diferente, que en el caso de los 10 experimentos que ya hemos hecho corresponderían con los siguientes valores:</p>
<pre><code>                      95.0 101.0 101.6 103.8 104.4 ...</code></pre>
<p>¿Qué pasaría si continuamos y recolectamos 10,000 medias muestrales y trazamos un histograma con ellas? Obtendríamos un resultado como el que vemos en la Figura <a href="estimation.html#fig:sampdistmean">2.7</a>. En esta imagen podemos apreciar que la media muestral de 5 puntuaciones de CI se encuentra, por lo general, entre 90 y 110. Pero lo más interesante de esta Figura es que demuestra el hecho de que si repetimos el experimento una y otra vez, ¡lo que obtenemos es una <em>distribución</em> de las medias muestrales! Esta distribución recibe un nombre especial en estadística: se le llama <strong><em>distribución muestral de la media</em></strong>.</p>
<p>La distribuciones muestrales</p>
<p>Las distribuciones muestrales son una idea teórica importante en la estadística, y además, son cruciales si queremos entender cómo se comportan las muestras pequeñas. Por ejempo, cuando realizamos el primer experimento con 5 puntuaciones de CI, la media muestral fue de 95. Sin embargo, lo que la distribución muestral nos dice en la Figura <a href="estimation.html#fig:sampdistmean">2.7</a>, es que este experimento con 5 puntuaciones no es muy preciso. Si repetimos el experimento muchas veces, la distribución muestral nos dice que podemos esperar que la media muestral esté entre 80 y 120.</p>
<div class="figure"><span id="fig:sampdistmean"></span>
<img src="FdI2_files/figure-html/sampdistmean-1.png" alt="La distribución muestral de la media en el experimento con 5 puntuaciones de CI. Si obtenemos una muestra aleatoria de 5 personas y calculamos la *media* de sus puntajes, obtendremos casi con seguridad un valor entre 80 y 120, aunque existen individuos que tienen un CI mayor de 120 o menor de 80. La línea negra dibuja la distribución poblacional de los puntajes de CI para comparar." width="672" />
<p class="caption">
Figure 2.7: La distribución muestral de la media en el experimento con 5 puntuaciones de CI. Si obtenemos una muestra aleatoria de 5 personas y calculamos la <em>media</em> de sus puntajes, obtendremos casi con seguridad un valor entre 80 y 120, aunque existen individuos que tienen un CI mayor de 120 o menor de 80. La línea negra dibuja la distribución poblacional de los puntajes de CI para comparar.
</p>
</div>
</div>
<div id="sampling-distributions-exist-for-any-sample-statistic" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Sampling distributions exist for any sample statistic!</h3>
<p>One thing to keep in mind when thinking about sampling distributions is that <em>any</em> sample statistic you might care to calculate has a sampling distribution. For example, suppose that each time I replicated the “five IQ scores” experiment I wrote down the largest IQ score in the experiment. This would give me a data set that started out like this:</p>
<pre><code>                      110 117 122 119 113 ... </code></pre>
<p>Doing this over and over again would give me a very different sampling distribution, namely the <em>sampling distribution of the maximum</em>. The sampling distribution of the maximum of 5 IQ scores is shown in Figure <a href="#fig:sampdistmax"><strong>??</strong></a>. Not surprisingly, if you pick 5 people at random and then find the person with the highest IQ score, they’re going to have an above average IQ. Most of the time you’ll end up with someone whose IQ is measured in the 100 to 140 range.</p>
</div>
<div id="clt" class="section level3">
<h3><span class="header-section-number">2.3.3</span> The central limit theorem</h3>
<p>An illustration of the how sampling distribution of the mean depends on sample size. In each panel, I generated 10,000 samples of IQ data, and calculated the mean IQ observed within each of these data sets. The histograms in these plots show the distribution of these means (i.e., the sampling distribution of the mean). Each individual IQ score was drawn from a normal distribution with mean 100 and standard deviation 15, which is shown as the solid black line).</p>
<div class="figure"><span id="fig:IQsampa"></span>
<img src="FdI2_files/figure-html/IQsampa-1.png" alt="Each data set contained only a single observation, so the mean of each sample is just one person's IQ score. As a consequence, the sampling distribution of the mean is of course identical to the population distribution of IQ scores." width="672" />
<p class="caption">
Figure 2.8: Each data set contained only a single observation, so the mean of each sample is just one person’s IQ score. As a consequence, the sampling distribution of the mean is of course identical to the population distribution of IQ scores.
</p>
</div>
<div class="figure"><span id="fig:IQsampb"></span>
<img src="FdI2_files/figure-html/IQsampb-1.png" alt="When we raise the sample size to 2, the mean of any one sample tends to be closer to the population mean than a one person's IQ score, and so the histogram (i.e., the sampling distribution) is a bit narrower than the population distribution." width="672" />
<p class="caption">
Figure 2.9: When we raise the sample size to 2, the mean of any one sample tends to be closer to the population mean than a one person’s IQ score, and so the histogram (i.e., the sampling distribution) is a bit narrower than the population distribution.
</p>
</div>
<div class="figure"><span id="fig:IQsampc"></span>
<img src="FdI2_files/figure-html/IQsampc-1.png" alt="By the time we raise the sample size to 10, we can see that the distribution of sample means tend to be fairly tightly clustered around the true population mean." width="672" />
<p class="caption">
Figure 2.10: By the time we raise the sample size to 10, we can see that the distribution of sample means tend to be fairly tightly clustered around the true population mean.
</p>
</div>
<p>At this point I hope you have a pretty good sense of what sampling distributions are, and in particular what the sampling distribution of the mean is. In this section I want to talk about how the sampling distribution of the mean changes as a function of sample size. Intuitively, you already know part of the answer: if you only have a few observations, the sample mean is likely to be quite inaccurate: if you replicate a small experiment and recalculate the mean you’ll get a very different answer. In other words, the sampling distribution is quite wide. If you replicate a large experiment and recalculate the sample mean you’ll probably get the same answer you got last time, so the sampling distribution will be very narrow. You can see this visually in Figures <a href="estimation.html#fig:IQsampa">2.8</a>, <a href="estimation.html#fig:IQsampb">2.9</a> and <a href="estimation.html#fig:IQsampc">2.10</a>: the bigger the sample size, the narrower the sampling distribution gets. We can quantify this effect by calculating the standard deviation of the sampling distribution, which is referred to as the <strong><em>standard error</em></strong>. The standard error of a statistic is often denoted SE, and since we’re usually interested in the standard error of the sample <em>mean</em>, we often use the acronym SEM. As you can see just by looking at the picture, as the sample size <span class="math inline">\(N\)</span> increases, the SEM decreases.</p>
<p>Okay, so that’s one part of the story. However, there’s something I’ve been glossing over so far. All my examples up to this point have been based on the “IQ scores” experiments, and because IQ scores are roughly normally distributed, I’ve assumed that the population distribution is normal. What if it isn’t normal? What happens to the sampling distribution of the mean? The remarkable thing is this: no matter what shape your population distribution is, as <span class="math inline">\(N\)</span> increases the sampling distribution of the mean starts to look more like a normal distribution. To give you a sense of this, I ran some simulations using R. To do this, I started with the “ramped” distribution shown in the histogram in Figure <a href="estimation.html#fig:cltdemo">2.11</a>. As you can see by comparing the triangular shaped histogram to the bell curve plotted by the black line, the population distribution doesn’t look very much like a normal distribution at all. Next, I used R to simulate the results of a large number of experiments. In each experiment I took <span class="math inline">\(N=2\)</span> samples from this distribution, and then calculated the sample mean. Figure <a href="#fig:cltdemob"><strong>??</strong></a> plots the histogram of these sample means (i.e., the sampling distribution of the mean for <span class="math inline">\(N=2\)</span>). This time, the histogram produces a <span class="math inline">\(\cap\)</span>-shaped distribution: it’s still not normal, but it’s a lot closer to the black line than the population distribution in Figure <a href="#fig:cltdemoa"><strong>??</strong></a>. When I increase the sample size to <span class="math inline">\(N=4\)</span>, the sampling distribution of the mean is very close to normal (Figure <a href="#fig:cltdemoc"><strong>??</strong></a>, and by the time we reach a sample size of <span class="math inline">\(N=8\)</span> it’s almost perfectly normal. In other words, as long as your sample size isn’t tiny, the sampling distribution of the mean will be approximately normal no matter what your population distribution looks like!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">    <span class="co"># needed for printing</span>
    width &lt;-<span class="st"> </span><span class="dv">6</span>
    height &lt;-<span class="st"> </span><span class="dv">6</span> 
    
    <span class="co"># parameters of the beta</span>
    a &lt;-<span class="st"> </span><span class="dv">2</span>
    b &lt;-<span class="st"> </span><span class="dv">1</span>
    
    <span class="co"># mean and standard deviation of the beta</span>
    s &lt;-<span class="st"> </span><span class="kw">sqrt</span>( a<span class="op">*</span>b <span class="op">/</span><span class="st"> </span>(a<span class="op">+</span>b)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(a<span class="op">+</span>b<span class="op">+</span><span class="dv">1</span>) )
    m &lt;-<span class="st"> </span>a <span class="op">/</span><span class="st"> </span>(a<span class="op">+</span>b)
    
    <span class="co"># define function to draw a plot</span>
    plotOne &lt;-<span class="st"> </span><span class="cf">function</span>(n,<span class="dt">N=</span><span class="dv">10000</span>) {
        
        <span class="co"># generate N random sample means of size n</span>
        X &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rbeta</span>(n<span class="op">*</span>N,a,b),n,N)
        X &lt;-<span class="st"> </span><span class="kw">colMeans</span>(X)
        
        <span class="co"># plot the data</span>
        <span class="kw">hist</span>( X, <span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,.<span class="dv">025</span>), <span class="dt">border=</span><span class="st">&quot;white&quot;</span>, <span class="dt">freq=</span><span class="ot">FALSE</span>,
            <span class="dt">col=</span><span class="kw">ifelse</span>(colour,emphColLight,emphGrey),
            <span class="dt">xlab=</span><span class="st">&quot;Media muestral&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;&quot;</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">1.2</span>),
            <span class="dt">main=</span><span class="kw">paste</span>(<span class="st">&quot;Tamaño de la muestra =&quot;</span>,n), <span class="dt">axes=</span><span class="ot">FALSE</span>,
            <span class="dt">font.main=</span><span class="dv">1</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">12</span>)
        )
        <span class="kw">box</span>()
        <span class="kw">axis</span>(<span class="dv">1</span>)
        <span class="co">#axis(2)</span>
        
        <span class="co"># plot the theoretical distribution</span>
        <span class="kw">lines</span>( x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="fl">1.2</span>,.<span class="dv">01</span>), <span class="kw">dnorm</span>(x,m,s<span class="op">/</span><span class="kw">sqrt</span>(n)), 
            <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>
        )
    }
    
    <span class="cf">for</span>( i <span class="cf">in</span> <span class="kw">c</span>(<span class="dv">50</span>)) {
        <span class="kw">plotOne</span>(i)}</code></pre></div>
<div class="figure"><span id="fig:cltdemo"></span>
<img src="FdI2_files/figure-html/cltdemo-1.png" alt="A demonstration of the central limit theorem. In panel a, we have a non-normal population distribution; and panels b-d show the sampling distribution of the mean for samples of size 2,4 and 8, for data drawn from the distribution in panel a. As you can see, even though the original population distribution is non-normal, the sampling distribution of the mean becomes pretty close to normal by the time you have a sample of even 4 observations. " width="672" />
<p class="caption">
Figure 2.11: A demonstration of the central limit theorem. In panel a, we have a non-normal population distribution; and panels b-d show the sampling distribution of the mean for samples of size 2,4 and 8, for data drawn from the distribution in panel a. As you can see, even though the original population distribution is non-normal, the sampling distribution of the mean becomes pretty close to normal by the time you have a sample of even 4 observations.
</p>
</div>
<p>On the basis of these figures, it seems like we have evidence for all of the following claims about the sampling distribution of the mean:</p>
<ul>
<li>The mean of the sampling distribution is the same as the mean of the population</li>
<li>The standard deviation of the sampling distribution (i.e., the standard error) gets smaller as the sample size increases</li>
<li>The shape of the sampling distribution becomes normal as the sample size increases</li>
</ul>
<p>As it happens, not only are all of these statements true, there is a very famous theorem in statistics that proves all three of them, known as the <strong><em>central limit theorem</em></strong>. Among other things, the central limit theorem tells us that if the population distribution has mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, then the sampling distribution of the mean also has mean <span class="math inline">\(\mu\)</span>, and the standard error of the mean is <span class="math display">\[
\mbox{SEM} = \frac{\sigma}{ \sqrt{N} }
\]</span> Because we divide the population standard devation <span class="math inline">\(\sigma\)</span> by the square root of the sample size <span class="math inline">\(N\)</span>, the SEM gets smaller as the sample size increases. It also tells us that the shape of the sampling distribution becomes normal.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<p>This result is useful for all sorts of things. It tells us why large experiments are more reliable than small ones, and because it gives us an explicit formula for the standard error it tells us <em>how much</em> more reliable a large experiment is. It tells us why the normal distribution is, well, <em>normal</em>. In real experiments, many of the things that we want to measure are actually averages of lots of different quantities (e.g., arguably, “general” intelligence as measured by IQ is an average of a large number of “specific” skills and abilities), and when that happens, the averaged quantity should follow a normal distribution. Because of this mathematical law, the normal distribution pops up over and over again in real data.</p>
</div>
</div>
<div id="pointestimates" class="section level2">
<h2><span class="header-section-number">2.4</span> Estimating population parameters</h2>
<p>In all the IQ examples in the previous sections, we actually knew the population parameters ahead of time. As every undergraduate gets taught in their very first lecture on the measurement of intelligence, IQ scores are <em>defined</em> to have mean 100 and standard deviation 15. However, this is a bit of a lie. How do we know that IQ scores have a true population mean of 100? Well, we know this because the people who designed the tests have administered them to very large samples, and have then “rigged” the scoring rules so that their sample has mean 100. That’s not a bad thing of course: it’s an important part of designing a psychological measurement. However, it’s important to keep in mind that this theoretical mean of 100 only attaches to the population that the test designers used to design the tests. Good test designers will actually go to some lengths to provide “test norms” that can apply to lots of different populations (e.g., different age groups, nationalities etc).</p>
<p>This is very handy, but of course almost every research project of interest involves looking at a different population of people to those used in the test norms. For instance, suppose you wanted to measure the effect of low level lead poisoning on cognitive functioning in Port Pirie, a South Australian industrial town with a lead smelter. Perhaps you decide that you want to compare IQ scores among people in Port Pirie to a comparable sample in Whyalla, a South Australian industrial town with a steel refinery.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> Regardless of which town you’re thinking about, it doesn’t make a lot of sense simply to <em>assume</em> that the true population mean IQ is 100. No-one has, to my knowledge, produced sensible norming data that can automatically be applied to South Australian industrial towns. We’re going to have to <strong><em>estimate</em></strong> the population parameters from a sample of data. So how do we do this?</p>
<div id="estimating-the-population-mean" class="section level3">
<h3><span class="header-section-number">2.4.1</span> Estimating the population mean</h3>
<p>Suppose we go to Port Pirie and 100 of the locals are kind enough to sit through an IQ test. The average IQ score among these people turns out to be <span class="math inline">\(\bar{X}=98.5\)</span>. So what is the true mean IQ for the entire population of Port Pirie? Obviously, we don’t know the answer to that question. It could be <span class="math inline">\(97.2\)</span>, but if could also be <span class="math inline">\(103.5\)</span>. Our sampling isn’t exhaustive so we cannot give a definitive answer. Nevertheless if I was forced at gunpoint to give a “best guess” I’d have to say <span class="math inline">\(98.5\)</span>. That’s the essence of statistical estimation: giving a best guess.</p>
<p>In this example, estimating the unknown poulation parameter is straightforward. I calculate the sample mean, and I use that as my <strong><em>estimate of the population mean</em></strong>. It’s pretty simple, and in the next section I’ll explain the statistical justification for this intuitive answer. However, for the moment what I want to do is make sure you recognise that the sample statistic and the estimate of the population parameter are conceptually different things. A sample statistic is a description of your data, whereas the estimate is a guess about the population. With that in mind, statisticians often different notation to refer to them. For instance, if true population mean is denoted <span class="math inline">\(\mu\)</span>, then we would use <span class="math inline">\(\hat\mu\)</span> to refer to our estimate of the population mean. In contrast, the sample mean is denoted <span class="math inline">\(\bar{X}\)</span> or sometimes <span class="math inline">\(m\)</span>. However, in simple random samples, the estimate of the population mean is identical to the sample mean: if I observe a sample mean of <span class="math inline">\(\bar{X} = 98.5\)</span>, then my estimate of the population mean is also <span class="math inline">\(\hat\mu = 98.5\)</span>. To help keep the notation clear, here’s a handy table:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(<span class="kw">data.frame</span>(<span class="dt">stringsAsFactors=</span><span class="ot">FALSE</span>,
                   <span class="dt">Symbol =</span> <span class="kw">c</span>(<span class="st">&quot;$</span><span class="ch">\\</span><span class="st">bar{X}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">hat{</span><span class="ch">\\</span><span class="st">mu}$&quot;</span>),
              <span class="dt">What.is.it =</span> <span class="kw">c</span>(<span class="st">&quot;Sample mean&quot;</span>, <span class="st">&quot;True population mean&quot;</span>,
                              <span class="st">&quot;Estimate of the population mean&quot;</span>),
   <span class="dt">Do.we.know.what.it.is =</span> <span class="kw">c</span>(<span class="st">&quot;Yes  calculated from the raw data&quot;</span>,
                              <span class="st">&quot;Almost never known for sure&quot;</span>,
                              <span class="st">&quot;Yes  identical to the sample mean&quot;</span>)))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Symbol</th>
<th align="left">What.is.it</th>
<th align="left">Do.we.know.what.it.is</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\bar{X}\)</span></td>
<td align="left">Sample mean</td>
<td align="left">Yes calculated from the raw data</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\mu\)</span></td>
<td align="left">True population mean</td>
<td align="left">Almost never known for sure</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\hat{\mu}\)</span></td>
<td align="left">Estimate of the population mean</td>
<td align="left">Yes identical to the sample mean</td>
</tr>
</tbody>
</table>
</div>
<div id="estimating-the-population-standard-deviation" class="section level3">
<h3><span class="header-section-number">2.4.2</span> Estimating the population standard deviation</h3>
<p>So far, estimation seems pretty simple, and you might be wondering why I forced you to read through all that stuff about sampling theory. In the case of the mean, our estimate of the population parameter (i.e. <span class="math inline">\(\hat\mu\)</span>) turned out to identical to the corresponding sample statistic (i.e. <span class="math inline">\(\bar{X}\)</span>). However, that’s not always true. To see this, let’s have a think about how to construct an <strong><em>estimate of the population standard deviation</em></strong>, which we’ll denote <span class="math inline">\(\hat\sigma\)</span>. What shall we use as our estimate in this case? Your first thought might be that we could do the same thing we did when estimating the mean, and just use the sample statistic as our estimate. That’s almost the right thing to do, but not quite.</p>
<p>Here’s why. Suppose I have a sample that contains a single observation. For this example, it helps to consider a sample where you have no intutions at all about what the true population values might be, so let’s use something completely fictitious. Suppose the observation in question measures the <em>cromulence</em> of my shoes. It turns out that my shoes have a cromulence of 20. So here’s my sample:</p>
<pre><code>20</code></pre>
<p>This is a perfectly legitimate sample, even if it does have a sample size of <span class="math inline">\(N=1\)</span>. It has a sample mean of 20, and because every observation in this sample is equal to the sample mean (obviously!) it has a sample standard deviation of 0. As a description of the <em>sample</em> this seems quite right: the sample contains a single observation and therefore there is no variation observed within the sample. A sample standard deviation of <span class="math inline">\(s = 0\)</span> is the right answer here. But as an estimate of the <em>population</em> standard deviation, it feels completely insane, right? Admittedly, you and I don’t know anything at all about what “cromulence” is, but we know something about data: the only reason that we don’t see any variability in the <em>sample</em> is that the sample is too small to display any variation! So, if you have a sample size of <span class="math inline">\(N=1\)</span>, it <em>feels</em> like the right answer is just to say “no idea at all”.</p>
<p>Notice that you <em>don’t</em> have the same intuition when it comes to the sample mean and the population mean. If forced to make a best guess about the population mean, it doesn’t feel completely insane to guess that the population mean is 20. Sure, you probably wouldn’t feel very confident in that guess, because you have only the one observation to work with, but it’s still the best guess you can make.</p>
<p>Let’s extend this example a little. Suppose I now make a second observation. My data set now has <span class="math inline">\(N=2\)</span> observations of the cromulence of shoes, and the complete sample now looks like this:</p>
<pre><code>20, 22</code></pre>
<p>This time around, our sample is <em>just</em> large enough for us to be able to observe some variability: two observations is the bare minimum number needed for any variability to be observed! For our new data set, the sample mean is <span class="math inline">\(\bar{X}=21\)</span>, and the sample standard deviation is <span class="math inline">\(s=1\)</span>. What intuitions do we have about the population? Again, as far as the population mean goes, the best guess we can possibly make is the sample mean: if forced to guess, we’d probably guess that the population mean cromulence is 21. What about the standard deviation? This is a little more complicated. The sample standard deviation is only based on two observations, and if you’re at all like me you probably have the intuition that, with only two observations, we haven’t given the population “enough of a chance” to reveal its true variability to us. It’s not just that we suspect that the estimate is <em>wrong</em>: after all, with only two observations we expect it to be wrong to some degree. The worry is that the error is <em>systematic</em>. Specifically, we suspect that the sample standard deviation is likely to be smaller than the population standard deviation.</p>
<p>This intuition feels right, but it would be nice to demonstrate this somehow. There are in fact mathematical proofs that confirm this intuition, but unless you have the right mathematical background they don’t help very much. Instead, what I’ll do is use R to simulate the results of some experiments. With that in mind, let’s return to our IQ studies. Suppose the true population mean IQ is 100 and the standard deviation is 15. I can use the <code>rnorm()</code> function to generate the the results of an experiment in which I measure <span class="math inline">\(N=2\)</span> IQ scores, and calculate the sample standard deviation. If I do this over and over again, and plot a histogram of these sample standard deviations, what I have is the <em>sampling distribution of the standard deviation</em>. I’ve plotted this distribution in Figure <a href="#fig:sampdistsd"><strong>??</strong></a>. Even though the true population standard deviation is 15, the average of the <em>sample</em> standard deviations is only 8.5. Notice that this is a very different result to what we found in Figure <a href="estimation.html#fig:IQsampb">2.9</a> when we plotted the sampling distribution of the mean. If you look at that sampling distribution, what you see is that the population mean is 100, and the average of the sample means is also 100.</p>
<p>Now let’s extend the simulation. Instead of restricting ourselves to the situation where we have a sample size of <span class="math inline">\(N=2\)</span>, let’s repeat the exercise for sample sizes from 1 to 10. If we plot the average sample mean and average sample standard deviation as a function of sample size, you get the results shown in Figure <a href="#fig:estimatorbias"><strong>??</strong></a>. On the left hand side (panel a), I’ve plotted the average sample mean and on the right hand side (panel b), I’ve plotted the average standard deviation. The two plots are quite different: <em>on average</em>, the average sample mean is equal to the population mean. It is an <strong><em>unbiased estimator</em></strong>, which is essentially the reason why your best estimate for the population mean is the sample mean.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> The plot on the right is quite different: on average, the sample standard deviation <span class="math inline">\(s\)</span> is <em>smaller</em> than the population standard deviation <span class="math inline">\(\sigma\)</span>. It is a <strong><em>biased estimator</em></strong>. In other words, if we want to make a “best guess” <span class="math inline">\(\hat\sigma\)</span> about the value of the population standard deviation <span class="math inline">\(\sigma\)</span>, we should make sure our guess is a little bit larger than the sample standard deviation <span class="math inline">\(s\)</span>.</p>
<p>The fix to this systematic bias turns out to be very simple. Here’s how it works. Before tackling the standard deviation, let’s look at the variance. If you recall from Section <a href="#var"><strong>??</strong></a>, the sample variance is defined to be the average of the squared deviations from the sample mean. That is: <span class="math display">\[
s^2 = \frac{1}{N} \sum_{i=1}^N (X_i - \bar{X})^2
\]</span> The sample variance <span class="math inline">\(s^2\)</span> is a biased estimator of the population variance <span class="math inline">\(\sigma^2\)</span>. But as it turns out, we only need to make a tiny tweak to transform this into an unbiased estimator. All we have to do is divide by <span class="math inline">\(N-1\)</span> rather than by <span class="math inline">\(N\)</span>. If we do that, we obtain the following formula: <span class="math display">\[
\hat\sigma^2 = \frac{1}{N-1} \sum_{i=1}^N (X_i - \bar{X})^2 
\]</span> This is an unbiased estimator of the population variance <span class="math inline">\(\sigma\)</span>. Moreover, this finally answers the question we raised in Section <a href="#var"><strong>??</strong></a>. Why did R give us slightly different answers when we used the <code>var()</code> function? Because the <code>var()</code> function calculates <span class="math inline">\(\hat\sigma^2\)</span> not <span class="math inline">\(s^2\)</span>, that’s why. A similar story applies for the standard deviation. If we divide by <span class="math inline">\(N-1\)</span> rather than <span class="math inline">\(N\)</span>, our estimate of the population standard deviation becomes: <span class="math display">\[
\hat\sigma = \sqrt{\frac{1}{N-1} \sum_{i=1}^N (X_i - \bar{X})^2} 
\]</span> and when we use R’s built in standard deviation function <code>sd()</code>, what it’s doing is calculating <span class="math inline">\(\hat\sigma\)</span>, not <span class="math inline">\(s\)</span>.<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></p>
<p>One final point: in practice, a lot of people tend to refer to <span class="math inline">\(\hat{\sigma}\)</span> (i.e., the formula where we divide by <span class="math inline">\(N-1\)</span>) as the <em>sample</em> standard deviation. Technically, this is incorrect: the <em>sample</em> standard deviation should be equal to <span class="math inline">\(s\)</span> (i.e., the formula where we divide by <span class="math inline">\(N\)</span>). These aren’t the same thing, either conceptually or numerically. One is a property of the sample, the other is an estimated characteristic of the population. However, in almost every real life application, what we actually care about is the estimate of the population parameter, and so people always report <span class="math inline">\(\hat\sigma\)</span> rather than <span class="math inline">\(s\)</span>. This is the right number to report, of course, it’s that people tend to get a little bit imprecise about terminology when they write it up, because “sample standard deviation” is shorter than “estimated population standard deviation”. It’s no big deal, and in practice I do the same thing everyone else does. Nevertheless, I think it’s important to keep the two <em>concepts</em> separate: it’s never a good idea to confuse “known properties of your sample” with “guesses about the population from which it came”. The moment you start thinking that <span class="math inline">\(s\)</span> and <span class="math inline">\(\hat\sigma\)</span> are the same thing, you start doing exactly that.</p>
<p>To finish this section off, here’s another couple of tables to help keep things clear:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(<span class="kw">data.frame</span>(<span class="dt">stringsAsFactors=</span><span class="ot">FALSE</span>,
                   <span class="dt">Symbol =</span> <span class="kw">c</span>(<span class="st">&quot;$s$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">sigma$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">hat{</span><span class="ch">\\</span><span class="st">sigma}$&quot;</span>, <span class="st">&quot;$s^2$&quot;</span>,
                              <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">sigma^2$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">hat{</span><span class="ch">\\</span><span class="st">sigma}^2$&quot;</span>),
              <span class="dt">What.is.it =</span> <span class="kw">c</span>(<span class="st">&quot;Sample standard deviation&quot;</span>,
                              <span class="st">&quot;Population standard deviation&quot;</span>,
                              <span class="st">&quot;Estimate of the population standard deviation&quot;</span>, <span class="st">&quot;Sample variance&quot;</span>,
                              <span class="st">&quot;Population variance&quot;</span>,
                              <span class="st">&quot;Estimate of the population variance&quot;</span>),
   <span class="dt">Do.we.know.what.it.is =</span> <span class="kw">c</span>(<span class="st">&quot;Yes - calculated from the raw data&quot;</span>,
                              <span class="st">&quot;Almost never known for sure&quot;</span>,
                              <span class="st">&quot;Yes - but not the same as the sample standard deviation&quot;</span>,
                              <span class="st">&quot;Yes - calculated from the raw data&quot;</span>,
                              <span class="st">&quot;Almost never known for sure&quot;</span>,
                              <span class="st">&quot;Yes -  but not the same as the sample variance&quot;</span>)
))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Symbol</th>
<th align="left">What.is.it</th>
<th align="left">Do.we.know.what.it.is</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(s\)</span></td>
<td align="left">Sample standard deviation</td>
<td align="left">Yes - calculated from the raw data</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\sigma\)</span></td>
<td align="left">Population standard deviation</td>
<td align="left">Almost never known for sure</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\hat{\sigma}\)</span></td>
<td align="left">Estimate of the population standard deviation</td>
<td align="left">Yes - but not the same as the sample standard deviation</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(s^2\)</span></td>
<td align="left">Sample variance</td>
<td align="left">Yes - calculated from the raw data</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\sigma^2\)</span></td>
<td align="left">Population variance</td>
<td align="left">Almost never known for sure</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\hat{\sigma}^2\)</span></td>
<td align="left">Estimate of the population variance</td>
<td align="left">Yes - but not the same as the sample variance</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="ci" class="section level2">
<h2><span class="header-section-number">2.5</span> Estimating a confidence interval</h2>
<blockquote>
<p><em>Statistics means never having to say you’re certain</em> – Unknown origin<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a> but I’ve never found the original source.</p>
</blockquote>
<p>Up to this point in this chapter, I’ve outlined the basics of sampling theory which statisticians rely on to make guesses about population parameters on the basis of a sample of data. As this discussion illustrates, one of the reasons we need all this sampling theory is that every data set leaves us with a some of uncertainty, so our estimates are never going to be perfectly accurate. The thing that has been missing from this discussion is an attempt to <em>quantify</em> the amount of uncertainty that attaches to our estimate. It’s not enough to be able guess that, say, the mean IQ of undergraduate psychology students is 115 (yes, I just made that number up). We also want to be able to say something that expresses the degree of certainty that we have in our guess. For example, it would be nice to be able to say that there is a 95% chance that the true mean lies between 109 and 121. The name for this is a <strong><em>confidence interval</em></strong> for the mean.</p>
<p>Armed with an understanding of sampling distributions, constructing a confidence interval for the mean is actually pretty easy. Here’s how it works. Suppose the true population mean is <span class="math inline">\(\mu\)</span> and the standard deviation is <span class="math inline">\(\sigma\)</span>. I’ve just finished running my study that has <span class="math inline">\(N\)</span> participants, and the mean IQ among those participants is <span class="math inline">\(\bar{X}\)</span>. We know from our discussion of the central limit theorem (Section <a href="estimation.html#clt">2.3.3</a> that the sampling distribution of the mean is approximately normal. We also know from our discussion of the normal distribution Section <a href="probability.html#normal">1.5</a> that there is a 95% chance that a normally-distributed quantity will fall within two standard deviations of the true mean. To be more precise, we can use the <code>qnorm()</code> function to compute the 2.5th and 97.5th percentiles of the normal distribution</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qnorm</span>( <span class="dt">p =</span> <span class="kw">c</span>(.<span class="dv">025</span>, .<span class="dv">975</span>) )</code></pre></div>
<pre><code>## [1] -1.959964  1.959964</code></pre>
<p>Okay, so I lied earlier on. The more correct answer is that 95% chance that a normally-distributed quantity will fall within 1.96 standard deviations of the true mean. Next, recall that the standard deviation of the sampling distribution is referred to as the standard error, and the standard error of the mean is written as SEM. When we put all these pieces together, we learn that there is a 95% probability that the sample mean <span class="math inline">\(\bar{X}\)</span> that we have actually observed lies within 1.96 standard errors of the population mean. Mathematically, we write this as: <span class="math display">\[
\mu - \left( 1.96 \times \mbox{SEM} \right) \ \leq \  \bar{X}\  \leq \  \mu + \left( 1.96 \times \mbox{SEM} \right) 
\]</span> where the SEM is equal to <span class="math inline">\(\sigma / \sqrt{N}\)</span>, and we can be 95% confident that this is true. However, that’s not answering the question that we’re actually interested in. The equation above tells us what we should expect about the sample mean, given that we know what the population parameters are. What we <em>want</em> is to have this work the other way around: we want to know what we should believe about the population parameters, given that we have observed a particular sample. However, it’s not too difficult to do this. Using a little high school algebra, a sneaky way to rewrite our equation is like this: <span class="math display">\[
\bar{X} -  \left( 1.96 \times \mbox{SEM} \right) \ \leq \ \mu  \ \leq  \ \bar{X} +  \left( 1.96 \times \mbox{SEM}\right)
\]</span> What this is telling is is that the range of values has a 95% probability of containing the population mean <span class="math inline">\(\mu\)</span>. We refer to this range as a <strong><em>95% confidence interval</em></strong>, denoted <span class="math inline">\(\mbox{CI}_{95}\)</span>. In short, as long as <span class="math inline">\(N\)</span> is sufficiently large – large enough for us to believe that the sampling distribution of the mean is normal – then we can write this as our formula for the 95% confidence interval: <span class="math display">\[
\mbox{CI}_{95} = \bar{X} \pm \left( 1.96 \times \frac{\sigma}{\sqrt{N}} \right)
\]</span> Of course, there’s nothing special about the number 1.96: it just happens to be the multiplier you need to use if you want a 95% confidence interval. If I’d wanted a 70% confidence interval, I could have used the <code>qnorm()</code> function to calculate the 15th and 85th quantiles:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qnorm</span>( <span class="dt">p =</span> <span class="kw">c</span>(.<span class="dv">15</span>, .<span class="dv">85</span>) )</code></pre></div>
<pre><code>## [1] -1.036433  1.036433</code></pre>
<p>and so the formula for <span class="math inline">\(\mbox{CI}_{70}\)</span> would be the same as the formula for <span class="math inline">\(\mbox{CI}_{95}\)</span> except that we’d use 1.04 as our magic number rather than 1.96.</p>
<div id="a-slight-mistake-in-the-formula" class="section level3">
<h3><span class="header-section-number">2.5.1</span> A slight mistake in the formula</h3>
<p>As usual, I lied. The formula that I’ve given above for the 95% confidence interval is approximately correct, but I glossed over an important detail in the discussion. Notice my formula requires you to use the standard error of the mean, SEM, which in turn requires you to use the true population standard deviation <span class="math inline">\(\sigma\)</span>. Yet, in Section @ref(pointestimates I stressed the fact that we don’t actually <em>know</em> the true population parameters. Because we don’t know the true value of <span class="math inline">\(\sigma\)</span>, we have to use an estimate of the population standard deviation <span class="math inline">\(\hat{\sigma}\)</span> instead. This is pretty straightforward to do, but this has the consequence that we need to use the quantiles of the <span class="math inline">\(t\)</span>-distribution rather than the normal distribution to calculate our magic number; and the answer depends on the sample size. When <span class="math inline">\(N\)</span> is very large, we get pretty much the same value using <code>qt()</code> that we would if we used <code>qnorm()</code>…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N &lt;-<span class="st"> </span><span class="dv">10000</span>   <span class="co"># suppose our sample size is 10,000</span>
<span class="kw">qt</span>( <span class="dt">p =</span> .<span class="dv">975</span>, <span class="dt">df =</span> N<span class="op">-</span><span class="dv">1</span>)   <span class="co"># calculate the 97.5th quantile of the t-dist</span></code></pre></div>
<pre><code>## [1] 1.960201</code></pre>
<p>But when <span class="math inline">\(N\)</span> is small, we get a much bigger number when we use the <span class="math inline">\(t\)</span> distribution:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N &lt;-<span class="st"> </span><span class="dv">10</span>   <span class="co"># suppose our sample size is 10</span>
<span class="kw">qt</span>( <span class="dt">p =</span> .<span class="dv">975</span>, <span class="dt">df =</span> N<span class="op">-</span><span class="dv">1</span>)   <span class="co"># calculate the 97.5th quantile of the t-dist</span></code></pre></div>
<pre><code>## [1] 2.262157</code></pre>
<p>There’s nothing too mysterious about what’s happening here. Bigger values mean that the confidence interval is wider, indicating that we’re more uncertain about what the true value of <span class="math inline">\(\mu\)</span> actually is. When we use the <span class="math inline">\(t\)</span> distribution instead of the normal distribution, we get bigger numbers, indicating that we have more uncertainty. And why do we have that extra uncertainty? Well, because our estimate of the population standard deviation <span class="math inline">\(\hat\sigma\)</span> might be wrong! If it’s wrong, it implies that we’re a bit less sure about what our sampling distribution of the mean actually looks like… and this uncertainty ends up getting reflected in a wider confidence interval.</p>
</div>
<div id="interpreting-a-confidence-interval" class="section level3">
<h3><span class="header-section-number">2.5.2</span> Interpreting a confidence interval</h3>
<p>The hardest thing about confidence intervals is understanding what they <em>mean</em>. Whenever people first encounter confidence intervals, the first instinct is almost always to say that “there is a 95% probabaility that the true mean lies inside the confidence interval”. It’s simple, and it seems to capture the common sense idea of what it means to say that I am “95% confident”. Unfortunately, it’s not quite right. The intuitive definition relies very heavily on your own personal <em>beliefs</em> about the value of the population mean. I say that I am 95% confident because those are my beliefs. In everyday life that’s perfectly okay, but if you remember back to Section <a href="probability.html#probmeaning">1.2</a>, you’ll notice that talking about personal belief and confidence is a Bayesian idea. Personally (speaking as a Bayesian) I have no problem with the idea that the phrase “95% probability” is allowed to refer to a personal belief. However, confidence intervals are <em>not</em> Bayesian tools. Like everything else in this chapter, confidence intervals are <em>frequentist</em> tools, and if you are going to use frequentist methods then it’s not appropriate to attach a Bayesian interpretation to them. If you use frequentist methods, you must adopt frequentist interpretations!</p>
<p>Okay, so if that’s not the right answer, what is? Remember what we said about frequentist probability: the only way we are allowed to make “probability statements” is to talk about a sequence of events, and to count up the frequencies of different kinds of events. From that perspective, the interpretation of a 95% confidence interval must have something to do with replication. Specifically: if we replicated the experiment over and over again and computed a 95% confidence interval for each replication, then 95% of those <em>intervals</em> would contain the true mean. More generally, 95% of all confidence intervals constructed using this procedure should contain the true population mean. This idea is illustrated in Figure <a href="#fig:cirep"><strong>??</strong></a>, which shows 50 confidence intervals constructed for a “measure 10 IQ scores” experiment (top panel) and another 50 confidence intervals for a “measure 25 IQ scores” experiment (bottom panel). A bit fortuitously, across the 100 replications that I simulated, it turned out that exactly 95 of them contained the true mean.</p>
<p>The critical difference here is that the Bayesian claim makes a probability statement about the population mean (i.e., it refers to our uncertainty about the population mean), which is not allowed under the frequentist interpretation of probability because you can’t “replicate” a population! In the frequentist claim, the population mean is fixed and no probabilistic claims can be made about it. Confidence intervals, however, are repeatable so we can replicate experiments. Therefore a frequentist is allowed to talk about the probability that the <em>confidence interval</em> (a random variable) contains the true mean; but is not allowed to talk about the probability that the <em>true population mean</em> (not a repeatable event) falls within the confidence interval.</p>
<p>I know that this seems a little pedantic, but it does matter. It matters because the difference in interpretation leads to a difference in the mathematics. There is a Bayesian alternative to confidence intervals, known as <em>credible intervals</em>. In most situations credible intervals are quite similar to confidence intervals, but in other cases they are drastically different. As promised, though, I’ll talk more about the Bayesian perspective in Chapter <a href="#bayes"><strong>??</strong></a>.</p>
</div>
</div>
<div id="summary" class="section level2">
<h2><span class="header-section-number">2.6</span> Summary</h2>
<p>In this chapter I’ve covered two main topics. The first half of the chapter talks about sampling theory, and the second half talks about how we can use sampling theory to construct estimates of the population parameters. The section breakdown looks like this:</p>
<ul>
<li>Basic ideas about samples, sampling and populations (Section <a href="estimation.html#srs">2.1</a>)</li>
<li>Statistical theory of sampling: the law of large numbers (Section <a href="estimation.html#lawlargenumbers">2.2</a>), sampling distributions and the central limit theorem (Section <a href="estimation.html#samplesandclt">2.3</a>).</li>
<li>Estimating means and standard deviations (Section <a href="estimation.html#pointestimates">2.4</a>)</li>
<li>Estimating a confidence interval (Section <a href="estimation.html#ci">2.5</a>)</li>
</ul>
<p>As always, there’s a lot of topics related to sampling and estimation that aren’t covered in this chapter, but for an introductory psychology class this is fairly comprehensive I think. For most applied researchers you won’t need much more theory than this. One big question that I haven’t touched on in this chapter is what you do when you don’t have a simple random sample. There is a lot of statistical theory you can draw on to handle this situation, but it’s well beyond the scope of this book.</p>

</div>
</div>













<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>Técnicamente, la de ley de los grandes números es aplicable a cualquier estadístico muestral que pueda ser descrito como un promedio de cantidades independiente. La varianza muestral, por ejemplo, puede ser representado como un tipo de promedio y por ello, sujeto a la ley de los grandes números. Sin embargo, el valor mínimo muestral no puede ser interpretado como un promedio de nada, y por tanto, no es gobernado por la ley de los grandes números.<a href="estimation.html#fnref3">↩</a></p></li>
<li id="fn4"><p>As usual, I’m being a bit sloppy here. The central limit theorem is a bit more general than this section implies. Like most introductory stats texts, I’ve discussed one situation where the central limit theorem holds: when you’re taking an average across lots of independent events drawn from the same distribution. However, the central limit theorem is much broader than this. There’s a whole class of things called “<span class="math inline">\(U\)</span>-statistics” for instance, all of which satisfy the central limit theorem and therefore become normally distributed for large sample sizes. The mean is one such statistic, but it’s not the only one.<a href="estimation.html#fnref4">↩</a></p></li>
<li id="fn5"><p>Please note that if you were <em>actually</em> interested in this question, you would need to be a <em>lot</em> more careful than I’m being here. You <em>can’t</em> just compare IQ scores in Whyalla to Port Pirie and assume that any differences are due to lead poisoning. Even if it were true that the only differences between the two towns corresponded to the different refineries (and it isn’t, not by a long shot), you need to account for the fact that people already <em>believe</em> that lead pollution causes cognitive deficits: if you recall back to Chapter <a href="#studydesign"><strong>??</strong></a>, this means that there are different demand effects for the Port Pirie sample than for the Whyalla sample. In other words, you might end up with an illusory group difference in your data, caused by the fact that people <em>think</em> that there is a real difference. I find it pretty implausible to think that the locals wouldn’t be well aware of what you were trying to do if a bunch of researchers turned up in Port Pirie with lab coats and IQ tests, and even less plausible to think that a lot of people would be pretty resentful of you for doing it. Those people won’t be as co-operative in the tests. Other people in Port Pirie might be <em>more</em> motivated to do well because they don’t want their home town to look bad. The motivational effects that would apply in Whyalla are likely to be weaker, because people don’t have any concept of “iron ore poisoning” in the same way that they have a concept for “lead poisoning”. Psychology is <em>hard</em>.<a href="estimation.html#fnref5">↩</a></p></li>
<li id="fn6"><p>I should note that I’m hiding something here. Unbiasedness is a desirable characteristic for an estimator, but there are other things that matter besides bias. However, it’s beyond the scope of this book to discuss this in any detail. I just want to draw your attention to the fact that there’s some hidden complexity here.<a href="estimation.html#fnref6">↩</a></p></li>
<li id="fn7"><p>Okay, I’m hiding something else here. In a bizarre and counterintuitive twist, since <span class="math inline">\(\hat\sigma^2\)</span> is an unbiased estimator of <span class="math inline">\(\sigma^2\)</span>, you’d assume that taking the square root would be fine, and <span class="math inline">\(\hat\sigma\)</span> would be an unbiased estimator of <span class="math inline">\(\sigma\)</span>. Right? Weirdly, it’s not. There’s actually a subtle, tiny bias in <span class="math inline">\(\hat\sigma\)</span>. This is just bizarre: <span class="math inline">\(\hat\sigma^2\)</span> is and unbiased estimate of the population variance <span class="math inline">\(\sigma^2\)</span>, but when you take the square root, it turns out that <span class="math inline">\(\hat\sigma\)</span> is a biased estimator of the population standard deviation <span class="math inline">\(\sigma\)</span>. Weird, weird, weird, right? So, why is <span class="math inline">\(\hat\sigma\)</span> biased? The technical answer is “because non-linear transformations (e.g., the square root) don’t commute with expectation”, but that just sounds like gibberish to everyone who hasn’t taken a course in mathematical statistics. Fortunately, it doesn’t matter for practical purposes. The bias is small, and in real life everyone uses <span class="math inline">\(\hat\sigma\)</span> and it works just fine. Sometimes mathematics is just annoying.<a href="estimation.html#fnref7">↩</a></p></li>
<li id="fn8"><p>This quote appears on a great many t-shirts and websites, and even gets a mention in a few academic papers (e.g., \url{<a href="http://www.amstat.org/publications/jse/v10n3/friedman.html" class="uri">http://www.amstat.org/publications/jse/v10n3/friedman.html</a><a href="estimation.html#fnref8">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probability.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["FdI2.pdf", "FdI2.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
