<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 2 Estimación | Fundamentos de Investigación II</title>
  <meta name="description" content="Apuntes de la asignatura de Fundamentos de Investigación II" />
  <meta name="generator" content="bookdown 0.12 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 2 Estimación | Fundamentos de Investigación II" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.png" />
  <meta property="og:description" content="Apuntes de la asignatura de Fundamentos de Investigación II" />
  <meta name="github-repo" content="negatoscope/FdI2" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 2 Estimación | Fundamentos de Investigación II" />
  
  <meta name="twitter:description" content="Apuntes de la asignatura de Fundamentos de Investigación II" />
  <meta name="twitter:image" content="images/cover.png" />

<meta name="author" content="Luis Eudave" />


<meta name="date" content="2020-10-16" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="probability.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Fundamentos de Investigación II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>1</b> Introducción a la probabilidad</a><ul>
<li class="chapter" data-level="1.1" data-path="probability.html"><a href="probability.html#probstats"><i class="fa fa-check"></i><b>1.1</b> ¿Cómo de diferentes son la probabilidad y la estadística?</a></li>
<li class="chapter" data-level="1.2" data-path="probability.html"><a href="probability.html#probmeaning"><i class="fa fa-check"></i><b>1.2</b> ¿Qué significa la probabilidad?</a><ul>
<li class="chapter" data-level="1.2.1" data-path="probability.html"><a href="probability.html#la-vision-frecuentista"><i class="fa fa-check"></i><b>1.2.1</b> La visión frecuentista</a></li>
<li class="chapter" data-level="1.2.2" data-path="probability.html"><a href="probability.html#la-vision-bayesiana"><i class="fa fa-check"></i><b>1.2.2</b> La visión bayesiana</a></li>
<li class="chapter" data-level="1.2.3" data-path="probability.html"><a href="probability.html#cual-es-la-diferencia-y-quien-tiene-razon"><i class="fa fa-check"></i><b>1.2.3</b> ¿Cuál es la diferencia? ¿Y quién tiene razón?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="probability.html"><a href="probability.html#basicprobability"><i class="fa fa-check"></i><b>1.3</b> Teoría de probabilidad básica</a><ul>
<li class="chapter" data-level="1.3.1" data-path="probability.html"><a href="probability.html#introduccion-a-las-distribuciones-de-probabilidad"><i class="fa fa-check"></i><b>1.3.1</b> Introducción a las distribuciones de probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="probability.html"><a href="probability.html#binomial"><i class="fa fa-check"></i><b>1.4</b> La distribución binomial</a><ul>
<li class="chapter" data-level="1.4.1" data-path="probability.html"><a href="probability.html#introduccion-al-binomio"><i class="fa fa-check"></i><b>1.4.1</b> Introducción al binomio</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="probability.html"><a href="probability.html#normal"><i class="fa fa-check"></i><b>1.5</b> La distribución normal</a><ul>
<li class="chapter" data-level="1.5.1" data-path="probability.html"><a href="probability.html#density"><i class="fa fa-check"></i><b>1.5.1</b> Densidad de probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="probability.html"><a href="probability.html#otherdists"><i class="fa fa-check"></i><b>1.6</b> Otras distribuciones útiles</a></li>
<li class="chapter" data-level="1.7" data-path="probability.html"><a href="probability.html#resumen"><i class="fa fa-check"></i><b>1.7</b> Resumen</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>2</b> Estimación</a><ul>
<li class="chapter" data-level="2.1" data-path="estimation.html"><a href="estimation.html#srs"><i class="fa fa-check"></i><b>2.1</b> Muestras, poblaciones y muestreo</a><ul>
<li class="chapter" data-level="2.1.1" data-path="estimation.html"><a href="estimation.html#pop"><i class="fa fa-check"></i><b>2.1.1</b> Definición de una población</a></li>
<li class="chapter" data-level="2.1.2" data-path="estimation.html"><a href="estimation.html#muestras-aleatorias-simples"><i class="fa fa-check"></i><b>2.1.2</b> Muestras aleatorias simples</a></li>
<li class="chapter" data-level="2.1.3" data-path="estimation.html"><a href="estimation.html#la-mayoria-de-las-muestras-no-son-muestras-aleatorias-simples"><i class="fa fa-check"></i><b>2.1.3</b> La mayoría de las muestras no son muestras aleatorias simples</a></li>
<li class="chapter" data-level="2.1.4" data-path="estimation.html"><a href="estimation.html#cuanto-importa-si-no-se-tiene-una-muestra-aleatoria-simple"><i class="fa fa-check"></i><b>2.1.4</b> ¿Cuánto importa si no se tiene una muestra aleatoria simple?</a></li>
<li class="chapter" data-level="2.1.5" data-path="estimation.html"><a href="estimation.html#parametros-poblacionales-y-estadisticos-muestrales"><i class="fa fa-check"></i><b>2.1.5</b> Parámetros poblacionales y estadísticos muestrales</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="estimation.html"><a href="estimation.html#lawlargenumbers"><i class="fa fa-check"></i><b>2.2</b> La ley de los grandes números</a></li>
<li class="chapter" data-level="2.3" data-path="estimation.html"><a href="estimation.html#samplesandclt"><i class="fa fa-check"></i><b>2.3</b> Distribuciones muestrales y el teorema del límite central</a><ul>
<li class="chapter" data-level="2.3.1" data-path="estimation.html"><a href="estimation.html#samplingdists"><i class="fa fa-check"></i><b>2.3.1</b> Distribución muestral de la media</a></li>
<li class="chapter" data-level="2.3.2" data-path="estimation.html"><a href="estimation.html#existen-distribuciones-muestrales-para-cualquier-estadistico-muestral"><i class="fa fa-check"></i><b>2.3.2</b> Existen distribuciones muestrales para cualquier estadístico muestral</a></li>
<li class="chapter" data-level="2.3.3" data-path="estimation.html"><a href="estimation.html#clt"><i class="fa fa-check"></i><b>2.3.3</b> El teorema del límite central</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de Investigación II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="estimation" class="section level1">
<h1><span class="header-section-number">Capítulo 2</span> Estimación</h1>
<p>Al comienzo del capítulo inicial, vimos la distinción que existe entre la <em>estadística descriptiva</em> y la <em>estadística inferencial</em>. El papel de la estadística descriptiva es resumir de manera concisa lo que <em>ya sabemos</em>. Por otro lado, el propósito de la estadística inferencial es “aprender lo que no sabemos a partir de lo que hacemos”. Ahora que tenemos cierto conocimiento sobre la teoría de la probabilidad, podemos pensar en el problema de la inferencia estadística. ¿Qué tipo de información nos gustaría conocer o aprender? ¿Y cómo lo aprendemos? Estas son las preguntas que se encuentran en el corazón de la estadística inferencial y tradicionalmente se dividen en dos “grandes ideas”: la estimación y la prueba o contraste de hipótesis. El objetivo de este capítulo es presentar la primera de estas grandes ideas, la teoría de la estimación. Pero antes, hablaré sobre la teoría del muestreo, ya que la teoría de la estimación no tiene sentido hasta que no se comprende el muestreo. Como consecuencia, este capítulo se divide en dos partes, las secciones <a href="estimation.html#srs">2.1</a> a <a href="estimation.html#samplesandclt">2.3</a> se centran en la teoría del muestreo, y las secciones <a href="#pointestimates"><strong>??</strong></a> y <a href="#ci"><strong>??</strong></a> hacen uso de esa teoría del muestreo para discutir cómo piensan los estadísticos sobre la estimación.</p>
<div id="srs" class="section level2">
<h2><span class="header-section-number">2.1</span> Muestras, poblaciones y muestreo</h2>
<p>Antes hemos hablado sobre el proceso de inducción inferencial, donde recalcamos que <em>todo</em> aprendizaje (o aquello que queremos llegar a conocer) requiere que hagamos suposiciones. Aceptando que esto es cierto, hemos de aceptar algunas suposiciones generales sobre los datos que hemos adquirido para poder utilizarlos. Aquí es donde entra en juego la <strong><em>teoría del muestreo</em></strong>. Si la teoría de la probabilidad representa los cimientos sobre los que se construye toda la teoría estadística, la teoría del muestreo es el marco alrededor del cual se puede construir el resto de la casa. La teoría del muestreo juega un papel muy importante en la especificación de los supuestos en los que se basan sus inferencias estadísticas. Y para hablar sobre “hacer inferencias” de la forma en que los estadísticos lo piensan, debemos ser un poco más explícitos acerca de <em>qué</em> es lo que estamos extrayendo (la muestra) y <em>sobre qué</em> es de lo que estamos haciendo inferencias (la población).</p>
<p>En casi todas las situaciones de interés, lo que tenemos a nuestra disposición como investigadores es una <em>muestra</em> de datos. Podríamos, por ejemplo, haber realizado un experimento con un cierto número de participantes; una empresa de encuestas podría haber telefoneado a algunas personas para hacer preguntas sobre las intenciones de voto, etc. Independientemente de cual sea el caso, el conjunto de datos disponibles que tengamos es finito e incompleto. No podemos conseguir que todas las personas del mundo realicen nuestro experimento; una empresa de encuestas no tiene el tiempo ni el dinero para llamar a todos los votantes del país, etc. Para la estadística descriptiva esta muestra es lo único que importa. Con la estadística inferencial daremos un paso más allá.</p>
<div id="pop" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Definición de una población</h3>
<p>Una muestra es una cosa muy concreta. Puedes abrir un archivo de Excel y ahí podrás encontrar los datos de una muestra. Una <strong><em>población</em></strong>, por otro lado, es una idea más abstracta. Se refiere al conjunto de todas las personas posibles, o todas las observaciones posibles, sobre las que desea sacar conclusiones y, en general, es <em>mucho</em> más grande que la muestra. En un mundo ideal, el investigador comenzaría el estudio con una idea clara de cuál es la población de interés, ya que el proceso de diseñar un estudio y probar una hipótesis sobre los datos que produce depende de la población sobre la que se quiere hacer afirmaciones. Sin embargo, en la práctica esto no sucede siempre: por lo general, el investigador tiene una idea bastante vaga de lo que es la población y diseña el estudio lo mejor que puede sobre esa base.</p>
<p>A veces es fácil indicar cuál es la población de interés. En el ejemplo de la “empresa de encuestas” que vimos en el capítulo anterior, la población consistía en todos los votantes inscritos en un momento del estudio: varios millones de personas. En cambio, la muestra fue un conjunto de 1,000 personas que pertenecen todas a esa población. Sin embargo, en la mayoría de los casos, definir esta muestra/población no es tan fácil. En estudios o experimentos con seres humanos, determinar la población de interés es un poco más complicado. Supongamos que realizo un experimento con 100 estudiantes de pregrado que representan mi muestra. Mi objetivo es, por ejemplo, intentar aprender algo sobre cómo una intervención educativa modifica la dinámica de una clase. Tomando en cuento a la muestra que tenemos, ¿cuál de las siguientes opciones contará como “la población”?:</p>
<ul>
<li>¿Todos los estudiantes de educación de la Universidad de Navarra?<br />
</li>
<li>¿Estudiantes de grado en educación en general, de cualquier parte del mundo?<br />
</li>
<li>¿Españoles vivos actualmente?<br />
</li>
<li>¿Españoles de edades similares a las de mi muestra?</li>
<li>¿Hispanoparlantes?</li>
<li>¿Cualquier persona viva actualmente?<br />
</li>
<li>¿Cualquier ser humano, pasado, presente o futuro?</li>
</ul>
<p>Cada una de estas opciones define un grupo real de personas, las cuales podrían ser todas de interés para mí como investigador en educación, y no es tan obvio cuál debería ser la verdadera población de interés.</p>
</div>
<div id="muestras-aleatorias-simples" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Muestras aleatorias simples</h3>
<div class="figure"><span id="fig:srs1"></span>
<img src="img/estimation/srs1.png" alt="Muestreo aleatorio simple *sin* reemplazo de una población finita." width="463" />
<p class="caption">
Figure 2.1: Muestreo aleatorio simple <em>sin</em> reemplazo de una población finita.
</p>
</div>
<p>Independientemente de cómo definamos a una población, la clave es que la muestra es un subgrupo de esa población, y nuestro objetivo es utilizar nuestro conocimiento de la muestra para hacer inferencias sobre las propiedades de la población. La relación que exista entre los dos dependerá del <em>procedimiento</em> mediante el cual se seleccionó la muestra. Este procedimiento se conoce como <strong><em>método de muestreo</em></strong> y es importante comprender su importancia.</p>
<p>Pongamos un ejemplo sencillo. Imaginemos que tenemos una bolsa que contiene 10 fichas. Cada ficha tiene una letra única impresa, con la que la podemos distinguir de entre las otras 10 fichas. Las fichas vienen en dos colores, blanco y negro. Este conjunto de fichas es la población de interés y se muestra gráficamente a la izquierda de la Figura <a href="estimation.html#fig:srs1">2.1</a>. Como podrás ver en la imagen, tenemos 4 fichas negras y 6 fichas blancas, pero recuerda que en la vida real esto no lo sabríamos a menos que miráramos en la bolsa. Ahora imagina que realizas el siguiente “experimento”: agitas la bolsa, cierras los ojos y sacas 4 fichas sin devolver ninguna de ellas a la bolsa. Primero sale la ficha <span class="math inline">\(a\)</span> (negra), seguida de la ficha <span class="math inline">\(c\)</span> (blanca), luego la <span class="math inline">\(j\)</span> (blanca) y finalmente la ficha <span class="math inline">\(b\)</span> (negra). Una vez extraídas 4 fichas, podrás volver a poner todas las fichas en la bolsa y repetir el experimento, como se muestra en el lado derecho de la Figura <a href="estimation.html#fig:srs1">2.1</a>. Cada vez que repites el experimento obtienes resultados diferentes, pero el procedimiento es idéntico en cada caso. El hecho de que el mismo procedimiento pueda dar lugar a resultados diferentes cada vez, lo define como un proceso <em>aleatorio</em>. Y debido a que hemos agitado la bolsa antes de sacar las fichas, parece razonable pensar que todas las fichas tienen las mismas posibilidades de ser seleccionadas. Un procedimiento en el que todos los miembros de la población tienen las mismas posibilidades de ser seleccionados se denomina <strong><em>muestra aleatoria simple</em></strong>. El hecho de que se <em>no</em> se devuelvan las fichas a la bolsa después de salir, significa que no podremos observar la misma ficha dos veces, y en tales casos se dice que ha habido un muestreo <strong><em>sin reemplazo</em></strong>.</p>
<p>Para comprender la importancia del procedimiento de muestreo, consideremos ahora una forma alternativa en la que podría haberse realizado el experimento. Supongamos que mi sobrino de 3 años coge la bolsa y decide sacar las cuatro fichas negras (le gusta el color negro) sin devolverlas la bolsa. Este esquema de muestreo <em>sesgado</em> se muestra en la Figura <a href="estimation.html#fig:brs">2.2</a>. Ahora considera el valor que tiene obtener una muestra con 4 fichas negras y 0 fichas blancas siguiendo el procedimiento de mi sobrino. Vemos pues, como el valor dependerá mucho del método de muestreo. Si sabemos que el método de muestreo está sesgado para seleccionar únicamente fichas negras, entonces una muestra que consta únicamente de fichas negras no dice mucho sobre nuestra población de fichas. Por esta razón, los estadísticos prefieren que un conjunto de datos provenga de una muestra aleatoria simple, ya que facilita <em>mucho</em> el análisis de los datos.</p>
<div class="figure"><span id="fig:brs"></span>
<img src="img/estimation/brs.png" alt="Muestreo sesgado sin reemplazo de una población finita." width="461" />
<p class="caption">
Figure 2.2: Muestreo sesgado sin reemplazo de una población finita.
</p>
</div>
<div class="figure"><span id="fig:srs2"></span>
<img src="img/estimation/srs2.png" alt="Muestreo aleatorio simple *con* reemplazo de una población finita." width="466" />
<p class="caption">
Figure 2.3: Muestreo aleatorio simple <em>con</em> reemplazo de una población finita.
</p>
</div>
<p>Vale la pena mencionar un tercer procedimiento. Esta vez cerramos los ojos, agitamos la bolsa y sacamos una ficha. Sin embargo, esta vez registramos la observación y luego volvemos a poner la ficha dentro de la bolsa. Nuevamente, cerramos los ojos, agitamos la bolsa y sacamos otra ficha. Repetimos este procedimiento hasta que tengamos 4 fichas. Los conjuntos de datos que hemos generado de esta manera siguen siendo muestras aleatorias simples, pero debido a que volvemos a meter las fichas dentro de la bolsa inmediatamente después de haberlas sacado, se denomina como una muestra <strong><em>con reemplazo</em></strong>. La diferencia entre este caso y el primero es que es posible observar al mismo elemento de la población varias veces (en este caso la misma ficha), tal como se ilustra en la Figura <a href="estimation.html#fig:srs2">2.3</a>.</p>
<p>Por lo general, la mayoría de los experimentos que veamos en ciencias de la educación tienden a tomar muestras sin reemplazo, ya que la misma persona no puede participar en el experimento dos veces. Sin embargo, una gran parte de la teoría estadística se basa en el supuesto de que los datos surgen de una muestra aleatoria simple <em>con</em> reemplazo. En la vida real, esto rara vez importa. Si la población de interés es grande, la diferencia entre el muestreo con y sin reemplazo es demasiado pequeña como para preocuparnos. Sin embargo, la diferencia que existe entre muestras aleatorias simples y muestras sesgadas no es algo no es algo que podemos ignorar tan facilmente.</p>
</div>
<div id="la-mayoria-de-las-muestras-no-son-muestras-aleatorias-simples" class="section level3">
<h3><span class="header-section-number">2.1.3</span> La mayoría de las muestras no son muestras aleatorias simples</h3>
<p>Si miras la lista anterior de posibles poblaciones, te darás cuenta que es casi imposible obtener una muestra aleatoria simple de la mayoría de esas poblaciones de interés. Cuando hacemos experimentos con estudiantes universitarios, el obtener una verdadera muestra aleatoria de estos estudiantes los podemos considerar como un milagro menor, aunque al final se trate de una población muy específica a partir de la cual generalizar. Mencionaré brevemente algunos de los otros tipos de muestreo que existen y que solemos encontrar con frecuencia:</p>
<ul>
<li><p><em>Muestreo estratificado</em>. Supongamos que tu población está (o puede estar) dividida en varias subpoblaciones o <em>estratos</em> diferentes. Quizás sea porque estás realizando un estudio en varios paises diferentes, por ejemplo. En lugar de intentar tomar una muestra aleatoria de toda la población en su conjunto, recolectamos una muestra aleatoria de cada una de las subpoblaciones o estratos. El muestreo estratificado suele ser más fácil de llevar a cabo que el muestreo aleatorio simple, especialmente cuando la población ya está dividida en los distintos estratos. También puede ser más eficiente que el muestreo aleatorio simple, especialmente cuando algunas de las subpoblaciones son raras o poco frecuentes. Por ejemplo, en el estudio de la esquizofrenia, resulta más sencillo dividir la población en dos estratos (con-esquizofrenia y sin-esquizofrenia) y adquirir una muestra de cada grupo. Si seleccionaramos personas al azar, obtendríamos tan pocas personas con esquizofrenia en la muestra que el estudio resultaría inútil.</p></li>
<li><p><em>Muestreo de bola de nieve</em>. Es una técnica que es especialmente útil cuando se toman muestras de una población “oculta” o de difícil acceso, y es especialmente común en las ciencias sociales. Por ejemplo, supongamos que los investigadores quieren realizar una encuesta de opinión a personas VIH positivo. Es posible que el equipo de investigación solo tenga los datos de contacto de algunas personas VIH positivo, por lo que la encuesta comienza pidiéndoles a esas personas que participen (etapa 1). Al final de la encuesta, se pide a los participantes que proporcionen los datos de contacto de otras personas que podrían querer participar. En la etapa 2, se encuesta a estos nuevos contactos. El proceso continúa hasta que los investigadores obtengan datos suficientes. La gran ventaja del muestreo de bola de nieve es que es capaz de proporcionar datos en situaciones que de otro modo serían imposibles de obtener. Desde el punto de vista estadístico, la principal desventaja es que la muestra es altamente no aleatoria y no aleatoria en formas que son difíciles de abordar.</p></li>
<li><p><em>Muestreo de conveniencia</em>. En este tipo de muestreo las muestras se eligen de una forma conveniente para el investigador, sin que exista una selección al azar a partir de la población de interés. El muestreo de bola de nieve es un tipo de muestreo de conveniencia, pero hay muchos otros. Un ejemplo son los estudios que se basan en estudiantes de universitarios. Estas muestras generalmente no son aleatorias desde dos puntos de vista: en primer lugar, depender de una muestra de estudiantes universitarios significa automáticamente que estos datos están restringidos a una sola subpoblación. En segundo lugar, los estudiantes suelen elegir los estudios en los que participan, por lo que la muestra es un subconjunto de estudiantes autoseleccionado, no un subconjunto seleccionado al azar. En general, la mayoría de los estudios incluyen muestras de conveniencia de una forma u otra. A veces, puede suponer una limitación en la interpretación de los resultados, pero no siempre.</p></li>
</ul>
</div>
<div id="cuanto-importa-si-no-se-tiene-una-muestra-aleatoria-simple" class="section level3">
<h3><span class="header-section-number">2.1.4</span> ¿Cuánto importa si no se tiene una muestra aleatoria simple?</h3>
<p>Hemos visto que en muchos casos no es posible recolectar muestras aleatorias simples. ¿Eso qué impacto tiene? Un ejemplo de ese impacto lo podemos apreciar con la diferencia que existe entre las Figuras <a href="estimation.html#fig:srs1">2.1</a> y <a href="estimation.html#fig:brs">2.2</a>. Sin embargo, no es tan malo como parece. Algunos tipos de muestras sesgadas no representan ningún problema. Por ejemplo, cuando utilizamos el muestreo estratificado, realmente sabemos <em>cuál</em> es el sesgo ya que lo hemos creado deliberadamente, con la intención de <em>aumentar</em> la efectividad de su estudio, y existen técnicas estadísticas que podemos utilizar para ajustar estos sesgos que hemos introducido. En estos casos, por lo tanto, no tenemos un problema.</p>
<p>Sin embargo, es importante recordar que el muestreo aleatorio es un medio para un fin, no el fin en sí mismo. Supongamos que recolectamos una muestra de conveniencia y, como tal, podemos asumir que está sesgada. Un sesgo en el método de muestreo solo es un problema si nos hace sacar conclusiones equivocadas. Desde esta perspectiva, podemos afirmar que no necesitamos que la muestra sea aleatoria en <em>todos</em> los aspectos: necesitamos que sea aleatoria con respecto al fenómeno de interés que buscamos estudiar. Supongamos que estoy haciendo un estudio sobre la capacidad de atención sostenida en niños de 6 años. En el estudio 1, tengo la capacidad de tomar muestras al azar de todos los niños de 6 años del mundo actualmente vivos, con una pequeña excepción: sólo puedo incluir niños nacidos en lunes. En el estudio 2, puedo tomar una muestra al azar de la población española. Con estos estudios quiero generalizar mis resultados a la población de todos los niños de 6 años. ¿Qué estudio es mejor? La respuesta, obviamente, es el estudio 1. ¿Por qué? Porque no tenemos ninguna razón para pensar que “nacer en lunes” influye en la capacidad de atención sostenida. Por otro lado, puedo pensar en varias razones por las que “ser español” podría ser importante. España es un país rico e industrializado con un sistema educativo muy desarrollado. Las personas que crecieron con este sistema habrán tenido experiencias de vida mucho más similares a las experiencias de vida de las personas que diseñaron las pruebas de capacidad de atención sostenida. Esta experiencia compartida podría traducirse fácilmente en creencias similares sobre cómo se debe “realizar una prueba”, entre otras razones. Este tipo de características son importantes y podrían, por ejemplo, llevar a una imagen engañosa de lo que es la capacidad atención sostenida.</p>
<p>Existe un reflexión clave oculta en esta discusión. Al diseñar estudios, es importante pensar en la población de interés y en esforzarse por elegir un método de muestreo que sea apropiado para esa población. En la práctica, muchas veces nos veremos obligados a utilizar una “muestra de conveniencia” (por ejemplo, estudiantes de unos pocos centros), pero deberíamos, al menos, dedicar un tiempo a pensar en los riesgos e implicaciones de esta práctica.</p>
</div>
<div id="parametros-poblacionales-y-estadisticos-muestrales" class="section level3">
<h3><span class="header-section-number">2.1.5</span> Parámetros poblacionales y estadísticos muestrales</h3>
<p>Hasta ahora hemos estado hablando de poblaciones como lo haría un científico. Para un educador, una población puede ser un grupo de niños. Para un ecologista, una población puede ser un grupo de osos. En la mayoría de los casos, las poblaciones son cosas concretas que realmente existen en el mundo real. Los estadísticos, sin embargo, tienen un interés dual. Por un lado, <em>están</em> interesados en los datos del mundo real de la misma forma que los científicos. Por otro lado, también operan en el ámbito de la abstracción pura como lo hacen los matemáticos. En consecuencia, la teoría estadística puede ser un poco abstracta cuando define una población. Para ello, los estadísticos operacionalizan el concepto de “población” en términos de objetos matemáticos los cuales ya conocemos: se llaman distribuciones de probabilidad.</p>
<p>La idea es muy simple. Digamos que estamos hablando (otra vez) de puntajes de coeficiente intelectual (CI). Para un educador, la población de interés es un grupo de humanos reales que tienen puntajes de CI. Un estadístico “simplifica” esto al definir operativamente a la población como la distribución de probabilidad representada en la Figura <a href="estimation.html#fig:IQdista">2.4</a>. Las pruebas de CI están <em>diseñadas</em> de tal forma que la media sea 100, que la desviación estándar sea 15 y que la distribución de los puntajes sea normal. Estos valores se denominan <strong><em>parámetros poblacionales</em></strong> porque son característicos de toda la población. Es decir, decimos que la media de la población <span class="math inline">\(\mu\)</span> es 100, y la desviación estándar de la población <span class="math inline">\(\sigma\)</span> es 15.</p>
<div class="figure"><span id="fig:IQdista"></span>
<img src="FdI2_files/figure-html/IQdista-1.png" alt="Distribución poblacional de los puntajes de CI." width="672" />
<p class="caption">
Figure 2.4: Distribución poblacional de los puntajes de CI.
</p>
</div>
<div class="figure"><span id="fig:IQdistb"></span>
<img src="FdI2_files/figure-html/IQdistb-1.png" alt="Muestra con 100 observaciones provenientes de la distribución poblacional previa." width="672" />
<p class="caption">
Figure 2.5: Muestra con 100 observaciones provenientes de la distribución poblacional previa.
</p>
</div>
<p>Supongamos que hacemos un experimento. Seleccionamos 100 personas al azar para que elaboren nuestro test de CI, lo cual me dará una muestra aleatoria de la población. Mi muestra consistirá en una serie de números como estos:</p>
<pre><code>                          106 101 98 80 74 ... 107 72 100</code></pre>
<p>Estos puntajes forman parte de una muestra extraída de una población con distribución normal, media de 100 y desviación estándar de 15. Si trazamos un histograma de esta muestra, obtendremos algo como el que se muestra en la Figura <a href="estimation.html#fig:IQdistb">2.5</a>. Podemos ver que el histograma tiene una forma <em>aproximadamente</em> normal, pero aún queda como una aproximación burda de la verdadera distribución de la población que se muestra en la Figura <a href="estimation.html#fig:IQdista">2.4</a>. Si calculamos la media muestral, obtendremos un número que está bastante cerca de la media de la población 100, pero no es idéntico. En este caso, vemos que las personas de mi muestra tienen un CI medio de 98,5 y la desviación estándar de sus puntuaciones de CI es de 15,9. Estos <strong><em>estadísticos muestrales</em></strong> nos presentan una descripción de nuestro conjunto de datos y, aunque son bastante similares a los valores reales de población, no son iguales. En general, los estadísticos muestrales son lo que podemos calcular a partir de un conjunto de datos mientras que los parámetros poblacionales son las cosas sobre las que deseamos aprender. Más adelante, hablaremos sobre cómo podemos estimar los parámetros poblacionales utilizando sus estadísticos muestrales (Sección <a href="#pointestimates"><strong>??</strong></a>) así como qué tan seguros estamos de esos estimadores (Sección <a href="#ci"><strong>??</strong></a>) pero antes necesitamos conocer algunos conceptos adicionales sobre la teoría de muestreo.</p>
</div>
</div>
<div id="lawlargenumbers" class="section level2">
<h2><span class="header-section-number">2.2</span> La ley de los grandes números</h2>
<p>En la sección anterior vimos los resultados de un experimento ficticio con un tamaño de muestra de <span class="math inline">\(N=100\)</span>. Los resultados fueron algo alentadores: la media real de la población es 100,,mientras que la media muestral fue de 98.5, una aproximación razonable. En muchos estudios científicos, este nivel de precisión es perfectamente aceptable, pero existen situaciones en las que nos gustaría ser bastante más precisos. Si queremos que nuestros estadísticos muestrales se acerquen más a los parámetros poblacionales, ¿qué podemos hacer al respecto?</p>
<p>La respuesta lógica sería recolectar más datos. Supongamos que hacemos un experimento más grande, en el cual medimos el CI de 10,000 personas. Si entrás <a href="https://leudave.shinyapps.io/sampling/">aquí</a> podrás hacer una simulación. El histograma de esta simulación se muestra en la Figura <a href="estimation.html#fig:IQdistc">2.6</a>. Una inspección rápida nos revelará que una muestra de mayor tamaño representa una mejor aproximación a la distribución poblacional real, especialmente si la comparamos con la muestra más pequeña. Esto también se ve reflejado en los estadísticos muestrales: el CI medio de la muestra grande es de 99.9 y su desviación estándar es de 15.1. Estos valores son muy cercanos a los valores reales de la población.</p>
<div class="figure"><span id="fig:IQdistc"></span>
<img src="FdI2_files/figure-html/IQdistc-1.png" alt="Muestra con 10,000 observaciones provenientes de la distribución poblacional previa." width="672" />
<p class="caption">
Figure 2.6: Muestra con 10,000 observaciones provenientes de la distribución poblacional previa.
</p>
</div>
<p>Con esto, podemos observar algo que parece obvio: entre más datos tengamos, mejores resultados obtendremos. Esta intuición tan evidente que compartimos todos, los estadísticos la definen como la <strong><em>ley de los grandes números</em></strong>. La ley de los grandes números es una ley matemática que aplica a muchos estadísticos muestrales, pero la forma más sencilla de entenderla es a través de la ley aplicada a las medias. Cuando se aplica a la media muestral, la ley de los grande números nos dice que conforme aumenta el tamaño de muestra, el valor de la media muestral se acercará al valor de la media poblacional real. O, para ser más precisos, conforme el tamaño muestral se aproxima al infinito (escrito como <span class="math inline">\(N \rightarrow \infty\)</span>) la media nuestral se aproximará a la media poblacional (<span class="math inline">\(\bar{X} \rightarrow \mu\)</span>).<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
<p>Espero que quede patente la importancia de la ley de los grandes números como una herramienta elemental en la teoría estadística. Esta ley de los grandes números es nuestro argumento para justificar nuestra creencia de que recolectar cada vez más y más datos nos acercará a la verdad. Para cualquier conjunto de datos, los estadísticos muestrales que calculemos estarán equivocados, pero la ley de los grandes números nos dice que si seguimos recolectando datos esos estadísticos muestrales tenderán a a acerca más y más a los parámetros poblacionales reales.</p>
</div>
<div id="samplesandclt" class="section level2">
<h2><span class="header-section-number">2.3</span> Distribuciones muestrales y el teorema del límite central</h2>
<p>La ley de los grandes números es una herramienta muy poderosa, pero no será suficiente para responder a todas nuestras preguntas. Entre otras cosas, lo que nos da esta ley es una “garantía a largo plazo”. A largo plazo, si pudiéramos recolectar una cantidad infinita de datos, la ley de los grandes números nos garantiza que los estadísticos muestrales serán correctos.</p>
<p>Sin embargo, esta “garantía a largo plazo” es de poca utilidad en la vida real: no basta con decir que <em>con el tiempo</em> llegaremos a la respuesta correcta cuando calculemos la media muestral. Saber que un conjunto de datos infinitamente largo me dará el valor exacto de la media poblacional es inconciliable con el <em>hecho</em> de que mi conjunto de datos tiene un tamaño de muestra de <span class="math inline">\(N=100\)</span>. En la vida real, tenemos que saber algo más sobre el comportamiento de la media muestral de una muestra modesta como la nuestra.</p>
<div id="samplingdists" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Distribución muestral de la media</h3>
<p>Abandonemos por un momento la idea de tener tamaños de muestra de 10,000 y pensemos en un experimento más modesto. Esta vez extraemos una muestra de <span class="math inline">\(N=5\)</span> personas y medimos su CI. Este es el resultado:</p>
<pre><code>90  82  94  99 110</code></pre>
<p>El CI medio de esta muestra es exactamente 95. Esta muestra nos revela un valor mucho menos preciso que en el experimento previo. Ahora imagina que decides <strong><em>replicar</em></strong> este mismo experimento. Es decir, quieres repetir el mismo procedimiento de tal forma que selecciones una nueva muestra aleatoria de 5 personas y obtener su CI una vez más. Estos son los CI de nuestra nueva muestra:</p>
<pre><code>78  88 111 111 117</code></pre>
<p>Al calcular la media de esta muestra vemos que es de 101. Si repetimos el experimento 10 veces más obtendremos los resultados que se muestran en la siguiente Tabla. Con ella podrás ver que la media muestral cambia con cada replicación del experimento.</p>
<table>
<thead>
<tr class="header">
<th align="left">.</th>
<th align="right">P1</th>
<th align="right">P2</th>
<th align="right">P3</th>
<th align="right">P4</th>
<th align="right">P5</th>
<th align="right">Media.Muestral</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Rep 1</td>
<td align="right">90</td>
<td align="right">82</td>
<td align="right">94</td>
<td align="right">99</td>
<td align="right">110</td>
<td align="right">95.0</td>
</tr>
<tr class="even">
<td align="left">Rep 2</td>
<td align="right">78</td>
<td align="right">88</td>
<td align="right">111</td>
<td align="right">111</td>
<td align="right">117</td>
<td align="right">101.0</td>
</tr>
<tr class="odd">
<td align="left">Rep 3</td>
<td align="right">111</td>
<td align="right">122</td>
<td align="right">91</td>
<td align="right">98</td>
<td align="right">86</td>
<td align="right">101.6</td>
</tr>
<tr class="even">
<td align="left">Rep 4</td>
<td align="right">98</td>
<td align="right">96</td>
<td align="right">119</td>
<td align="right">99</td>
<td align="right">107</td>
<td align="right">103.8</td>
</tr>
<tr class="odd">
<td align="left">Rep 5</td>
<td align="right">105</td>
<td align="right">113</td>
<td align="right">103</td>
<td align="right">103</td>
<td align="right">98</td>
<td align="right">104.4</td>
</tr>
<tr class="even">
<td align="left">Rep 6</td>
<td align="right">81</td>
<td align="right">89</td>
<td align="right">93</td>
<td align="right">85</td>
<td align="right">114</td>
<td align="right">92.4</td>
</tr>
<tr class="odd">
<td align="left">Rep 7</td>
<td align="right">100</td>
<td align="right">93</td>
<td align="right">108</td>
<td align="right">98</td>
<td align="right">133</td>
<td align="right">106.4</td>
</tr>
<tr class="even">
<td align="left">Rep 8</td>
<td align="right">107</td>
<td align="right">100</td>
<td align="right">105</td>
<td align="right">117</td>
<td align="right">85</td>
<td align="right">102.8</td>
</tr>
<tr class="odd">
<td align="left">Rep 9</td>
<td align="right">86</td>
<td align="right">119</td>
<td align="right">108</td>
<td align="right">73</td>
<td align="right">116</td>
<td align="right">100.4</td>
</tr>
<tr class="even">
<td align="left">Rep 10</td>
<td align="right">95</td>
<td align="right">126</td>
<td align="right">112</td>
<td align="right">120</td>
<td align="right">76</td>
<td align="right">105.8</td>
</tr>
</tbody>
</table>
<p>Supongamos ahora que decidimos continuar con este procedimiento, replicando el experimento de “5 puntuaciones de CI” una y otra vez. Y cada vez, obtendremos una media muestral diferente, que en el caso de los 10 experimentos que ya hemos hecho corresponderían con los siguientes valores:</p>
<pre><code>                      95.0 101.0 101.6 103.8 104.4 ...</code></pre>
<p>¿Qué pasaría si continuamos y recolectamos 10,000 medias muestrales y trazamos un histograma con ellas? Obtendríamos un resultado como el que vemos en la Figura <a href="estimation.html#fig:sampdistmean">2.7</a>. En esta imagen podemos apreciar que la media muestral de “5 puntuaciones de CI” se encuentra, por lo general, entre 90 y 110. Pero lo más interesante de esta Figura es que demuestra el hecho de que si repetimos el experimento una y otra vez, ¡lo que obtenemos es una <em>distribución</em> de las medias muestrales! Esta distribución recibe un nombre especial en estadística: se le llama <strong><em>distribución muestral de la media</em></strong>.</p>
<p>Las distribuciones muestrales son una idea teórica importante en la estadística, y además, son cruciales si queremos entender cómo se comportan las muestras pequeñas. Por ejemplo, cuando realizamos el primer experimento con 5 puntuaciones de CI, la media muestral fue de 95. Sin embargo, lo que la distribución muestral nos dice en la Figura <a href="estimation.html#fig:sampdistmean">2.7</a>, es que este experimento con 5 puntuaciones no es muy preciso. Si repetimos el experimento muchas veces, la distribución muestral nos dice que podemos esperar que la media muestral esté entre 80 y 120.</p>
<div class="figure"><span id="fig:sampdistmean"></span>
<img src="FdI2_files/figure-html/sampdistmean-1.png" alt="La distribución muestral de la media en el experimento con 5 puntuaciones de CI. Si obtenemos una muestra aleatoria de 5 personas y calculamos la *media* de sus puntajes, obtendremos casi con seguridad un valor entre 80 y 120, aunque existen individuos que tienen un CI mayor de 120 o menor de 80. La línea negra dibuja la distribución poblacional de los puntajes de CI para comparar." width="672" />
<p class="caption">
Figure 2.7: La distribución muestral de la media en el experimento con 5 puntuaciones de CI. Si obtenemos una muestra aleatoria de 5 personas y calculamos la <em>media</em> de sus puntajes, obtendremos casi con seguridad un valor entre 80 y 120, aunque existen individuos que tienen un CI mayor de 120 o menor de 80. La línea negra dibuja la distribución poblacional de los puntajes de CI para comparar.
</p>
</div>
</div>
<div id="existen-distribuciones-muestrales-para-cualquier-estadistico-muestral" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Existen distribuciones muestrales para cualquier estadístico muestral</h3>
<p>Una cosa que debemos tener en cuenta cuando pensemos sobre las distribuciones muestrales es que es posible estimarlos a partir de <em>cualquier</em> estadístico muestral. Por ejemplo, supongamos que en cada una de las veces que replicamos el “experimento con 5 puntajes de CI” también tomamos nota del valor de CI máximo en cada experimento. Esto daría como resultado una serie de número que empezaría de esta forma:</p>
<pre><code>                      110 117 122 119 113 ... </code></pre>
<p>Si hacemos esto una y otra vez obtendremos una distribución muestral muy diferente, concretamente la <em>distribución muestral del valor máximo</em>. La distribución muestral del valor máximo de 5 puntajes de CI se muestra en la Figura <a href="estimation.html#fig:sampdistmax">2.8</a>. No es de sorprender, que si escogemos a 5 personas al azar y seleccionamos a la persona con el puntaje más alto, este tenga un CI superior a la media. Y de hecho, la mayoría de las veces nos encontraremos con puntajes de CI en el rango entre 100 y 140.</p>
<div class="figure"><span id="fig:sampdistmax"></span>
<img src="img/estimation/sampdistmax.png" alt="Distribución muestral del valor máximo de CI" width="471" />
<p class="caption">
Figure 2.8: Distribución muestral del valor máximo de CI
</p>
</div>
</div>
<div id="clt" class="section level3">
<h3><span class="header-section-number">2.3.3</span> El teorema del límite central</h3>
<p>A continuación verás una serie de ilustraciones en las que podremos observar como influye el tamaño de la muestra en las distribuciones muestrales. Estas distribuciones muestrales se han generado a partir 10,000 muestras de datos sobre el CI, donde se ha calculado la media muestral de cada una de esas muestras. Los histogramas muestran la distribución de esas medias muestrales (en otras palabras, son distribuciones muestrales de la media). Cada valor individual de CI fue extraído de una distribución normal con media de 100 y desviación estándar de 15, que se muestra como una línea sólida de color negro.</p>
<div class="figure"><span id="fig:IQsampa"></span>
<img src="FdI2_files/figure-html/IQsampa-1.png" alt="Esta distribución muestral parte de una sola observación (tamaño muestral de 1), de forma que la media muestral es el puntaje de CI de una persona. Como consecuencia, la distribución muestral de la media es idéntica a la distribución poblacional de los valores de CI." width="672" />
<p class="caption">
Figure 2.9: Esta distribución muestral parte de una sola observación (tamaño muestral de 1), de forma que la media muestral es el puntaje de CI de una persona. Como consecuencia, la distribución muestral de la media es idéntica a la distribución poblacional de los valores de CI.
</p>
</div>
<div class="figure"><span id="fig:IQsampb"></span>
<img src="FdI2_files/figure-html/IQsampb-1.png" alt="Cuando aumentamos el tamaño de la muestra a 2, la media de cualquier muestra tiende a acercarse más a la media poblacional que a un puntaje individual de CI, por lo que el histograma (distribución muestral) es un poco más estrecho que el de la distribución de la población." width="672" />
<p class="caption">
Figure 2.10: Cuando aumentamos el tamaño de la muestra a 2, la media de cualquier muestra tiende a acercarse más a la media poblacional que a un puntaje individual de CI, por lo que el histograma (distribución muestral) es un poco más estrecho que el de la distribución de la población.
</p>
</div>
<div class="figure"><span id="fig:IQsampc"></span>
<img src="FdI2_files/figure-html/IQsampc-1.png" alt="Cuando el tamaño de la muestra es de 10 podemos ver que la distribución muestral de la media tiende a organizarse alrededor de la media (real) de la población." width="672" />
<p class="caption">
Figure 2.11: Cuando el tamaño de la muestra es de 10 podemos ver que la distribución muestral de la media tiende a organizarse alrededor de la media (real) de la población.
</p>
</div>
<p>Espero que con esta demostración, tengas un mejor idea de lo que son las distribuciones muestrales, y en particular lo que es la distribución muestral de la media. En esta sección hablaremos de cómo la distribución muestral de la media cambia en función del tamaño muestral. Intuitivamente tú ya conoces la respuesta: si tenemos sólo unas cuantas observaciones, es probable que la media muestral no sea muy precisa. Si replicas este experimento con una muestra pequeña y vuelves a calcular la media obtendrás, casi con seguridad, una respuesta muy diferente. En otras palabras, su distribución muestral es muy ancha. Por otro lado, si replicas un experimento con un tamaño muestral grande y calculas la media muestral varias veces, es muy probable que obtengas la misma respuesta, o al menos muy aproximada, por lo que la distribución muestral será muy estrecha. Esto lo puedes apreciar visualmente con las Figuras <a href="estimation.html#fig:IQsampa">2.9</a>, <a href="estimation.html#fig:IQsampb">2.10</a> y <a href="estimation.html#fig:IQsampc">2.11</a>: entre más grande sea la muestra, más estrecha será la distribución muestral. Podemos cuantificar este efecto si calculamos la desviación estándar de la distribución muestral, mejor conocida como el <strong><em>error estándar</em></strong>. El error estándar de la media se denota como <span class="math inline">\(\sigma\)</span> con el subíndice <span class="math inline">\(\bar{X}\)</span> (o SEM en inglés). Y como puedes ver y confirmar con las figuras, conforme aumenta el tamaño muestral <span class="math inline">\(N\)</span>, el error estándar disminuye.</p>
<p>De momento hemos visto cómo se comportan las distribuciones muestrales de los puntajes de CI, que es un parámetro que tiene una distribución poblacional normal. Pero, ¿qué pasa con aquellos datos que no guardan una distribución normal? Esta es la clave: sin importar la forma de la distribución de la población, si aumentamos <span class="math inline">\(N\)</span>, su distribución muestral siempre será como la que hemos visto con la distribución normal. Por ejemplo, en la Figura <a href="#fig:cltdemo"><strong>??</strong></a> verás que una distribución poblacional que tiene forma de rampa (los valores más altos son los más frecuentes). Si comparas esta forma con la de la distribución normal (la línea sólida negra), podrás confirmar que no se parecen en nada. Si repetimos el mismo procedimiento que hemos hecho anteriormente, y extraemos un número elevado de muestras (10,000) con un tamaño muestral de <span class="math inline">\(N=2\)</span> y calculamos sus medias muestrales, obtendremos la distribución muestral de la media que puedes ver en la Figura <a href="#fig:cltdemob"><strong>??</strong></a>. Esta distribución cambia de forma de manera importante, y aunque no es normal, se aproxima bastante, sobre todo si la comparamos con la distribución poblacional original (Figura <a href="#fig:cltdemoa"><strong>??</strong></a>). Si aumentamos el tamaño muestral a <span class="math inline">\(N=4\)</span>, la distribución muestral de la media se acerca más a una distribución normal (Figura <a href="#fig:cltdemoc"><strong>??</strong></a>, y con un tamaño muestral de <span class="math inline">\(N=8\)</span> esta ya es perfectamente normal. En otras palabras, siempre y cuando el tamaño de tu muestra no sea diminuto, la distribución muestral de la media será normal, ¡sin importar la forma de la distribución poblacional!</p>
<div class="figure"><span id="fig:cltdemo1"></span>
<img src="FdI2_files/figure-html/cltdemo-1.png" alt="Una demostración del teorema del límite central. En el primer panel, tenemos a una población con una distribución no-normal; en los tres paneles siguientes se muestran distribuciones muestrales de la media para muestra de tamaño muestral de 2, 4 y 8, extraídos de la distribución poblacional del primer panel. Como podrás ver, aunque la distribución poblacional original es no-normal, la distribución muestral de la media se acerca mucho a una distribución normal incluso cuando la muestra tiene 4 observaciones." width="672" />
<p class="caption">
Figure 2.12: Una demostración del teorema del límite central. En el primer panel, tenemos a una población con una distribución no-normal; en los tres paneles siguientes se muestran distribuciones muestrales de la media para muestra de tamaño muestral de 2, 4 y 8, extraídos de la distribución poblacional del primer panel. Como podrás ver, aunque la distribución poblacional original es no-normal, la distribución muestral de la media se acerca mucho a una distribución normal incluso cuando la muestra tiene 4 observaciones.
</p>
</div>
<div class="figure"><span id="fig:cltdemo2"></span>
<img src="FdI2_files/figure-html/cltdemo-2.png" alt="Una demostración del teorema del límite central. En el primer panel, tenemos a una población con una distribución no-normal; en los tres paneles siguientes se muestran distribuciones muestrales de la media para muestra de tamaño muestral de 2, 4 y 8, extraídos de la distribución poblacional del primer panel. Como podrás ver, aunque la distribución poblacional original es no-normal, la distribución muestral de la media se acerca mucho a una distribución normal incluso cuando la muestra tiene 4 observaciones." width="672" />
<p class="caption">
Figure 2.13: Una demostración del teorema del límite central. En el primer panel, tenemos a una población con una distribución no-normal; en los tres paneles siguientes se muestran distribuciones muestrales de la media para muestra de tamaño muestral de 2, 4 y 8, extraídos de la distribución poblacional del primer panel. Como podrás ver, aunque la distribución poblacional original es no-normal, la distribución muestral de la media se acerca mucho a una distribución normal incluso cuando la muestra tiene 4 observaciones.
</p>
</div>
<div class="figure"><span id="fig:cltdemo3"></span>
<img src="FdI2_files/figure-html/cltdemo-3.png" alt="Una demostración del teorema del límite central. En el primer panel, tenemos a una población con una distribución no-normal; en los tres paneles siguientes se muestran distribuciones muestrales de la media para muestra de tamaño muestral de 2, 4 y 8, extraídos de la distribución poblacional del primer panel. Como podrás ver, aunque la distribución poblacional original es no-normal, la distribución muestral de la media se acerca mucho a una distribución normal incluso cuando la muestra tiene 4 observaciones." width="672" />
<p class="caption">
Figure 2.14: Una demostración del teorema del límite central. En el primer panel, tenemos a una población con una distribución no-normal; en los tres paneles siguientes se muestran distribuciones muestrales de la media para muestra de tamaño muestral de 2, 4 y 8, extraídos de la distribución poblacional del primer panel. Como podrás ver, aunque la distribución poblacional original es no-normal, la distribución muestral de la media se acerca mucho a una distribución normal incluso cuando la muestra tiene 4 observaciones.
</p>
</div>
<div class="figure"><span id="fig:cltdemo4"></span>
<img src="FdI2_files/figure-html/cltdemo-4.png" alt="Una demostración del teorema del límite central. En el primer panel, tenemos a una población con una distribución no-normal; en los tres paneles siguientes se muestran distribuciones muestrales de la media para muestra de tamaño muestral de 2, 4 y 8, extraídos de la distribución poblacional del primer panel. Como podrás ver, aunque la distribución poblacional original es no-normal, la distribución muestral de la media se acerca mucho a una distribución normal incluso cuando la muestra tiene 4 observaciones." width="672" />
<p class="caption">
Figure 2.15: Una demostración del teorema del límite central. En el primer panel, tenemos a una población con una distribución no-normal; en los tres paneles siguientes se muestran distribuciones muestrales de la media para muestra de tamaño muestral de 2, 4 y 8, extraídos de la distribución poblacional del primer panel. Como podrás ver, aunque la distribución poblacional original es no-normal, la distribución muestral de la media se acerca mucho a una distribución normal incluso cuando la muestra tiene 4 observaciones.
</p>
</div>
<p>Con base en estas figuras, parece que tenemos evidencia suficiente para sustentar las siguientes afirmaciones sobre las distribuciones muestrales de la media:</p>
<ul>
<li>La media de una distribución muestral es igual a la media poblacional</li>
<li>La desviación estándar de una distribución muestral (el error estándar) disminuye conforme aumenta el tamaño muestral</li>
<li>La forma de una distribución muestral adquiere una forma normal o de campana conforme aumenta el tamaño muestral</li>
</ul>
<p>Estas tres afirmaciones que hemos deducido, pueden ser comprobadas a través de un teorema muy famoso en estadística, conocido como el <strong><em>teorema del límite central</em></strong>. Entre otras cosas, el teorema del límite central nos dice que si una distribución poblacional tiene una media <span class="math inline">\(\mu\)</span> y una desviación estándar <span class="math inline">\(\sigma\)</span>, entonces la distribución muestral de la media también tendra una media <span class="math inline">\(\mu\)</span> y un error estándar de la media:</p>
<p><span class="math display">\[
\mbox{SEM} = \frac{\sigma}{ \sqrt{N} }
\]</span> Ya que en esta fórmula se divide la desviación estándar de la población <span class="math inline">\(\sigma\)</span> por la raíz cuadrada del tamaño muestral <span class="math inline">\(N\)</span>, el error estándar disminuye conforme aumenta el tamaño muestral. También nos dice que la forma de la distribución muestral se vuelve normal.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<p>Este resultado es útil por muchas razones. Nos dice porqué los experimentos con un tamaño muestral más grande son más confiables que aquellos con muestras pequeñas, además de darnos una fórmula para el error estándar que nos permite cuantificar <em>qué tanto</em> más confiable es ese experimento. Nos dice que porque la distribución normal, es… <em>normal</em>. Cuando hacemos un experimento, muchas de las cosas que medimos son en realidad un promedio de muchas otras medidas (por ejemplo, la inteligencia “general” que mide el CI es un promedio de un gran número de habilidades “específicas”), y cuando eso pasa, la cantidad promediada debe seguir una distribución normal. Es por esta ley matemática que la distribución normal aparace con tanta frecuencia en los datos que recogemos del mundo real.</p>

</div>
</div>
</div>









<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>Técnicamente, la de ley de los grandes números es aplicable a cualquier estadístico muestral que pueda ser descrito como un promedio de cantidades independiente. La varianza muestral, por ejemplo, puede ser representado como un tipo de promedio y por ello, sujeto a la ley de los grandes números. Sin embargo, el valor mínimo muestral no puede ser interpretado como un promedio de nada, y por tanto, no es gobernado por la ley de los grandes números.<a href="estimation.html#fnref3">↩</a></p></li>
<li id="fn4"><p>Hemos explicado el caso de la media muestral que satisface el teorema del límite central. Sin embargo, existen otros estadísticos muestrales que también lo hacen, y que no revisaremos, al ser esto una introducción.<a href="estimation.html#fnref4">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probability.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["FdI2.pdf", "FdI2.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
